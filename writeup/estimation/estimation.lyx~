#LyX 2.1 created this file. For more info see http://www.lyx.org/
\lyxformat 474
\begin_document
\begin_header
\textclass article
\use_default_options true
\begin_modules
theorems-ams-bytype
natbibapa
knitr
\end_modules
\maintain_unincluded_children false
\language english
\language_package default
\inputencoding auto
\fontencoding global
\font_roman default
\font_sans default
\font_typewriter default
\font_math auto
\font_default_family default
\use_non_tex_fonts false
\font_sc false
\font_osf false
\font_sf_scale 100
\font_tt_scale 100
\graphics default
\default_output_format default
\output_sync 0
\bibtex_command bibtex8
\index_command default
\paperfontsize default
\spacing double
\use_hyperref false
\papersize default
\use_geometry false
\use_package amsmath 1
\use_package amssymb 1
\use_package cancel 1
\use_package esint 1
\use_package mathdots 1
\use_package mathtools 1
\use_package mhchem 1
\use_package stackrel 1
\use_package stmaryrd 1
\use_package undertilde 1
\cite_engine natbib
\cite_engine_type authoryear
\biblio_style plain
\use_bibtopic false
\use_indices false
\paperorientation portrait
\suppress_date false
\justification true
\use_refstyle 1
\index Index
\shortcut idx
\color #008000
\end_index
\secnumdepth 3
\tocdepth 3
\paragraph_separation skip
\defskip bigskip
\quotes_language english
\papercolumns 1
\papersides 1
\paperpagestyle default
\tracking_changes false
\output_changes false
\html_math_output 0
\html_css_as_file 0
\html_be_strict false
\end_header

\begin_body

\begin_layout Title
LAGR and its oracle properties
\end_layout

\begin_layout Author
Wesley Brooks
\end_layout

\begin_layout Section
Introduction
\end_layout

\begin_layout Standard
\begin_inset Note Comment
status open

\begin_layout Plain Layout
Whereas the coefficients in traditional linear regression are scalar constants,
 the coefficients in a varying coefficient regression (VCR) model are functions
 - often 
\backslash
emph{smooth} functions - of some effect modifying variable 
\backslash
citep{Hastie:1993a}.
 
\end_layout

\begin_layout Plain Layout
The methodology described herein is applicable to geostatistical data and
 areal data.
 Let $
\backslash
mathcal{D}$ be a spatial domain on which data is collected.
 For geostatistical data, let $
\backslash
bm{s}$ denote a location in $
\backslash
mathcal{D}$.
 Let a univariate spatial process $
\backslash
left
\backslash
{Y(
\backslash
bm{s}) : 
\backslash
bm{s} 
\backslash
in 
\backslash
mathcal{D}
\backslash
right
\backslash
}$ and a possibly multivariate spatial process $
\backslash
left
\backslash
{
\backslash
bm{X}(
\backslash
bm{s}) : 
\backslash
bm{s} 
\backslash
in 
\backslash
mathcal{D}
\backslash
right
\backslash
}$ denote random fields of the response and the covariates, respectively.
 For $i = 1, 
\backslash
dots, n$, let $
\backslash
bm{s}_i$ denote the sampling location in $
\backslash
mathcal{D}$ of the $i$th observation of the response and the covariates.
 Let the observed data be denoted $
\backslash
left
\backslash
{y(
\backslash
bm{s}_i), 
\backslash
bm{x}(
\backslash
bm{s}_i)
\backslash
right
\backslash
}$, $i=1, 
\backslash
dots, n$.
 Then the data are a realization of the random fields at the sampling locations
 $
\backslash
left
\backslash
{Y(
\backslash
bm{s}_i), 
\backslash
bm{X}(
\backslash
bm{s}_i)
\backslash
right
\backslash
}$ for $i=1, 
\backslash
dots, n$.
 
\end_layout

\begin_layout Plain Layout
For areal data, the spatial domain $
\backslash
mathcal{D}$ is partitioned into $n$ regions $
\backslash
{D_1, 
\backslash
dots, D_n
\backslash
}$ such that $
\backslash
mathcal{D} = 
\backslash
bigcup 
\backslash
limits_{i=1}^n D_i$.
 In the case of areal data, the random variables $
\backslash
left
\backslash
{Y(D_i), 
\backslash
bm{X}(D_i)
\backslash
right
\backslash
}$ are defined for regions instead of for point locations; population and
 spatial mean temperature are examples of areal data.
 The analytical method described herein can be applied to areal data if
 they are recast as geostatistical data by assuming that the data are point-refe
renced to a representative location of each region, such as the centroid.
 That is, $
\backslash
left
\backslash
{
\backslash
bm{X}(
\backslash
bm{s}_i), Y(
\backslash
bm{s}_i)
\backslash
right
\backslash
} $ where $
\backslash
bm{s}_i$ is the centroid of $D_i$ for $i=1, 
\backslash
dots, n$.
 
\end_layout

\begin_layout Plain Layout
Common practice in the analysis of geostatistical and areal data is to model
 the response variable with a spatial linear regression model consisting
 of the sum of a fixed mean function, a spatial random effect, and random
 error all on domain $
\backslash
mathcal{D}$, as in: 
\backslash
begin{align}
\backslash
label{eq:spatial-regression} Y(
\backslash
bm{s}) = 
\backslash
bm{X}(
\backslash
bm{s})'
\backslash
bm{
\backslash
beta} + W(
\backslash
bm{s}) + 
\backslash
varepsilon(
\backslash
bm{s}) 
\backslash
end{align} where $
\backslash
bm{X}(
\backslash
bm{s})'
\backslash
bm{
\backslash
beta}$ is the mean function consisting of a vector of covariates $
\backslash
bm{X}(
\backslash
bm{s})$, and a vector of regression coefficients $
\backslash
bm{
\backslash
beta}$.
 The random error $
\backslash
varepsilon(
\backslash
bm{s})$ denotes white noise such that the errors are independent and identically
 distributed with mean zero and variance $
\backslash
sigma^2$, while the random component $W(
\backslash
bm{s})$ denotes a mean-zero, second-order stationary random field that is
 independent of the random error.
 The mean function captures the large-scale systematic trend of the response,
 the spatial random field $W(
\backslash
bm{s})$ can be thought of as a small-scale spatial random effect, and the
 error term $
\backslash
varepsilon(
\backslash
bm{s})$ captures micro-scale variation 
\backslash
citep{Cressie:1993}.
\end_layout

\begin_layout Plain Layout
It is common to pre-specify the form of a covariance function for the spatial
 random effect $W(
\backslash
bm{s})$ 
\backslash
citep{Diggle:2007}.
 For example, the exponential covariance function (a special case of the
 Mat
\backslash
'{e}rn class of covariance functions) has the form 
\backslash
begin{align}
\backslash
label{eq:exponential-covariance} 
\backslash
text{Cov}(W(
\backslash
bm{s}), W(
\backslash
bm{t})) = 
\backslash
sigma^2 
\backslash
exp
\backslash
left
\backslash
{-
\backslash
phi^{-1} 
\backslash
delta(
\backslash
bm{s}, 
\backslash
bm{t}) 
\backslash
right
\backslash
} 
\backslash
end{align} where $
\backslash
sigma^2$ is a variance parameter, $
\backslash
phi$ is a range parameter, and $
\backslash
delta(
\backslash
bm{s}, 
\backslash
bm{t})$ is the Euclidean distance between locations $
\backslash
bm{s}$ and $
\backslash
bm{t}$.
 The general form of a covariance function in the Mat
\backslash
'{e}rn class is 
\backslash
begin{align}
\backslash
label{eq:matern-covarinace} 
\backslash
text{Cov}(W(
\backslash
bm{s}), W(
\backslash
bm{t})) = 
\backslash
left
\backslash
{
\backslash
Gamma(
\backslash
nu) 2^{
\backslash
nu-1} 
\backslash
right
\backslash
}^{-1} 
\backslash
left
\backslash
{
\backslash
delta(
\backslash
bm{s}, 
\backslash
bm{t}) 
\backslash
phi^{-1}
\backslash
sqrt{2
\backslash
nu}
\backslash
right
\backslash
}^
\backslash
nu K_{
\backslash
nu} 
\backslash
left(
\backslash
delta(
\backslash
bm{s}, 
\backslash
bm{t}) 
\backslash
phi^{-1}
\backslash
sqrt{2
\backslash
nu}
\backslash
right) 
\backslash
end{align} where $
\backslash
nu$ denotes the degree of smoothness, $K_{
\backslash
nu}$ denotes the modified Bessel equation of the second kind, and as before
 $
\backslash
phi$ denotes a range parameter and $
\backslash
delta(
\backslash
bm{s}, 
\backslash
bm{t})$ the Euclidean distance between locations $
\backslash
bm{s}$ and $
\backslash
bm{t}$.
 The exponential covariance function corresponds to a Mat
\backslash
'{e}rn class covariance function with $
\backslash
nu = 1/2$.
\end_layout

\begin_layout Plain Layout
%SVCR - justification %Stationarity in spatial linear regression A random
 field is said to be stationary if the joint distribution of a the response
 at a finite set of locations does not change when the set of locations
 are all shifted in space by a fixed spatial lag.
 That is, letting $
\backslash
left
\backslash
{T(
\backslash
bm{s}) : 
\backslash
bm{s} 
\backslash
in 
\backslash
mathcal{D}
\backslash
right
\backslash
}$ be a random field on spatial domain $
\backslash
mathcal{D}$ that takes value $T(
\backslash
bm{s}_i)$ at location $
\backslash
bm{s}_i 
\backslash
in 
\backslash
mathcal{D}$ for $i = 1, 
\backslash
dots, n$, the random field $T(
\backslash
bm{s})$ is stationary if $F_n
\backslash
left(T(
\backslash
bm{s}_1), 
\backslash
dots, T(
\backslash
bm{s}_n)
\backslash
right) = F_n
\backslash
left(T(
\backslash
bm{s}_1+
\backslash
bm{h}), 
\backslash
dots, T(
\backslash
bm{s}_n+
\backslash
bm{h})
\backslash
right)$ where $F_n(
\backslash
cdot)$ is the joint distribution of a length $n$ sample from $T(
\backslash
bm{s})$ and $
\backslash
bm{h}$ is a fixed spatial lag.
 The random field $
\backslash
left
\backslash
{T(
\backslash
bm{s}) : 
\backslash
bm{s} 
\backslash
in 
\backslash
mathcal{D}
\backslash
right
\backslash
}$ is second-order stationary if the following are satisfied: 
\backslash
begin{align} E
\backslash
left
\backslash
{ T(
\backslash
bm{s}) 
\backslash
right
\backslash
} &= 
\backslash
mu 
\backslash
text{ for all } 
\backslash
bm{s} 
\backslash
in 
\backslash
mathcal{D} 
\backslash
notag 
\backslash

\backslash
 
\backslash
text{var}
\backslash
left
\backslash
{T(
\backslash
bm{s})
\backslash
right
\backslash
} &= 
\backslash
sigma^2 < 
\backslash
infty 
\backslash
text{ for all } 
\backslash
bm{s} 
\backslash
in 
\backslash
mathcal{D} 
\backslash
notag 
\backslash

\backslash
 
\backslash
text{cov}
\backslash
left
\backslash
{ T(
\backslash
bm{s}), T(
\backslash
bm{s} + 
\backslash
bm{h}) 
\backslash
right
\backslash
} &= C(
\backslash
bm{h}) 
\backslash
end{align} where the function $C(
\backslash
cdot)$ depends only on the spatial lag $
\backslash
bm{h}$ and not on the location $
\backslash
bm{s}$.
 %the joint distribution at any two locations in the domain does not change
 when the locations are shifted by a fixed spatial lag.
 
\end_layout

\begin_layout Plain Layout
The coefficient vector $
\backslash
bm{
\backslash
beta}$ in (
\backslash
ref{eq:spatial-regression}) is a fixed constant.
 The model can be made more flexible if the coefficients are described by
 a stationary random field.
 Such a model is written 
\backslash
begin{align}
\backslash
label{eq:SVCR-process} Y(
\backslash
bm{s}) = 
\backslash
bm{X}(
\backslash
bm{s})'
\backslash
bm{
\backslash
beta}(
\backslash
bm{s}) + 
\backslash
varepsilon(
\backslash
bm{s}) 
\backslash
end{align} where $
\backslash
bm{
\backslash
beta}(
\backslash
bm{s})$ is a random coefficient field with a Mat
\backslash
'{e}rn-class covariance function and the spatial random effect $W(
\backslash
bm{s})$ included in the intercept $
\backslash
beta_0(
\backslash
bm{s})$.
 The random coefficient field $
\backslash
bm{
\backslash
beta}(
\backslash
bm{s})$ can be estimated by Markov Chain Monte Carlo (MCMC) methods under
 the assumption that $
\backslash
bm{
\backslash
beta}(
\backslash
bm{s})$ is stationary 
\backslash
citep{Gelfand:2003}.
\end_layout

\begin_layout Plain Layout
%The spatial random effect describes the spatial pattern in the deviations
 from the systematic part of the model.
 When fitting the spatial regression model (
\backslash
ref{eq:spatial-regression}), it is usually required that the the fitted
 values of the spatial random effect and of the residuals sum to zero, i.e.
 $
\backslash
sum
\backslash
limits_{i=1}^n
\backslash
hat{W}(
\backslash
bm{s}_i) = 0$ and $
\backslash
sum
\backslash
limits_{i=1}^n
\backslash
hat{
\backslash
varepsilon}(
\backslash
bm{s}_i) = 0$.
 This mode of analysis is appropriate when the systematic part of the regression
 model does not vary between locations.
 On the other hand, a VCR model is appropriate for the case where the systematic
 part of the regression model does vary across locations.
\end_layout

\begin_layout Plain Layout
%Spatial VCR Alternatively, kernel-based and spline-based methods can be
 considered for fitting VCR models without assuming the coefficients are
 described by a stationary random field.
 
\end_layout

\begin_layout Plain Layout
Coefficients for a spline-based VCR model are estimated by maximizing a
 penalized global likelihood, with the penalty calculated from the wiggliness
 of the coefficient surface 
\backslash
citep{Wood:2006}.
 This contrasts to kernel-based estimates of the coefficients in a VCR model,
 which maximize a local likelihood to estimate the local coefficients at
 each sampling location 
\backslash
citep{Loader:1999}.
 
\backslash
cite{Fan:1999} demonstrated that the optimal kernel bandwidth estimate for
 a VCR model can be found via a two-step technique.
 
\end_layout

\begin_layout Plain Layout
Model selection in VCR models may be local or global.
 Global selection means including or excluding variables everywhere in the
 spatial domain, while local selection means including or excluding variables
 at individual locations within the spatial domain.
 For global model selection in spline-based VCR models, 
\backslash
cite{Wang:2008a} proposed a SCAD penalty 
\backslash
citep{Fan:2001} for variable selection in spline-based VCR models with a
 univariate effect-modifying variable.
 
\backslash
cite{Antoniadis:2012a} used the nonnegative Garrote penalty 
\backslash
citep{Breiman:1995} in P-spline-based VCR models having a univariate effect-modi
fying variable.
 
\end_layout

\begin_layout Plain Layout
Wavelet methods for fitting SVCR models were explored by 
\backslash
cite{Shang-2011} and 
\backslash
cite{Zhang-2011}.
 Sparsity in the wavelet coefficients is achieved either by $
\backslash
ell_1$-penalization (also known as the Lasso 
\backslash
citep{Tibshirani:1996}) 
\backslash
citep{Shang-2011} or by Bayesian variable selection 
\backslash
citep{Zhang-2011}.
 Sparsity in the wavelet domain does not imply sparsity in the covariates,
 though, so neither method is suitable for local variable selection.
\end_layout

\begin_layout Plain Layout
Geographically weighted regression (GWR) is a kernel-based method for estimating
 the coefficients of an SVCR model where the kernel weights are based on
 the distance between sampling locations 
\backslash
citep{Brundson:1998a, Fotheringham:2002}.
 At each sampling location, traditional GWR estimates the local regression
 coefficients by the local likelihood 
\backslash
citep{Loader:1999}.
 As a kernel-based smoother for regression coefficients, traditional GWR
 tends to exhibit bias near the boundary of the region being modeled 
\backslash
citep{Hastie:1993b}.
 One way to reduce the boundary-effect bias is to model the coefficient
 surface as locally linear rather than locally constant by including coefficient
-by-location interactions 
\backslash
citep{Wang:2008b}.
 
\end_layout

\begin_layout Plain Layout
Current practice for VCR models relies on 
\shape italic
a priori
\shape default
 global model selection to decide which variables should be included in
 the model.
 The idea of using Lasso regularization for local variable selection in
 a VCR model has appeared in the literature as the geographically weighted
 Lasso (GWL) 
\begin_inset CommandInset citation
LatexCommand cite
key "Wheeler-2009"

\end_inset

.
 The GWL applies the Lasso for local variable selection and uses a jackknife
 criterion for selection of the Lasso tuning parameters.
 However, there are several drawbacks to the GWL.
 First, the GWL is a lasso procedure, but the lasso does not generally produce
 consistent estimates of the relevant covariates 
\begin_inset CommandInset citation
LatexCommand cite
key "Leng-2006"

\end_inset

.
 Because the jackknife criterion can only be computed at sampling locations
 where the response variable is observed, the GWL cannot be used to impute
 missing values of the response variable nor to interpolate the coefficient
 surface and/or the response variable between sampling locations.
 
\end_layout

\begin_layout Plain Layout
The adaptive Lasso (AL) 
\backslash
citep{Zou:2006} is an improvement to the Lasso that does produce consistent
 estimates of the coefficients and has been shown to have appealing properties
 for automating variable selection, which under suitable conditions include
 the ``oracle" property of asymptotically selecting exactly the correct
 set of covariates for inclusion in a regression model.
 
\end_layout

\begin_layout Plain Layout
The remainder of this document is organized as follows.
 In Section 
\backslash
ref{section:simulation}, a simulation study is conducted to assess the performan
ce of the GWEN in variable selection and coefficient estimation.
 An application to real data is presented in Section 
\backslash
ref{section:data-analysis}.
 
\end_layout

\end_inset


\end_layout

\begin_layout Section
Varying coefficients regression
\begin_inset CommandInset label
LatexCommand label
name "sec:vcr"

\end_inset


\end_layout

\begin_layout Subsection
Model
\end_layout

\begin_layout Standard
Consider 
\begin_inset Formula $n$
\end_inset

 data points, observed at sampling locations 
\begin_inset Formula $\bm{s}_{i}=(s_{i,1}\;\; s_{i,2})^{T}$
\end_inset

 for 
\begin_inset Formula $i=1,\dots,\bm{s}_{n}$
\end_inset

, which are distributed in a spatial domain 
\begin_inset Formula $D\subset\mathbb{R}^{2}$
\end_inset

 according to a density 
\begin_inset Formula $f(\bm{s})$
\end_inset

.
 For 
\begin_inset Formula $i=1,\dots,n$
\end_inset

, let 
\begin_inset Formula $y(\bm{s}_{i})$
\end_inset

 and 
\begin_inset Formula $\bm{x}(\bm{s}_{i})$
\end_inset

 denote, respectively, the univariate response and the 
\begin_inset Formula $(p+1)$
\end_inset

-variate vector of covariates measured at location 
\begin_inset Formula $\bm{s}_{i}$
\end_inset

.
 At each location 
\begin_inset Formula $\bm{s}_{i}$
\end_inset

, assume that the outcome is related to the covariates by a linear model
 where the coefficients 
\begin_inset Formula $\bm{\beta}(\bm{s}_{i})$
\end_inset

 may be spatially-varying and 
\begin_inset Formula $\varepsilon(\bm{s}_{i})$
\end_inset

 is random error at location 
\begin_inset Formula $\bm{s}_{i}$
\end_inset

.
 That is, 
\begin_inset Formula 
\begin{align}
y(\bm{s}_{i})=\bm{x}(\bm{s}_{i})'\bm{\beta}(\bm{s}_{i})+\varepsilon(\bm{s}_{i}).\label{eq:lm(s)}
\end{align}

\end_inset


\end_layout

\begin_layout Standard
Further assume that the error term 
\begin_inset Formula $\varepsilon(\bm{s}_{i})$
\end_inset

 is normally distributed with zero mean and variance 
\begin_inset Formula $\sigma^{2}$
\end_inset

, and that 
\begin_inset Formula $\varepsilon(\bm{s}_{i})$
\end_inset

, 
\begin_inset Formula $i=1,\dots,n$
\end_inset

 are independent.
 That is, 
\begin_inset Formula 
\begin{align}
\bm{\varepsilon}\overset{iid}{\sim}\mathcal{N}\left(0,\sigma^{2}\right).\label{eq:err}
\end{align}

\end_inset


\end_layout

\begin_layout Subsection
Augment the covariates and the coefficients with location interactions
\end_layout

\begin_layout Standard
In the context of nonparametric regression, the boundary-effect bias can
 be reduced by local polynomial modeling, usually in the form of a locally
 linear model 
\begin_inset CommandInset citation
LatexCommand cite
key "Fan-Gijbels-1996"

\end_inset

.
 Here, locally linear coefficients are estimated by augmenting the local
 design matrix with covariate-by-location interactions in two dimensions
 as proposed by 
\begin_inset CommandInset citation
LatexCommand cite
key "Wang-2008b"

\end_inset

.
 The augmented local design matrix at location 
\begin_inset Formula $\bm{s}_{i}$
\end_inset

 is 
\begin_inset Formula 
\begin{align}
\bm{Z}(\bm{s}_{i})=\left(\bm{X}\:\: L_{i}\bm{X}\:\: M_{i}\bm{X}\right)
\end{align}

\end_inset


\end_layout

\begin_layout Standard
where 
\begin_inset Formula $\bm{X}$
\end_inset

 is the unaugmented matrix of covariates, 
\begin_inset Formula $L_{i}=\text{diag}\{s_{i'_{1}}-s_{i_{1}}\}$
\end_inset

 and 
\begin_inset Formula $M_{i}=\text{diag}\{s_{i'_{2}}-s_{i_{2}}\}$
\end_inset

 for 
\begin_inset Formula $i'=1,\dots,n$
\end_inset

.
\end_layout

\begin_layout Standard
Now we have that 
\begin_inset Formula $Y(\bm{s}_{i})=\left\{ \bm{Z}(\bm{s}_{i})\right\} _{i}^{T}\bm{\zeta}(\bm{s}_{i})+\varepsilon(\bm{s}_{i})$
\end_inset

, where 
\begin_inset Formula $\left\{ \bm{Z}(\bm{s}_{i})\right\} _{i}^{T}$
\end_inset

 is the 
\begin_inset Formula $i$
\end_inset

th row of the matrix 
\begin_inset Formula $\bm{Z}(\bm{s}_{i})$
\end_inset

 as a row vector, and 
\begin_inset Formula $\bm{\zeta}(\bm{s}_{i})$
\end_inset

 is the vector of local coefficients at location 
\begin_inset Formula $\bm{s}_{i}$
\end_inset

, augmented with the local gradients of the coefficient surfaces in the
 two spatial dimensions, indicated by 
\begin_inset Formula $\nabla_{u}$
\end_inset

 and 
\begin_inset Formula $\nabla_{v}$
\end_inset

:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
\bm{\zeta}(\bm{s}_{i})=\left(\bm{\beta}(\bm{s}_{i})^{T}\;\;\nabla_{u}\bm{\beta}(\bm{s}_{i})^{T}\;\;\nabla_{v}\bm{\beta}(\bm{s}_{i})^{T}\right)^{T}
\]

\end_inset


\end_layout

\begin_layout Subsection
Local likelihood
\end_layout

\begin_layout Standard
The total log-likelihood of the observed data is the sum of the log-likelihood
 of each individual observation: 
\begin_inset Formula 
\begin{align}
\ell\left\{ \bm{\zeta}\right\} =-(1/2)\sum_{i=1}^{n}\left[\log{\sigma^{2}}+\sigma^{-2}\left\{ y(\bm{s}_{i})-\bm{z}'(\bm{s}_{i})\bm{\zeta}(\bm{s}_{i})\right\} ^{2}\right].\label{eq:coefficients}
\end{align}

\end_inset


\end_layout

\begin_layout Standard
Since there are a total of 
\begin_inset Formula $n\times3(p+1)+1$
\end_inset

 parameters for 
\begin_inset Formula $n$
\end_inset

 observations, the model is not identifiable and it is not possible to directly
 maximize the total likelihood.
 But since the coefficient functions are smooth, the coefficients at location
 
\begin_inset Formula $\bm{s}$
\end_inset

 can approximate the coefficients within some neighborhood of 
\begin_inset Formula $\bm{s}$
\end_inset

, with the quality of the approximation declining as the distance from 
\begin_inset Formula $\bm{s}$
\end_inset

 increases.
\end_layout

\begin_layout Standard
This intuition is formalized by the local likelihood, which is maximized
 at location 
\begin_inset Formula $\bm{s}$
\end_inset

 to estimate the local coefficients 
\begin_inset Formula $\bm{\zeta}(\bm{s})$
\end_inset

: 
\begin_inset Formula 
\begin{align}
\mathcal{L}\left\{ \bm{\zeta}(\bm{s})\right\}  & =\prod_{i=1}^{n}\left\{ \left(2\pi\sigma^{2}\right)^{-1/2}\exp\left[-(1/2)\sigma^{-2}\left\{ y(\bm{s}_{i})-\bm{z}'(\bm{s}_{i})\bm{\zeta}(\bm{s})\right\} ^{2}\right]\right\} ^{K_{h}(\|\bm{s}-\bm{s}_{i}\|)},\label{eq:local-likelihood}
\end{align}

\end_inset


\end_layout

\begin_layout Standard
The weights are computed from a kernel function 
\begin_inset Formula $K_{h}(\cdot)$
\end_inset

 such as the Epanechnikov kernel: 
\begin_inset Formula 
\begin{align}
K_{h}(\|\bm{s}_{i}-\bm{s}_{i'}\|) & =h^{-2}K\left(h^{-1}\|\bm{s}_{i}-\bm{s}_{i'}\|\right)\notag\label{eq:epanechnikov}\\
K(x) & =\begin{cases}
(3/4)(1-x^{2}) & \mbox{ if }x<1,\\
0 & \mbox{ if }x\geq1.
\end{cases}
\end{align}

\end_inset


\end_layout

\begin_layout Standard
Thus, the local log-likelihood function is, up to an additive constant:
 
\begin_inset Formula 
\begin{align}
\ell\left\{ \bm{\zeta}(\bm{s})\right\}  & =-(1/2)\sum_{i=1}^{n}K_{h}(\|\bm{s}-\bm{s}_{i}\|)\left[\log{\sigma^{2}}+\sigma^{-2}\left\{ y(\bm{s}_{i})-\bm{z}'(\bm{s}_{i})\bm{\zeta}(\bm{s})\right\} ^{2}\right].\label{eq:local-log-likelihood}
\end{align}

\end_inset


\end_layout

\begin_layout Subsection
Estimating the coefficients
\end_layout

\begin_layout Standard
Letting 
\begin_inset Formula $\bm{W}(\bm{s})$
\end_inset

 be a diagonal weight matrix where 
\begin_inset Formula $W_{ii}(\bm{s})=K_{h}(\|\bm{s}-\bm{s}_{i}\|)$
\end_inset

, the local likelihood is maximized by weighted least squares: 
\begin_inset Formula 
\begin{align}
\mathcal{S}\left\{ \bm{\zeta}(\bm{s})\right\}  & =(1/2)\left\{ \bm{Y}-\bm{Z}(\bm{s})\bm{\zeta}(\bm{s})\right\} ^{T}\bm{W}(\bm{s})\left\{ \bm{Y}-\bm{Z}(\bm{s})\bm{\zeta}(\bm{s})\right\} ^{T}\notag\label{eq:zeta-hat}\\
\therefore\tilde{\bm{\zeta}}(\bm{s}) & =\left\{ \bm{Z}^{T}(\bm{s})\bm{W}(\bm{s})\bm{Z}(\bm{s})\right\} ^{-1}\bm{Z}^{T}(\bm{s})\bm{W}(\bm{s})\bm{Y}
\end{align}

\end_inset


\end_layout

\begin_layout Standard
Now Theorem 3 of 
\begin_inset CommandInset citation
LatexCommand cite
key "Sun-Yan-Zhang-Lu-2014"

\end_inset

 says that, for any given 
\begin_inset Formula $\bm{{s}}$
\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
\sqrt{{nh^{2}f(\bm{{s}})}}\left[\hat{\bm{\beta}}(\bm{s})-\bm{\beta}(\bm{s})-(1/2)\kappa_{0}^{-1}\kappa_{2}h^{2}\left\{ \bm{\beta}_{uu}(\bm{s})+\bm{\beta}_{vv}(\bm{s})\right\} \right]\xrightarrow{{D}}N\left(\bm{0},\kappa_{0}^{-2}\nu_{0}\sigma^{2}\Psi^{-1}\right)
\]

\end_inset


\end_layout

\begin_layout Section
Local variable selection with LAGR
\begin_inset CommandInset label
LatexCommand label
name "sec:lagr-gaussian"

\end_inset


\end_layout

\begin_layout Standard
Estimating the local coefficients by (
\begin_inset CommandInset ref
LatexCommand ref
reference "eq:zeta-hat"

\end_inset

) relies on 
\emph on
a priori
\emph default
 variable selection.
 The goal of local adaptive grouped regularization (LAGR) is to simultaneously
 select the locally relevant predictors and estimate the local coefficients.
 The proposed LAGR penalty is an adaptive 
\begin_inset Formula $\ell_{1}$
\end_inset

 penalty akin to the adaptive group lasso 
\begin_inset CommandInset citation
LatexCommand citep
key "Wang-Leng-2008,Zou-2006"

\end_inset

.
\end_layout

\begin_layout Subsection
Variable groupings
\end_layout

\begin_layout Standard
Each raw covariate in a LAGR model is grouped with its covariate-by-location
 interactions.
 That is, 
\begin_inset Formula $\bm{\zeta}_{j}(\bm{s})=\left(\beta_{j}(\bm{s})\;\;\;\nabla_{u}\beta_{j}(\bm{s})\;\;\;\nabla_{v}\beta_{j}(\bm{s})\right)^{T}$
\end_inset

 for 
\begin_inset Formula $j=1,\dots,p$
\end_inset

.
 By the mechanism of the group lasso, variables within the same group are
 included in or dropped from the model together.
 The intercept group is left unpenalized.
\end_layout

\begin_layout Subsection
The LAGR-penalized local likelihood
\end_layout

\begin_layout Standard
The objective function for the LAGR at location 
\begin_inset Formula $\bm{s}$
\end_inset

 is the penalized local sum of squares: 
\begin_inset Formula 
\begin{align}
Q\{\bm{\zeta}(\bm{s})\} & =\mathcal{S}\left\{ \bm{\zeta}(\bm{s})\right\} +\mathcal{J}\{\bm{\zeta}(\bm{s})\}\notag\label{eq:adaptive-lasso-WLS}\\
 & =(1/2)\left\{ \bm{Y}-\bm{Z}(\bm{s})\bm{\zeta}(\bm{s})\right\} ^{T}\bm{W}(\bm{s})\left\{ \bm{Y}-\bm{Z}(\bm{s})\bm{\zeta}(\bm{s})\right\} ^{T}+\sum_{j=1}^{p}\phi_{j}(\bm{s})\|\bm{\zeta}_{j}(\bm{s})\|
\end{align}

\end_inset


\end_layout

\begin_layout Standard
which is the sum of the weighted sum of squares 
\begin_inset Formula $\mathcal{S}\left\{ \bm{\zeta}(\bm{s})\right\} $
\end_inset

 and the LAGR penalty 
\begin_inset Formula $\mathcal{J}\{\bm{\zeta}(\bm{s})\}$
\end_inset

.
\end_layout

\begin_layout Standard
The LAGR penalty for the 
\begin_inset Formula $j$
\end_inset

th group of coefficients 
\begin_inset Formula $\bm{\zeta}_{j}(\bm{s})$
\end_inset

 at location 
\begin_inset Formula $\bm{s}$
\end_inset

 is 
\begin_inset Formula $\phi_{j}(\bm{s})=\lambda_{n}(\bm{s})\|\tilde{\bm{\zeta}}_{j}(\bm{s})\|^{-\gamma}$
\end_inset

, where 
\begin_inset Formula $\lambda_{n}(\bm{s})>0$
\end_inset

 is a the local tuning parameter applied to all coefficients at location
 
\begin_inset Formula $\bm{s}$
\end_inset

 and 
\begin_inset Formula $\tilde{\bm{\zeta}}_{j}(\bm{s})$
\end_inset

 is the vector of unpenalized local coefficients from (
\begin_inset CommandInset ref
LatexCommand ref
reference "eq:zeta-hat"

\end_inset

).
\end_layout

\begin_layout Subsection
Oracle properties of LAGR
\end_layout

\begin_layout Theorem
\begin_inset CommandInset label
LatexCommand label
name "theorem:normality"

\end_inset

 
\end_layout

\begin_layout Theorem
\begin_inset Argument 1
status open

\begin_layout Plain Layout
Asymptotic normality
\end_layout

\end_inset


\end_layout

\begin_layout Theorem
If 
\begin_inset Formula $h^{-1}n^{-1/2}a_{n}\xrightarrow{p}0$
\end_inset

 and 
\begin_inset Formula $hn^{-1/2}b_{n}\xrightarrow{p}\infty$
\end_inset

 then 
\begin_inset Formula 
\[
h\sqrt{n}\left[\hat{\bm{\beta}}_{(a)}(\bm{s})-\bm{\beta}_{(a)}(\bm{s})-\frac{\kappa_{2}h^{2}}{2\kappa_{0}}\{\nabla_{uu}^{2}\bm{\beta}_{(a)}(\bm{s})+\nabla_{vv}^{2}\bm{\beta}_{(a)}(\bm{s})\}\right]\xrightarrow{d}N(0,f(\bm{s})^{-1}\kappa_{0}^{-2}\nu_{0}\sigma^{2}\Psi^{-1})
\]

\end_inset


\end_layout

\begin_layout --Separator--

\end_layout

\begin_layout Theorem
\begin_inset CommandInset label
LatexCommand label
name "theorem:selection"

\end_inset


\end_layout

\begin_layout Theorem
\begin_inset Argument 1
status open

\begin_layout Plain Layout
Selection consistency
\end_layout

\end_inset


\end_layout

\begin_layout Theorem
If 
\begin_inset Formula $h^{-1}n^{-1/2}a_{n}\xrightarrow{p}\infty$
\end_inset

 and 
\begin_inset Formula $hn^{-1/2}b_{n}\xrightarrow{p}\infty$
\end_inset

 then 
\begin_inset Formula $P\left\{ \|\hat{\bm{\zeta}}_{j}(\bm{s})\|=0\right\} \to0$
\end_inset

 if 
\begin_inset Formula $j\le p_{0}$
\end_inset

 and 
\begin_inset Formula $P\left\{ \|\hat{\bm{\zeta}}_{j}(\bm{s})\|=0\right\} \to1$
\end_inset

 if 
\begin_inset Formula $j>p_{0}$
\end_inset

.
 
\end_layout

\begin_layout Paragraph
Remarks
\end_layout

\begin_layout Standard
Together, TheoremÂ 
\begin_inset CommandInset ref
LatexCommand ref
reference "theorem:normality"

\end_inset

 and Theorem 
\begin_inset CommandInset ref
LatexCommand ref
reference "theorem:selection"

\end_inset

 indicate that the LAGR estimates have the same asymptotic distribution
 as a local regression model where the nonzero coefficients are known in
 advance 
\begin_inset CommandInset citation
LatexCommand citep
key "Sun-Yan-Zhang-Lu-2014"

\end_inset

, and that the LAGR estimates of true zero coefficients go to zero with
 probability one.
 Thus, selection and estimation by LAGR has the oracle property.
\end_layout

\begin_layout Paragraph
A note on rates
\end_layout

\begin_layout Standard
To prove the oracle properties of LAGR, we assumed that 
\begin_inset Formula $h^{-1}n^{-1/2}a_{n}\xrightarrow{p}0$
\end_inset

 and 
\begin_inset Formula $hn^{-1/2}b_{n}\xrightarrow{p}\infty$
\end_inset

.
 Therefore, 
\begin_inset Formula $h^{-1}n^{-1/2}\lambda_{n}(\bm{s})\to0$
\end_inset

 for 
\begin_inset Formula $j\le p_{0}$
\end_inset

 and 
\begin_inset Formula $hn^{-1/2}\lambda_{n}(\bm{s})\|\bm{\zeta}_{j}(\bm{s})\|^{-\gamma}\to\infty$
\end_inset

 for 
\begin_inset Formula $j>p_{0}$
\end_inset

.
\end_layout

\begin_layout Standard
We require that 
\begin_inset Formula $\lambda_{n}(\bm{s})$
\end_inset

 can satisfy both assumptions.
 Suppose 
\begin_inset Formula $\lambda_{n}(\bm{s})=n^{\alpha}$
\end_inset

, and recall that 
\begin_inset Formula $h=O(n^{-1/6})$
\end_inset

 and 
\begin_inset Formula $\|\tilde{\bm{\zeta}}_{p}(\bm{s})\|=O(h^{-1}n^{-1/2})$
\end_inset

.
 Then 
\begin_inset Formula $h^{-1}n^{-1/2}\lambda_{n}(\bm{s})=O(n^{-1/3+\alpha})$
\end_inset

 and 
\begin_inset Formula $hn^{-1/2}\lambda_{n}(\bm{s})\|\tilde{\bm{\zeta}}_{p}(\bm{s}\|^{-\gamma}=O(n^{-2/3+\alpha+\gamma/3})$
\end_inset

.
\end_layout

\begin_layout Standard
So 
\begin_inset Formula $(2-\gamma)/3<\alpha<1/3$
\end_inset

, which can only be satisfied for 
\begin_inset Formula $\gamma>1$
\end_inset

.
\end_layout

\begin_layout Subsection
Selecting the tuning parameter 
\begin_inset Formula $\lambda_{n}(\bm{s})$
\end_inset


\end_layout

\begin_layout Standard
In practical application, it is necessary to select the LAGR tuning parameter
 
\begin_inset Formula $\lambda_{n}(\bm{s})$
\end_inset

 for each local model.
 A popular approach in other lasso-type problems is to select the tuning
 parameter that maximizes a criterion that approximates the expected log-likelih
ood of a new, independent data set drawn from the same distribution.
 This is the framework of Mallows' Cp 
\begin_inset CommandInset citation
LatexCommand citep
key "Mallows-1973"

\end_inset

, Stein's unbiased risk estimate (SURE) 
\begin_inset CommandInset citation
LatexCommand citep
key "Stein-1981"

\end_inset

 and Akaike's information criterion (AIC) 
\begin_inset CommandInset citation
LatexCommand citep
key "Akaike-1973"

\end_inset

.
\end_layout

\begin_layout Standard
These criteria use a so-called covariance penalty 
\begin_inset CommandInset citation
LatexCommand citep
key "Efron:2004a"

\end_inset

 to estimate the bias due to using the same data set to select a model and
 to estimate its parameters.
 We adopt the approximate degrees of freedom for the adaptive group lasso
 from 
\begin_inset CommandInset citation
LatexCommand citet
key "Yuan-Lin-2006"

\end_inset

 and minimize the AICc 
\begin_inset CommandInset citation
LatexCommand citet
key "Hurvich-1998"

\end_inset

 to select the tuning parameter 
\begin_inset Formula $\lambda_{n}(\bm{s})$
\end_inset

:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{align*}
\hat{df}(\lambda;\bm{s})= & \sum_{j=1}^{p}I\left(\|\hat{\bm{\zeta}}(\bm{s})\|>0\right)+\sum_{j=1}^{p}\frac{\|\hat{\bm{\zeta}}(\bm{s})\|}{\|\tilde{\bm{\zeta}}(\bm{s})\|}(p_{j}-1)\\
\text{AIC}_{c}(\lambda;\bm{s})= & \sum_{i=1}^{n}K_{h}(\|\bm{s}-\bm{s}_{i}\|)\sigma^{-2}\left\{ y(\bm{s}_{i})-z'(\bm{s}_{i})\hat{\bm{\zeta}}(\lambda;\bm{s})\right\} ^{2}+2\hat{df}(\lambda;\bm{s})+\frac{2\hat{df}(\lambda;\bm{s})\left\{ \hat{df}(\lambda;\bm{s})+1\right\} }{\sum_{i=1}^{n}K_{h}(\|\bm{s}-\bm{s}_{i}\|)-\hat{df}(\lambda;\bm{s})-1}
\end{align*}

\end_inset


\end_layout

\begin_layout Standard
where the local coefficient estimate has been written 
\begin_inset Formula $\hat{\bm{\zeta}}(\lambda;\bm{s})$
\end_inset

 to emphasize that it depends on the tuning parameter.
\end_layout

\begin_layout Standard
\begin_inset Note Comment
status open

\begin_layout Section
Extension to GLLMs
\begin_inset CommandInset label
LatexCommand label
name "sec:lagr-gllm"

\end_inset


\end_layout

\begin_layout Subsection
Model
\end_layout

\begin_layout Plain Layout
Generalized linear models (GLM) extend the linear model to distributions
 other than gaussian.
 The generalized local linear model (GLLM) is an extension of the GLM to
 varying coefficient models via local regression.
\end_layout

\begin_layout Plain Layout
As was the case for local linear regression models, the GLLM coefficients
 are smooth functions of location, called 
\begin_inset Formula $\bm{\beta}(\bm{s})$
\end_inset

.
 If the response variable 
\begin_inset Formula $y$
\end_inset

 is from an exponential-family distribution then its density is 
\end_layout

\begin_layout Plain Layout
\begin_inset Formula 
\[
f\left\{ y(\bm{s})|\bm{x}(\bm{s})\right\} =c\left\{ y(\bm{s})\right\} \times\exp\left[\frac{\theta(\bm{s})y(\bm{s})-b\left\{ \theta(\bm{s})\right\} }{a\left\{ \phi(\bm{s})\right\} }\right]
\]

\end_inset


\end_layout

\begin_layout Plain Layout
where 
\begin_inset Formula $\phi$
\end_inset

 and 
\begin_inset Formula $\theta$
\end_inset

 are parameters and
\end_layout

\begin_layout Plain Layout
\begin_inset Formula 
\begin{align*}
E\left\{ y(\bm{s})|\bm{x}(\bm{s})\right\} = & \mu(\bm{s})=b'\left\{ \theta(\bm{s})\right\} \\
\theta(\bm{s})= & (g\circ b')^{-1}\left\{ \eta(\bm{s})\right\} \\
\eta(\bm{s})= & \bm{x}^{T}(\bm{s})\bm{\beta}(\bm{s})=g\left\{ \mu(\bm{s})\right\} \\
\text{\text{Var}}\left\{ y(\bm{s})|\bm{x}(\bm{s})\right\} = & b''\left\{ \theta(\bm{s})\right\} a\left\{ \phi(\bm{s})\right\} 
\end{align*}

\end_inset


\end_layout

\begin_layout Plain Layout
The function 
\begin_inset Formula $g(\cdot)$
\end_inset

 is called the link function.
 If its inverse 
\begin_inset Formula $g^{-1}(\cdot)=b'(\cdot)$
\end_inset

 then the composition 
\begin_inset Formula $(g\circ b')(\cdot)$
\end_inset

 is the identity function.
 This particular choice of 
\begin_inset Formula $g$
\end_inset

 is called the canonical link.
 We follow the practice of 
\begin_inset CommandInset citation
LatexCommand cite
key "Fan-Heckman-Wand-1995"

\end_inset

 in assuming the use of the canonical link.
\end_layout

\begin_layout Plain Layout
Under the canonical link function, the expressions for the mean and variance
 of the response variable can be simplified to
\end_layout

\begin_layout Plain Layout
\begin_inset Formula 
\begin{align*}
E\left\{ y(\bm{s})|\bm{x}(\bm{s})\right\} = & g^{-1}\left\{ \eta(\bm{s})\right\} \\
\text{\text{Var}}\left\{ y(\bm{s})|\bm{x}(\bm{s})\right\} = & a\left\{ \phi(\bm{s})\right\} /g'\left\{ \mu(\bm{s})\right\} =V\left\{ \mu(\bm{s})\right\} \times a\left\{ \phi(\bm{s})\right\} 
\end{align*}

\end_inset

 
\end_layout

\begin_layout Subsection
Local quasi-likelihood
\end_layout

\begin_layout Plain Layout
Assuming the canonical link, all that is required is to specify the mean-varianc
e relationship via the variance function, 
\begin_inset Formula $V\left\{ \mu(\bm{s})\right\} $
\end_inset

.
 Then the GLLM coefficients can be estimated by maximizing the local quasi-likel
ihood 
\end_layout

\begin_layout Plain Layout
\begin_inset Formula 
\begin{align}
\ell\left\{ \bm{\zeta}(\bm{s})\right\}  & =\sum_{i=1}^{n}K_{h}(\|\bm{s}-\bm{s}_{i}\|)Q\left[g^{-1}\left\{ z'(\bm{s}_{i})\bm{\zeta}(\bm{s})\right\} ,Y(\bm{s}_{i})\right].
\end{align}

\end_inset


\end_layout

\begin_layout Plain Layout
The local quasi-likelihood generalizes the local log-likelihood that was
 used to estimate coefficients in the local linear model case.
 The quasi-likelihood is convex, and is defined in terms of its derivative,
 the quasi-score function
\end_layout

\begin_layout Plain Layout
\begin_inset Formula 
\[
\frac{\partial}{\partial\mu}Q(\mu,y)=\frac{y-\mu}{V(\mu)}.
\]

\end_inset


\end_layout

\begin_layout Subsection
Estimation
\end_layout

\begin_layout Plain Layout
Under these conditions, the local quasi-likelihood is maximized where
\end_layout

\begin_layout Plain Layout
\begin_inset Formula 
\begin{align}
\left(\frac{\partial}{\partial\bm{\zeta}}\ell\right)\left\{ \hat{{\bm{\zeta}}}(\bm{s})\right\}  & =\sum_{i=1}^{n}K_{h}(\|\bm{s}-\bm{s}_{i}\|)\frac{y(\bm{s}_{i})-\hat{\mu}(\bm{s}_{i})}{V\left\{ \hat{\mu}(\bm{s}_{i})\right\} g'\left\{ \hat{\mu}(\bm{s}_{i})\right\} }\bm{z}(\bm{s}_{i})=\bm{0}_{3p}.
\end{align}

\end_inset


\end_layout

\begin_layout Plain Layout
Except for the 
\begin_inset Formula $K_{h}(\|\bm{s}-\bm{s}_{i}\|)$
\end_inset

 term, this is the same as the normal equations for estimating coefficients
 in a GLM.
 The method of iteratively reweighted least squares (IRLS) is used to solve
 for 
\begin_inset Formula $\hat{{\bm{\zeta}}}(\bm{s})$
\end_inset

.
\end_layout

\begin_layout Subsection
Distribution of the local coefficients
\end_layout

\begin_layout Plain Layout
The asymptotic distribution of the local coefficients in a varying-coefficients
 GLM with a one-dimensional effect-modifying parameter are given in 
\begin_inset CommandInset citation
LatexCommand cite
key "Cai-Fan-Li-2000"

\end_inset

.
 For coefficients that vary in two dimensions (e.g.
 spatial location), the asymptotic distribution under the canonical link
 is
\end_layout

\begin_layout Plain Layout
\begin_inset Formula 
\[
\sqrt{{nh^{2}f(\bm{{s}})}}\left[\hat{\bm{\beta}}(\bm{s})-\bm{\beta}(\bm{s})-(1/2)\kappa_{0}^{-1}\kappa_{2}h^{2}\left\{ \bm{\beta}_{uu}(\bm{s})+\bm{\beta}_{vv}(\bm{s})\right\} \right]\xrightarrow{{D}}N\left\{ \bm{0},\kappa_{0}^{-2}\nu_{0}\Gamma^{-1}(\bm{s})\right\} 
\]

\end_inset


\end_layout

\begin_layout Plain Layout
where 
\begin_inset Formula $\Gamma(\bm{s})=E\left[V\left\{ \mu(\bm{s})\right\} X(\bm{s})X(\bm{s})^{T}\right]$
\end_inset

.
\end_layout

\begin_layout Subsection
LAGR penalty
\end_layout

\begin_layout Plain Layout
As in the case of linear models, the LAGR for GLMs is a grouped 
\begin_inset Formula $\ell_{1}$
\end_inset

 regularization method.
 Now, though, we use a penalized local quasi-likelihood:
\end_layout

\begin_layout Plain Layout
\begin_inset Formula 
\begin{align}
Q\{\bm{\zeta}(\bm{s})\} & =\mathcal{\ell}\left\{ \bm{\zeta}(\bm{s})\right\} +\mathcal{J}\{\bm{\zeta}(\bm{s})\}\notag\label{eq:adaptive-lasso-GLLM}\\
 & =\sum_{i=1}^{n}K_{h}(\|\bm{s}-\bm{s}_{i}\|)Q\left[g^{-1}\left\{ z'(\bm{s}_{i})\bm{\zeta}(\bm{s})\right\} ,Y(\bm{s}_{i})\right]+\sum_{j=1}^{p}\phi_{j}(\bm{s})\|\bm{\zeta}_{j}(\bm{s})\|
\end{align}

\end_inset


\end_layout

\begin_layout Plain Layout
and similarly to the case for gaussian data, 
\begin_inset Formula $\phi_{j}(\bm{s})=\lambda_{n}(\bm{s})\|\tilde{\bm{\zeta}}_{j}(\bm{s})\|^{-\gamma}$
\end_inset

, where 
\begin_inset Formula $\lambda_{n}(\bm{s})>0$
\end_inset

 is a the local tuning parameter applied to all coefficients at location
 
\begin_inset Formula $\bm{s}$
\end_inset

 and 
\begin_inset Formula $\tilde{\bm{\zeta}}_{j}(\bm{s})$
\end_inset

 is the vector of unpenalized local coefficients.
\end_layout

\begin_layout Subsection
Oracle properties of LAGR in the GLM setting
\end_layout

\begin_layout Plain Layout
The oracle properties for LAGR in the GLM setting are similar to those in
 the gaussian setting:
\end_layout

\begin_layout Theorem
\begin_inset CommandInset label
LatexCommand label
name "theorem:normality-glm"

\end_inset

 
\end_layout

\begin_layout Theorem
\begin_inset Argument 1
status open

\begin_layout Plain Layout
Asymptotic normality
\end_layout

\end_inset


\end_layout

\begin_layout Theorem
If 
\begin_inset Formula $h^{-1}n^{-1/2}a_{n}\xrightarrow{p}0$
\end_inset

 and 
\begin_inset Formula $hn^{-1/2}b_{n}\xrightarrow{p}\infty$
\end_inset

 then 
\begin_inset Formula 
\[
h\sqrt{n}\left[\hat{\bm{\beta}}_{(a)}(\bm{s})-\bm{\beta}_{(a)}(\bm{s})-\frac{\kappa_{2}h^{2}}{2\kappa_{0}}\{\nabla_{uu}^{2}\bm{\beta}_{(a)}(\bm{s})+\nabla_{vv}^{2}\bm{\beta}_{(a)}(\bm{s})\}\right]\xrightarrow{d}N(0,f(\bm{s})^{-1}\kappa_{0}^{-2}\nu_{0}\Gamma^{-1}(\bm{s}))
\]

\end_inset


\end_layout

\begin_layout --Separator--

\end_layout

\begin_layout Theorem
\begin_inset CommandInset label
LatexCommand label
name "theorem:selection-glm"

\end_inset


\end_layout

\begin_layout Theorem
\begin_inset Argument 1
status open

\begin_layout Plain Layout
Selection consistency
\end_layout

\end_inset


\end_layout

\begin_layout Theorem
If 
\begin_inset Formula $h^{-1}n^{-1/2}a_{n}\xrightarrow{p}\infty$
\end_inset

 and 
\begin_inset Formula $hn^{-1/2}b_{n}\xrightarrow{p}\infty$
\end_inset

 then 
\begin_inset Formula $P\left\{ \|\hat{\bm{\zeta}}_{j}(\bm{s})\|=0\right\} \to0$
\end_inset

 if 
\begin_inset Formula $j\le p_{0}$
\end_inset

 and 
\begin_inset Formula $P\left\{ \|\hat{\bm{\zeta}}_{j}(\bm{s})\|=0\right\} \to1$
\end_inset

 if 
\begin_inset Formula $j>p_{0}$
\end_inset

.
 
\end_layout

\end_inset


\end_layout

\begin_layout Section
Simulations
\begin_inset CommandInset label
LatexCommand label
name "sec:simulations"

\end_inset


\end_layout

\begin_layout Standard
A simulation study was conducted to assess the performance of the method
 described in Sections 
\begin_inset CommandInset ref
LatexCommand ref
reference "sec:vcr"

\end_inset

--
\begin_inset CommandInset ref
LatexCommand ref
reference "sec:lagr-gaussian"

\end_inset

.
 
\end_layout

\begin_layout Standard
Data were simulated on the domain 
\begin_inset Formula $[0,1]^{2}$
\end_inset

, which was divided into a 
\begin_inset Formula $30\times30$
\end_inset

 grid.
 Each of 
\begin_inset Formula $p=5$
\end_inset

 covariates 
\begin_inset Formula $X_{1},\dots,X_{5}$
\end_inset

 was simulated by a Gaussian random field with mean zero and exponential
 covariance function 
\begin_inset Formula $\text{Cov}\left(X_{ji},X_{ji'}\right)=\sigma_{x}^{2}\exp{\left(-\tau_{x}^{-1}\delta_{ii'}\right)}$
\end_inset

 where 
\begin_inset Formula $\sigma_{x}^{2}=1$
\end_inset

 is the variance, 
\begin_inset Formula $\tau_{x}=0.1$
\end_inset

 is the range parameter, and 
\begin_inset Formula $\delta_{ii'}$
\end_inset

 is the Euclidean distance 
\begin_inset Formula $\|\bm{s}_{i}-\bm{s}_{i'}\|_{2}$
\end_inset

.
 
\end_layout

\begin_layout Standard
Correlation was induced between the covariates by multiplying the matrix
 
\begin_inset Formula $\bm{X}=\left(X_{1}\cdots X_{5}\right)$
\end_inset

 by 
\begin_inset Formula $\bm{R}$
\end_inset

, where 
\begin_inset Formula $\bm{R}$
\end_inset

 is the Cholesky decomposition of the covariance matrix 
\begin_inset Formula $\bm{\Sigma}=\bm{R}'\bm{R}$
\end_inset

.
 The covariance matrix 
\begin_inset Formula $\bm{\Sigma}$
\end_inset

 is a 
\begin_inset Formula $5\times5$
\end_inset

 matrix that has ones on the diagonal and 
\begin_inset Formula $\rho$
\end_inset

 for all off-diagonal entries, where 
\begin_inset Formula $\rho$
\end_inset

 is the between-covariate correlation.
 
\end_layout

\begin_layout Standard
The simulated response was 
\begin_inset Formula $y_{i}=\bm{x}'_{i}\bm{\beta}_{i}+\varepsilon_{i}$
\end_inset

 for 
\begin_inset Formula $i=1,\dots,n$
\end_inset

 where 
\begin_inset Formula $n=900$
\end_inset

 and the 
\begin_inset Formula $\varepsilon_{i}$
\end_inset

's were iid Gaussian with mean zero and variance 
\begin_inset Formula $\sigma_{\varepsilon}^{2}$
\end_inset

.
 The simulated data included the response 
\begin_inset Formula $y$
\end_inset

 and five covariates 
\begin_inset Formula $x_{1},\dots,x_{5}$
\end_inset

.
 The true data-generating model uses only 
\begin_inset Formula $x_{1}$
\end_inset

.
 The variables 
\begin_inset Formula $x_{2},\dots,x_{5}$
\end_inset

 are included to assess performance in model selection.
 
\end_layout

\begin_layout Standard
Three different functions were used for the coefficient surface 
\begin_inset Formula $\beta_{1}(\bm{s})$
\end_inset

.
 They are plotted in Figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:simulation-coefficient-functions"

\end_inset

, and their mathematical forms are listed in (
\begin_inset CommandInset ref
LatexCommand ref
reference "eq:simulation-coefficient-functions"

\end_inset

).
 The first is a step function, which is equal to zero in 40% of the spatial
 domain, equal to one in a different 40% of the spatial domain, and increases
 linearly in the middle 20% of the domain.
 The second is a gradient function, which increases linearly from zero at
 one end of the domain to one at the other.
 The final coefficient function is a parabola taking its maximum value of
 1 at the center of the domain and falling to zero at each corner of the
 domain.
 
\end_layout

\begin_layout Standard
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\begin_inset Graphics
	filename ../../figures/simulation/step.pdf
	width 33text%

\end_inset


\begin_inset Graphics
	filename ../../figures/simulation/gradient.pdf
	width 33text%

\end_inset


\begin_inset Graphics
	filename ../../figures/simulation/parabola.pdf
	width 33text%

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
These are, respectively, the step, gradient, and parabola functions that
 were used for the coefficient function 
\begin_inset Formula $\beta_{1}(\bm{s})$
\end_inset

 in the VCR model 
\begin_inset Formula $y(\bm{s}_{i})=x_{1}(\bm{s}_{i})\beta_{1}(\bm{s}_{i})+\varepsilon(\bm{s}_{i})$
\end_inset

 when generating the data for the simulation study.
\begin_inset CommandInset label
LatexCommand label
name "fig:simulation-coefficient-functions"

\end_inset


\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{align}
\beta_{step}(\bm{s})= & \ \ \begin{cases}
1 & if\ s_{x}>0.6\\
5s_{x}-2 & if\ 0.4<s_{x}\le0.6\\
0 & o.w.
\end{cases}\nonumber \\
\beta_{gradient}(\bm{s})= & \ \ s_{x}\nonumber \\
\beta_{parabola}(\bm{s})= & \ \ 1-\frac{(s_{x}-0.5)^{2}+(s_{y}-0.5)^{2}}{0.5}\label{eq:simulation-coefficient-functions}
\end{align}

\end_inset


\end_layout

\begin_layout Standard
In total, three parameters were varied to produce 18 settings, each of which
 was simulated 100 times.
 There were three functional forms for the coefficient surface 
\begin_inset Formula $\beta_{1}(\bm{s})$
\end_inset

; data was simulated both with low (
\begin_inset Formula $\rho=0$
\end_inset

), medium (
\begin_inset Formula $\rho=0.5$
\end_inset

), and high (
\begin_inset Formula $\rho=0.9$
\end_inset

) correlation between the covariates; and simulations were made with low
 (
\begin_inset Formula $\sigma_{\varepsilon}^{2}=0.25$
\end_inset

) and high (
\begin_inset Formula $\sigma_{\varepsilon}^{2}=1$
\end_inset

) variance for the random error term.
 The simulation settings are enumerated in Table 
\begin_inset CommandInset ref
LatexCommand ref
reference "tab:simulation-settings"

\end_inset

.
 
\end_layout

\begin_layout Standard
\begin_inset Float table
wide false
sideways false
status open

\begin_layout Plain Layout
\begin_inset Tabular
<lyxtabular version="3" rows="19" columns="3">
<features rotate="0" tabularvalignment="middle">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<row>
<cell alignment="center" valignment="top" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $\beta_{1}(\bm{s})$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $\rho$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $\sigma_{\varepsilon}^{2}$
\end_inset


\end_layout

\end_inset
</cell>
</row>
<row>
<cell multirow="3" alignment="left" valignment="middle" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
step
\end_layout

\end_inset
</cell>
<cell multirow="3" alignment="left" valignment="middle" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
0
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
0.25
\end_layout

\end_inset
</cell>
</row>
<row>
<cell multirow="4" alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell multirow="4" alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
1
\end_layout

\end_inset
</cell>
</row>
<row>
<cell multirow="4" alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell multirow="3" alignment="left" valignment="middle" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
0.5
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
0.25
\end_layout

\end_inset
</cell>
</row>
<row>
<cell multirow="4" alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell multirow="4" alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
1
\end_layout

\end_inset
</cell>
</row>
<row>
<cell multirow="4" alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell multirow="3" alignment="left" valignment="middle" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
0.9
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
0.25
\end_layout

\end_inset
</cell>
</row>
<row>
<cell multirow="4" alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell multirow="4" alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
1
\end_layout

\end_inset
</cell>
</row>
<row>
<cell multirow="3" alignment="left" valignment="middle" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
gradient
\end_layout

\end_inset
</cell>
<cell multirow="3" alignment="left" valignment="middle" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
0
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
0.25
\end_layout

\end_inset
</cell>
</row>
<row>
<cell multirow="4" alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell multirow="4" alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
1
\end_layout

\end_inset
</cell>
</row>
<row>
<cell multirow="4" alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell multirow="3" alignment="left" valignment="middle" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
0.5
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
0.25
\end_layout

\end_inset
</cell>
</row>
<row>
<cell multirow="4" alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell multirow="4" alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
1
\end_layout

\end_inset
</cell>
</row>
<row>
<cell multirow="4" alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell multirow="3" alignment="left" valignment="middle" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
0.9
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
0.25
\end_layout

\end_inset
</cell>
</row>
<row>
<cell multirow="4" alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell multirow="4" alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
1
\end_layout

\end_inset
</cell>
</row>
<row>
<cell multirow="3" alignment="left" valignment="middle" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
parabola
\end_layout

\end_inset
</cell>
<cell multirow="3" alignment="left" valignment="middle" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
0
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
0.25
\end_layout

\end_inset
</cell>
</row>
<row>
<cell multirow="4" alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell multirow="4" alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
1
\end_layout

\end_inset
</cell>
</row>
<row>
<cell multirow="4" alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell multirow="3" alignment="left" valignment="middle" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
0.5
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
0.25
\end_layout

\end_inset
</cell>
</row>
<row>
<cell multirow="4" alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell multirow="4" alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
1
\end_layout

\end_inset
</cell>
</row>
<row>
<cell multirow="4" alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell multirow="3" alignment="left" valignment="middle" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
0.9
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
0.25
\end_layout

\end_inset
</cell>
</row>
<row>
<cell multirow="4" alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell multirow="4" alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
1
\end_layout

\end_inset
</cell>
</row>
</lyxtabular>

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
Listing of the simulation settings used to assess the performance of LAGR
 models versus oracle selection and no selection.
\begin_inset CommandInset label
LatexCommand label
name "tab:simulation-settings"

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Subsection
Methods for comparison
\end_layout

\begin_layout Standard
The performance of LAGR was compared to that of a VCR model without variable
 selection, and to a VCR model with oracular selection.
 Oracular selection means that exactly the correct set of covariates was
 used to fit each local model.
\end_layout

\begin_layout Subsection
Results
\end_layout

\begin_layout Standard
The results are presented in terms of the mean integrated squared error
 (MISE) of the coefficient surface estimates 
\begin_inset Formula $\hat{\beta}_{1}(\bm{s}),\dots,\hat{\beta}_{5}(\bm{s})$
\end_inset

, the MISE of the fitted response 
\begin_inset Formula $\hat{y}(\bm{s})$
\end_inset

, and the frequency with which the coefficient surface estimates 
\begin_inset Formula $\hat{\beta}_{1}(\bm{s}),\dots,\hat{\beta}_{5}(\bm{s})$
\end_inset

 in the LAGR model were zero.
\end_layout

\begin_layout Standard
The MISE of the estimates of 
\begin_inset Formula $\beta_{1}(\bm{s})$
\end_inset

 are in Table 
\begin_inset CommandInset ref
LatexCommand ref
reference "tab:x1-mise"

\end_inset

.
\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout

<<MISE-X1, echo=FALSE, results='asis', message=FALSE>>=
\end_layout

\begin_layout Plain Layout

#Imports:
\end_layout

\begin_layout Plain Layout

require(xtable)
\end_layout

\begin_layout Plain Layout

require(brooks)
\end_layout

\begin_layout Plain Layout

load("~/scratch/gwr-sim-output.RData")
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

#Calculate the MISE for the first coefficient:
\end_layout

\begin_layout Plain Layout

mise = matrix(0, nrow=0, ncol=3)
\end_layout

\begin_layout Plain Layout

for (setting in 1:18) {
\end_layout

\begin_layout Plain Layout

    #Get the proper coefficient surface
\end_layout

\begin_layout Plain Layout

    if (setting < 7) {B1 = step}
\end_layout

\begin_layout Plain Layout

    else if (setting < 13) {B1 = gradient}
\end_layout

\begin_layout Plain Layout

    else {B1 = parabola}
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

    #compute the MISE
\end_layout

\begin_layout Plain Layout

    row = sapply(c('lagr', 'gwr', 'oracle'),
\end_layout

\begin_layout Plain Layout

                  function(selection.method) {
\end_layout

\begin_layout Plain Layout

                     mean(sweep(output[[setting]][[selection.method]][['X1']],
 1, as.vector(B1))**2)                  			}
\end_layout

\begin_layout Plain Layout

	)
\end_layout

\begin_layout Plain Layout

    mise = rbind(mise, row)
\end_layout

\begin_layout Plain Layout

}
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

#Which entries should be bolded (for having the lowest MISE)?
\end_layout

\begin_layout Plain Layout

bold = matrix(FALSE, nrow=nrow(mise), ncol=ncol(mise))
\end_layout

\begin_layout Plain Layout

for (i in 1:nrow(mise)){
\end_layout

\begin_layout Plain Layout

    bold[i,which.min(mise[i,])] = TRUE
\end_layout

\begin_layout Plain Layout

}
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

#Which entries should be italicised (for having the second-lowest MISE)?
\end_layout

\begin_layout Plain Layout

ital = matrix(FALSE, nrow=nrow(mise), ncol=ncol(mise))
\end_layout

\begin_layout Plain Layout

for (i in 1:nrow(mise)){
\end_layout

\begin_layout Plain Layout

    ital[i,order(mise[i,])[2]] = TRUE
\end_layout

\begin_layout Plain Layout

}
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

#Put names on the table
\end_layout

\begin_layout Plain Layout

rownames(mise) = NULL
\end_layout

\begin_layout Plain Layout

colnames(mise) = c("LAGR", "none", "oracle")
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

#Generate the table, caption it, and print it with emphasis.
\end_layout

\begin_layout Plain Layout

mise.table = xtable(mise)
\end_layout

\begin_layout Plain Layout

caption(mise.table) = "The MISE for the estimates of $
\backslash

\backslash
beta_1(
\backslash

\backslash
bm{s})$ in each simulation setting, under variable selection via LAGR, no
 variable selection, and oracular variable selection.
 Highlighting indicates the 
\backslash

\backslash
textbf{lowest} and 
\backslash

\backslash
emph{next-lowest} MISE."
\end_layout

\begin_layout Plain Layout

label(mise.table) = "tab:x1-mise"
\end_layout

\begin_layout Plain Layout

xtable.printbold(mise.table, table.placement=NULL, which.bold=bold, which.ital=ital,
 hline.after=c(0))
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

@
\end_layout

\end_inset


\end_layout

\begin_layout Standard
Recall that 
\begin_inset Formula $\beta_{2}(\bm{s}),\dots,\beta_{5}(\bm{s})$
\end_inset

 are exactly zero across the entire domain.
 Oracle selection will estimate these coefficients perfectly, so we focus
 on the comparison between estimation by LAGR and by the VCR model with
 no selection.
 The MISE of the estimates of 
\begin_inset Formula $\beta_{2}(\bm{s}),\dots,\beta_{5}(\bm{s})$
\end_inset

 for each simulation setting are enumerated in Table 
\begin_inset CommandInset ref
LatexCommand ref
reference "tab:x2-x5-mise"

\end_inset

, which shows that for every simulation setting, LAGR selection and estimation
 is more accurate than the standard VCR model.
\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout

<<MISE-X2-X5, echo=FALSE, results='asis', message=FALSE>>=
\end_layout

\begin_layout Plain Layout

#Imports:
\end_layout

\begin_layout Plain Layout

require(xtable)
\end_layout

\begin_layout Plain Layout

require(brooks)
\end_layout

\begin_layout Plain Layout

load("~/scratch/gwr-sim-output.RData")
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

#Calculate the MISE for the first coefficient:
\end_layout

\begin_layout Plain Layout

mise.x2.x5 = matrix(0, nrow=0, ncol=2)
\end_layout

\begin_layout Plain Layout

for (setting in 1:18) {
\end_layout

\begin_layout Plain Layout

    #Get the proper coefficient surface
\end_layout

\begin_layout Plain Layout

    if (setting < 7) {B1 = step}
\end_layout

\begin_layout Plain Layout

    else if (setting < 13) {B1 = gradient}
\end_layout

\begin_layout Plain Layout

    else {B1 = parabola}
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

    #compute the MISE
\end_layout

\begin_layout Plain Layout

    row = sapply(c('lagr', 'gwr'),
\end_layout

\begin_layout Plain Layout

		function(selection.method) {
\end_layout

\begin_layout Plain Layout

			mean(sapply(c('X2','X3','X4','X5'), function(vv) {
\end_layout

\begin_layout Plain Layout

				output[[setting]][[selection.method]][[vv]]**2
\end_layout

\begin_layout Plain Layout

			}))
\end_layout

\begin_layout Plain Layout

		}
\end_layout

\begin_layout Plain Layout

	)
\end_layout

\begin_layout Plain Layout

    mise.x2.x5 = rbind(mise.x2.x5, row)
\end_layout

\begin_layout Plain Layout

}
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

#Which entries should be bolded (for having the lowest MISE)?
\end_layout

\begin_layout Plain Layout

bold = matrix(FALSE, nrow=nrow(mise.x2.x5), ncol=ncol(mise.x2.x5))
\end_layout

\begin_layout Plain Layout

for (i in 1:nrow(mise.x2.x5)){
\end_layout

\begin_layout Plain Layout

    bold[i,which.min(mise.x2.x5[i,])] = TRUE
\end_layout

\begin_layout Plain Layout

}
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

#Put names on the table
\end_layout

\begin_layout Plain Layout

rownames(mise.x2.x5) = NULL
\end_layout

\begin_layout Plain Layout

colnames(mise.x2.x5) = c("LAGR", "none")
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

#Generate the table, caption it, and print it with emphasis.
\end_layout

\begin_layout Plain Layout

mise.x2.x5.table = xtable(mise.x2.x5, digits=3)
\end_layout

\begin_layout Plain Layout

caption(mise.x2.x5.table) = "The MISE for the estimates of $
\backslash

\backslash
beta_2(
\backslash

\backslash
bm{s}),
\backslash

\backslash
dots,
\backslash

\backslash
beta_5(
\backslash

\backslash
bm{s})$ in each simulation setting, under variable selection via LAGR and
 no variable selection.
 Highlighting indicates the 
\backslash

\backslash
textbf{lowest} MISE."
\end_layout

\begin_layout Plain Layout

label(mise.x2.x5.table) = "tab:x2-x5-mise"
\end_layout

\begin_layout Plain Layout

xtable.printbold(mise.x2.x5.table, table.placement=NULL, which.bold=bold, hline.after=c
(0))
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

@
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout

<<PZERO, echo=FALSE, results='asis', message=FALSE>>=
\end_layout

\begin_layout Plain Layout

#Imports:
\end_layout

\begin_layout Plain Layout

require(xtable)
\end_layout

\begin_layout Plain Layout

require(brooks)
\end_layout

\begin_layout Plain Layout

load("~/scratch/gwr-sim-output.RData")
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

zz = vector()
\end_layout

\begin_layout Plain Layout

for (i in 1:18) {
\end_layout

\begin_layout Plain Layout

    zz = c(zz, mean(sapply(pzero, function(x) x[i])))
\end_layout

\begin_layout Plain Layout

}
\end_layout

\begin_layout Plain Layout

zz = matrix(zz)
\end_layout

\begin_layout Plain Layout

colnames(zz) = c("Frequency of exact zero")
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

#Generate the table, caption it, and print it with emphasis.
\end_layout

\begin_layout Plain Layout

pzero.table = xtable(zz)
\end_layout

\begin_layout Plain Layout

caption(pzero.table) = "Proportion of local models under each setting in
 which the coefficients $
\backslash

\backslash
beta_2(
\backslash

\backslash
bm{s}),
\backslash

\backslash
dots,
\backslash

\backslash
beta_5(
\backslash

\backslash
bm{s})$ are estimated as exactly zero."
\end_layout

\begin_layout Plain Layout

label(pzero.table) = "tab:pzero"
\end_layout

\begin_layout Plain Layout

print(pzero.table, table.placement=NULL, hline.after=c(0))
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

@
\end_layout

\end_inset


\end_layout

\begin_layout Standard
From Table 
\begin_inset CommandInset ref
LatexCommand ref
reference "tab:pzero"

\end_inset

 we see that LAGR has good ability to identify non-important predictors.
 The frequency with which 
\begin_inset Formula $\beta_{2}(\bm{s}),\dots,\beta_{5}(\bm{s})$
\end_inset

 were dropped from the LAGR models ranged from 
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
Sexpr{round(min(zz),2)}
\end_layout

\end_inset

 to 
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
Sexpr{round(max(zz),2)}
\end_layout

\end_inset

.
\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout

<<MISEY, echo=FALSE, results='asis', message=FALSE>>=
\end_layout

\begin_layout Plain Layout

#Imports:
\end_layout

\begin_layout Plain Layout

require(xtable)
\end_layout

\begin_layout Plain Layout

require(brooks)
\end_layout

\begin_layout Plain Layout

load("~/scratch/gwr-sim-output.RData")
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

std = matrix(rbind(c(0.25, 0.25, 0.25), c(1, 1, 1)), nrow=18, ncol=3)
\end_layout

\begin_layout Plain Layout

bold.misey = matrix(FALSE, nrow=nrow(mise), ncol=ncol(mise))
\end_layout

\begin_layout Plain Layout

for (i in 1:nrow(mise)){
\end_layout

\begin_layout Plain Layout

	bold.misey[i,which.min(abs(misey[i,] - std[i,]))] = TRUE
\end_layout

\begin_layout Plain Layout

}
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

#Which entries should be italicised (for having the second-lowest MISE)?
\end_layout

\begin_layout Plain Layout

ital.misey = matrix(FALSE, nrow=nrow(mise), ncol=ncol(mise))
\end_layout

\begin_layout Plain Layout

for (i in 1:nrow(mise)){
\end_layout

\begin_layout Plain Layout

	ital.misey[i,order(abs(misey[i,] - std[i,]))[2]] = TRUE
\end_layout

\begin_layout Plain Layout

}
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

#Put names on the table
\end_layout

\begin_layout Plain Layout

rownames(misey) = NULL
\end_layout

\begin_layout Plain Layout

colnames(misey) = c("LAGR", "none", "oracle")
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

#Generate the table, caption it, and print it with emphasis.
\end_layout

\begin_layout Plain Layout

misey.table = xtable(misey)
\end_layout

\begin_layout Plain Layout

caption(misey.table) = "The MISE for the fitted output in each simulation
 setting, under variable selection via LAGR, no variable selection, and
 oracular variable selection.
 Highlighting indicates the 
\backslash

\backslash
textbf{closest} and 
\backslash

\backslash
emph{next-closest} to the actual error variance $
\backslash

\backslash
sigma_
\backslash

\backslash
varepsilon^2$ for that setting."
\end_layout

\begin_layout Plain Layout

label(misey.table) = "tab:misey"
\end_layout

\begin_layout Plain Layout

xtable.printbold(misey.table, table.placement=NULL, which.bold=bold.misey, which.ital=
ital.misey, hline.after=c(0))
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

@
\end_layout

\end_inset


\end_layout

\begin_layout Standard
The MISE of the fitted 
\begin_inset Formula $\hat{y}(\bm{s})$
\end_inset

 is listed in Table 
\begin_inset CommandInset ref
LatexCommand ref
reference "tab:misey"

\end_inset

, where the highlighting is based on which methods estimate an error variance
 that is closest to the known truth for the simulation.
 The results are all very similar to each other, indicating that no method
 was consistently better than the others in this simulation at fitting the
 model output.
\end_layout

\begin_layout Subsection
Discussion
\end_layout

\begin_layout Standard
The proposed LAGR method was accurate in selection and estimation, with
 estimation accuracy for 
\begin_inset Formula $\beta_{1}(\bm{s})$
\end_inset

 about equal to that of the VCR model with no selection, and with consistently
 better accuracy for estimating 
\begin_inset Formula $\beta_{2}(\bm{s}),\dots,\beta_{5}(\bm{s})$
\end_inset

.
\end_layout

\begin_layout Standard
There was minimal difference in the performance of the proposed LAGR method
 between low (
\begin_inset Formula $\sigma_{\varepsilon}=0.5$
\end_inset

) and high (
\begin_inset Formula $\sigma_{\varepsilon}=1$
\end_inset

) error variance, and between no (
\begin_inset Formula $\rho=0$
\end_inset

) and moderate (
\begin_inset Formula $\rho=0.5$
\end_inset

) correlation among the predictor variables.
 But the selection and estimation accuracy did decline when there was high
 (
\begin_inset Formula $\rho=0.9$
\end_inset

) correlation among the predictor variables.
\end_layout

\begin_layout Section
Data example
\begin_inset CommandInset label
LatexCommand label
name "sec:example"

\end_inset


\end_layout

\begin_layout Standard
The proposed LAGR estimation method was used to estimate the coefficients
 in a VCR model of the effect of some covariates on the price of homes in
 Boston.
 The data source is the Boston house price data set of 
\begin_inset CommandInset citation
LatexCommand cite
key "Harrison-Rubinfeld-1978,Gilley-Pace-1996,Pace-Gilley-1997"

\end_inset

, which is based on the 1970 U.S.
 census.
 In the data, we have the median price of homes sold in 506 census tracts
 (MEDV), along with some potential predictor variables.
 The predictor variables are CRIM (the per-capita crime rate in the tract),
 RM (the mean number of rooms for houses sold in the tract), RAD (an index
 of how accessible the tract is from Boston's radial roads), TAX (the property
 tax per $10,000 of property value), and LSTAT (the percentage of the tract's
 residents who are considered 
\begin_inset Quotes eld
\end_inset

lower status
\begin_inset Quotes erd
\end_inset

).
\end_layout

\begin_layout Standard
The bandwidth parameter was set to 0.2 for a nearest neighbors-type bandwidth,
 meaning that the sum of kernel weights for each local model was 20% of
 the total number of observations.
 The kernel used was the Epanechnikov kernel.
\end_layout

\begin_layout Subsection
Results
\end_layout

\begin_layout Standard
Estimates of the regression coefficients are plotted in Figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:boston-lagr-coefs"

\end_inset

.
\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
begin{figure}
\end_layout

\begin_layout Plain Layout

<<boston-plots, echo=FALSE, results='asis', message=FALSE>>=
\end_layout

\begin_layout Plain Layout

require(brooks)
\end_layout

\begin_layout Plain Layout

load("~/git/gwr/scratch/boston-preset-bw.RData")
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

bmap = list()
\end_layout

\begin_layout Plain Layout

for (v in c('CRIM', 'RM', 'RAD', 'TAX', 'LSTAT')) {
\end_layout

\begin_layout Plain Layout

    bmap[[v]] = ggplot(boston.map) +
\end_layout

\begin_layout Plain Layout

        aes(x=PolyCoordsY, y=PolyCoordsX, group=Poly_Name) +
\end_layout

\begin_layout Plain Layout

        aes_string(fill=paste('coef', v, sep='')) +
\end_layout

\begin_layout Plain Layout

        geom_polygon() +
\end_layout

\begin_layout Plain Layout

        scale_fill_gradient2(low='orange', mid='white', high="purple", midpoint=
0) +
\end_layout

\begin_layout Plain Layout

        xlab("longitude") +
\end_layout

\begin_layout Plain Layout

        ylab("latitude")
\end_layout

\begin_layout Plain Layout

}
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

multiplot(plotlist=bmap, cols=2)
\end_layout

\begin_layout Plain Layout

@
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout


\backslash
caption{The coefficients for the boston house price data as estimated by
 LAGR.
\backslash
label{fig:boston-lagr-coefs}}
\end_layout

\begin_layout Plain Layout


\backslash
end{figure}
\end_layout

\end_inset


\end_layout

\begin_layout Standard
One interesting result is that LAGR indicates that the TAX variable was
 nowhere an important predictor of the median house price.
 Another is that the coefficients of CRIM and LSTAT are everywhere negative
 or zero (meaning that the increasing the crime rate or proportion of lower-stat
us individuals reduces the median house price where the effect is discernable)
 and that of RM is positive (meaning that when the average house in a tract
 has more rooms, the median house will be more expensive), but the coefficient
 of RAD is positive in some areas and negative in others.
 This indicates that there are parts of Boston where improved access to
 radial roads increases the median house price and parts where it decreases
 the median house price.
\end_layout

\begin_layout Standard
There is not an obvious spatial pattern to the local coefficients for RAD
 - there are more tracts with negative coefficients than positive, and the
 positive coefficients do appear to be clustered, but the tracts with positive
 coefficients are also adjacent to tracts with negative coefficients.
 Indeed, there is not an obvious spatial pattern to any of the coefficient
 surfaces except for TAX, which is zero everywhere.
\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout

<<boston-coef-table, echo=FALSE, results='asis', message=FALSE>>=
\end_layout

\begin_layout Plain Layout

require(xtable)
\end_layout

\begin_layout Plain Layout

require(brooks)
\end_layout

\begin_layout Plain Layout

load("~/git/gwr/scratch/boston-preset-bw.RData")
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

vars = c('CRIM', 'RM', 'RAD', 'TAX', 'LSTAT')
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

boston.coef.summary = matrix(NA, nrow=0, ncol=3)
\end_layout

\begin_layout Plain Layout

for (v in vars) {
\end_layout

\begin_layout Plain Layout

	row = vector()
\end_layout

\begin_layout Plain Layout

	colname.coef = paste("coef", v, sep="")
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

	#Add the table's elements to this row:
\end_layout

\begin_layout Plain Layout

	row = c(row, mean(boston.tracts@data[,colname.coef]))
\end_layout

\begin_layout Plain Layout

	row = c(row, sd(boston.tracts@data[,colname.coef]))
\end_layout

\begin_layout Plain Layout

	row = c(row, mean(boston.tracts@data[,colname.coef]==0))
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

	#Add this row to the table:
\end_layout

\begin_layout Plain Layout

	boston.coef.summary = rbind(boston.coef.summary, row)
\end_layout

\begin_layout Plain Layout

}
\end_layout

\begin_layout Plain Layout

rownames(boston.coef.summary) = vars
\end_layout

\begin_layout Plain Layout

colnames(boston.coef.summary) = c('Mean', 'SD', 'Prop.
 zero')
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

#Generate the table, caption it, and print it with emphasis.
\end_layout

\begin_layout Plain Layout

boston.coef.table = xtable(boston.coef.summary)
\end_layout

\begin_layout Plain Layout

caption(boston.coef.table) = "The mean, standard deviation, and proportion
 of zeros among the local coefficients in a model for the median house price
 in census tracts in Boston, with coefficients selected and fitted by LAGR."
\end_layout

\begin_layout Plain Layout

label(boston.coef.table) = "tab:boston-coefs-lagr"
\end_layout

\begin_layout Plain Layout

print(boston.coef.table, table.placement=NULL, hline.after=c(0))
\end_layout

\begin_layout Plain Layout

@
\end_layout

\end_inset


\end_layout

\begin_layout Standard
A summary of the local coefficients is in Table 
\begin_inset CommandInset ref
LatexCommand ref
reference "tab:boston-coefs-lagr"

\end_inset

.
 It indicates that RM is the only predictor variable with a positive mean
 of the local coefficients, but also that the mean of the local coefficients
 of RM is the largest coefficient - at 
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
Sexpr{round(boston.coef.summary['RM','Mean'],2)}
\end_layout

\end_inset

, it is more than twice as large in magnitude as the mean local coefficient
 of LSTAT (
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
Sexpr{round(boston.coef.summary['LSTAT','Mean'],2)}
\end_layout

\end_inset

), which is second-largest.
\end_layout

\begin_layout Standard
The coefficient of the CRIM variable was estimated to be exactly zero at
 
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
Sexpr{100*round(boston.coef.summary['CRIM','Prop.
 zero'],2)}
\end_layout

\end_inset

% of the locations.
 The percentage for the RAD variable was 
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
Sexpr{100*round(boston.coef.summary['RAD','Prop.
 zero'],2)}
\end_layout

\end_inset

%.
\end_layout

\begin_layout Standard
In their example using the same data, 
\begin_inset CommandInset citation
LatexCommand cite
key "Sun-Yan-Zhang-Lu-2014"

\end_inset

 estimated that the coefficients of RAD annd LSTAT should be constant, at
 0.36 and -0.45, respectively.
 That conclusion differs from our result, which says that the mean local
 coefficient of RAD is actually negative (
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
Sexpr{round(boston.coef.summary['RAD','Mean'],2)}
\end_layout

\end_inset

), while our mean fitted local coefficient for LSTAT was more negative than
 the estimate of 
\begin_inset CommandInset citation
LatexCommand cite
key "Sun-Yan-Zhang-Lu-2014"

\end_inset

.
\end_layout

\begin_layout Section
\start_of_appendix
Proofs of theorems
\begin_inset CommandInset label
LatexCommand label
name "app:proofs"

\end_inset

 
\end_layout

\begin_layout Proof
\begin_inset Argument 1
status open

\begin_layout Plain Layout
Proof of theorem 
\begin_inset CommandInset ref
LatexCommand ref
reference "theorem:normality"

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
Define 
\begin_inset Formula $V_{4}^{(n)}(\bm{u})$
\end_inset

 to be the 
\begin_inset Formula 
\begin{align}
\mkern-36muV_{4}^{(n)}(\bm{u}) & =Q\left\{ \bm{\zeta}(\bm{s})+h^{-1}n^{-1/2}\bm{u}\right\} -Q\left\{ \bm{\zeta}(\bm{s})\right\} \notag\label{eq:consistency}\\
 & \mkern-36mu=(1/2)\left[\bm{Y}-\bm{Z}(\bm{s})\left\{ \bm{\zeta}(\bm{s})+h^{-1}n^{-1/2}\bm{u}\right\} \right]^{T}\bm{W}(\bm{s})\left[\bm{Y}-\bm{Z}(\bm{s})\left\{ \bm{\zeta}(\bm{s})+h^{-1}n^{-1/2}\bm{u}\right\} \right]\notag\\
 & +\sum_{j=1}^{p}\phi_{j}(\bm{s})\|\bm{\zeta}_{j}(\bm{s})+h^{-1}n^{-1/2}\bm{u}_{j}\|\notag\\
 & -(1/2)\left\{ \bm{Y}-\bm{Z}(\bm{s})\bm{\zeta}(\bm{s})\right\} ^{T}\bm{W}(\bm{s})\left\{ \bm{Y}-\bm{Z}(\bm{s})\bm{\zeta}(\bm{s})\right\} -\sum_{j=1}^{p}\phi_{j}(\bm{s})\|\bm{\zeta}_{j}(\bm{s})\|\notag\\
 & \mkern-36mu=(1/2)\bm{u}^{T}\left\{ h^{-2}n^{-1}\bm{Z}^{T}(\bm{s})\bm{W}(\bm{s})\bm{Z}(\bm{s})\right\} \bm{u}-\bm{u}^{T}\left[h^{-1}n^{-1/2}\bm{Z}^{T}(\bm{s})\bm{W}(\bm{s})\left\{ \bm{Y}-\bm{Z}(\bm{s})\bm{\zeta}(\bm{s})\right\} \right]\notag\\
 & +\sum_{j=1}^{p}n^{-1/2}\phi_{j}(\bm{s})n^{1/2}\left\{ \|\bm{\zeta}_{j}(\bm{s})+h^{-1}n^{-1/2}\bm{u}_{j}\|-\|\bm{\zeta}_{j}(\bm{s})\|\right\} 
\end{align}

\end_inset


\end_layout

\begin_layout Standard
Note the different limiting behavior of the third term between the cases
 
\begin_inset Formula $j\le p_{0}$
\end_inset

 and 
\begin_inset Formula $j>p_{0}$
\end_inset

:
\end_layout

\begin_layout Paragraph
Case 
\begin_inset Formula $j\le p_{0}$
\end_inset


\end_layout

\begin_layout Standard
If 
\begin_inset Formula $j\le p_{0}$
\end_inset

 then 
\begin_inset Formula $n^{-1/2}\phi_{j}(\bm{s})\to n^{-1/2}\lambda_{n}(\bm{s})\|\bm{\zeta}_{j}(\bm{s})\|^{-\gamma}$
\end_inset

 and 
\begin_inset Formula $|\sqrt{n}\left\{ \|\bm{\zeta}_{j}(\bm{s})+h^{-1}n^{-1/2}\bm{u}_{j}\|-\|\bm{\zeta}_{j}(\bm{s})\|\right\} |\le h^{-1}\|\bm{u}_{j}\|$
\end_inset

 so 
\begin_inset Formula 
\[
\lim\limits _{n\to\infty}\phi_{j}(\bm{s})\left(\|\bm{\zeta}_{j}(\bm{s})+h^{-1}n^{-1/2}\bm{u}_{j}\|-\|\bm{\zeta}_{j}(\bm{s})\|\right)\le h^{-1}n^{-1/2}\phi_{j}(\bm{s})\|\bm{u}_{j}\|\le h^{-1}n^{-1/2}a_{n}\|\bm{u}_{j}\|\to0
\]

\end_inset


\end_layout

\begin_layout Paragraph
Case 
\begin_inset Formula $j>p_{0}$
\end_inset


\end_layout

\begin_layout Standard
If 
\begin_inset Formula $j>p_{0}$
\end_inset

 then 
\begin_inset Formula $\phi_{j}(\bm{s})\left(\|\bm{\zeta}_{j}(\bm{s})+h^{-1}n^{-1/2}\bm{u}_{j}\|-\|\bm{\zeta}_{j}(\bm{s})\|\right)=\phi_{j}(\bm{s})h^{-1}n^{-1/2}\|\bm{u}_{j}\|$
\end_inset

.
\end_layout

\begin_layout Standard
And note that 
\begin_inset Formula $h=O(n^{-1/6})$
\end_inset

 so that if 
\begin_inset Formula $hn^{-1/2}b_{n}\xrightarrow{p}\infty$
\end_inset

 then 
\begin_inset Formula $h^{-1}n^{-1/2}b_{n}\xrightarrow{p}\infty$
\end_inset

.
\end_layout

\begin_layout Standard
Now, if 
\begin_inset Formula $\|\bm{u}_{j}\|\ne0$
\end_inset

 then 
\begin_inset Formula 
\[
h^{-1}n^{-1/2}\phi_{j}(\bm{s})\|\bm{u}_{j}\|\ge h^{-1}n^{-1/2}b_{n}\|\bm{u}_{j}\|\to\infty
\]

\end_inset

.
 On the other hand, if 
\begin_inset Formula $\|\bm{u}_{j}\|=0$
\end_inset

 then 
\begin_inset Formula $h^{-1}n^{-1/2}\phi_{j}(\bm{s})\|\bm{u}_{j}\|=0$
\end_inset

.
\end_layout

\begin_layout Standard
Thus, the limit of 
\begin_inset Formula $V_{4}^{(n)}(\bm{u})$
\end_inset

 is the same as the limit of 
\begin_inset Formula $V_{4}^{*(n)}(\bm{u})$
\end_inset

 where
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
\mkern-72muV_{4}^{*(n)}(\bm{u})=\begin{cases}
(1/2)\bm{u}^{T}\left\{ h^{-2}n^{-1}\bm{Z}^{T}(\bm{s})\bm{W}(\bm{s})\bm{Z}(\bm{s})\right\} \bm{u}-\bm{u}^{T}\left[h^{-1}n^{-1/2}\bm{Z}^{T}(\bm{s})\bm{W}(\bm{s})\left\{ \bm{Y}-\bm{Z}(\bm{s})\bm{\zeta}(\bm{s})\right\} \right] & \mbox{ if }\|\bm{u}_{j}\|=0\;\forall j>p_{0}\\
\infty & \mbox{ otherwise }
\end{cases}.
\]

\end_inset


\end_layout

\begin_layout Standard
From which it is clear that 
\begin_inset Formula $V_{4}^{*(n)}(\bm{u})$
\end_inset

 is convex and its unique minimizer is 
\begin_inset Formula $\hat{\bm{u}}^{(n)}$
\end_inset

:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{align}
0 & =\left\{ h^{-2}n^{-1}\bm{Z}^{T}(\bm{s})\bm{W}(\bm{s})\bm{Z}(\bm{s})\right\} \hat{\bm{u}}^{(n)}-\left[h^{-1}n^{-1/2}\bm{Z}^{T}(\bm{s})\bm{W}(\bm{s})\left\{ \bm{Y}-\bm{Z}(\bm{s})\bm{\zeta}(\bm{s})\right\} \right]\notag\label{eq:limit}\\
\therefore\hat{\bm{u}}^{(n)} & =\left\{ n^{-1}\bm{Z}^{T}(\bm{s})\bm{W}(\bm{s})\bm{Z}(\bm{s})\right\} ^{-1}\left[hn^{-1/2}\bm{Z}^{T}(\bm{s})\bm{W}(\bm{s})\left\{ \bm{Y}-\bm{Z}(\bm{s})\bm{\zeta}(\bm{s})\right\} \right]\notag\\
\end{align}

\end_inset


\end_layout

\begin_layout Standard
By the epiconvergence results of 
\begin_inset CommandInset citation
LatexCommand citet
key "Geyer-1994"

\end_inset

 and 
\begin_inset CommandInset citation
LatexCommand citet
key "Knight-Fu-2000"

\end_inset

, the minimizer of the limiting function is the limit of the minimizers
 
\begin_inset Formula $\hat{\bm{u}}^{(n)}$
\end_inset

.
 And since, by Lemma 2 of 
\begin_inset CommandInset citation
LatexCommand citet
key "Sun-Yan-Zhang-Lu-2014"

\end_inset

,
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{equation}
\hat{\bm{u}}^{(n)}\xrightarrow{d}N\left(\frac{\kappa_{2}h^{2}}{2\kappa_{0}}\{\nabla_{uu}^{2}\bm{\zeta}_{j}(\bm{s})+\nabla_{vv}^{2}\bm{\zeta}_{j}(\bm{s})\},f(\bm{s})\kappa_{0}^{-2}\nu_{0}\sigma^{2}\Psi^{-1}\right)
\end{equation}

\end_inset

the result is proven.
\end_layout

\begin_layout Proof
\begin_inset Argument 1
status open

\begin_layout Plain Layout
Proof of theorem 
\begin_inset CommandInset ref
LatexCommand ref
reference "theorem:selection"

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Proof
We showed in Theorem 
\begin_inset CommandInset ref
LatexCommand ref
reference "theorem:normality"

\end_inset

 that 
\begin_inset Formula $\hat{\bm{\zeta}}_{j}(\bm{s})\xrightarrow{p}\bm{\zeta}_{j}(\bm{s})+\frac{\kappa_{2}h^{2}}{2\kappa_{0}}\{\nabla_{uu}^{2}\bm{\zeta}_{j}(\bm{s})+\nabla_{vv}^{2}\bm{\zeta}_{j}(\bm{s})\}$
\end_inset

, so to complete the proof of selection consistency, it only remains to
 show that 
\begin_inset Formula $P\left\{ \hat{\bm{\zeta}}_{j}(\bm{s})=0\right\} \to1$
\end_inset

 if 
\begin_inset Formula $j>p_{0}$
\end_inset

.
\end_layout

\begin_layout Standard
The proof is by contradiction.
 Without loss of generality we consider only the case 
\begin_inset Formula $j=p$
\end_inset

.
\end_layout

\begin_layout Standard
Assume 
\begin_inset Formula $\|\hat{\bm{\zeta}}_{p}(\bm{s})\|\ne0$
\end_inset

.
 Then 
\begin_inset Formula $Q\left\{ \bm{\zeta}(\bm{s})\right\} $
\end_inset

 is differentiable w.r.t.
 
\begin_inset Formula $\bm{\zeta}_{p}(\bm{s})$
\end_inset

 and is minimized where 
\begin_inset Formula 
\begin{align}
0 & =\bm{Z}_{p}^{T}(\bm{s})\bm{W}(\bm{s})\left\{ \bm{Y}-\bm{Z}_{-p}(\bm{s})\hat{\bm{\zeta}}_{-p}(\bm{s})-\bm{Z}_{p}(\bm{s})\hat{\bm{\zeta}}_{p}(\bm{s})\right\} -\phi_{p}(\bm{s})\frac{\hat{\bm{\zeta}}_{p}(\bm{s})}{\|\hat{\bm{\zeta}}_{p}(\bm{s})\|}\notag\\
 & =\bm{Z}_{p}^{T}(\bm{s})\bm{W}(\bm{s})\left[\bm{Y}-\bm{Z}(\bm{s})\bm{\zeta}(\bm{s})-\frac{h^{2}\kappa_{2}}{2\kappa_{0}}\left\{ \nabla_{uu}^{2}\bm{\zeta}(\bm{s})+\nabla_{vv}^{2}\bm{\zeta}(\bm{s})\right\} \right]\notag\\
 & \mkern+72mu+\bm{Z}_{p}^{T}(\bm{s})\bm{W}(\bm{s})\bm{Z}_{-p}(\bm{s})\left[\bm{\zeta}_{-p}(\bm{s})+\frac{h^{2}\kappa_{2}}{2\kappa_{0}}\left\{ \nabla_{uu}^{2}\bm{\zeta}_{-p}(\bm{s})+\nabla_{vv}^{2}\bm{\zeta}_{-p}(\bm{s})\right\} -\hat{\bm{\zeta}}_{-p}(\bm{s})\right]\notag\\
 & \mkern+72mu+\bm{Z}_{p}^{T}(\bm{s})\bm{W}(\bm{s})\bm{Z}_{p}(\bm{s})\left[\bm{\zeta}_{p}(\bm{s})+\frac{h^{2}\kappa_{2}}{2\kappa_{0}}\left\{ \nabla_{uu}^{2}\bm{\zeta}_{p}(\bm{s})+\nabla_{vv}^{2}\bm{\zeta}_{p}(\bm{s})\right\} -\hat{\bm{\zeta}}_{p}(\bm{s})\right]\notag\\
 & \mkern+72mu-\phi_{p}(\bm{s})\frac{\hat{\bm{\zeta}}_{p}(\bm{s})}{\|\hat{\bm{\zeta}}_{p}(\bm{s})\|}\notag\\
\end{align}

\end_inset


\end_layout

\begin_layout Standard
So 
\begin_inset Formula 
\begin{align}
\frac{h}{\sqrt{n}}\phi_{p}(\bm{s})\frac{\hat{\bm{\zeta}}_{p}(\bm{s})}{\|\hat{\bm{\zeta}}_{p}(\bm{s})\|} & =\bm{Z}_{p}^{T}(\bm{s})\bm{W}(\bm{s})\frac{h}{\sqrt{n}}\left[\bm{Y}-\bm{Z}(\bm{s})\bm{\zeta}(\bm{s})-\frac{h^{2}\kappa_{2}}{2\kappa_{0}}\left\{ \nabla_{uu}^{2}\bm{\zeta}(\bm{s})+\nabla_{vv}^{2}\bm{\zeta}(\bm{s})\right\} \right]\notag\label{eq:selection}\\
 & +\left\{ n^{-1}\bm{Z}_{p}^{T}(\bm{s})\bm{W}(\bm{s})\bm{Z}_{-p}(\bm{s})\right\} h\sqrt{n}\left[\bm{\zeta}_{-p}(\bm{s})+\frac{h^{2}\kappa_{2}}{2\kappa_{0}}\left\{ \nabla_{uu}^{2}\bm{\zeta}_{-p}(\bm{s})+\nabla_{vv}^{2}\bm{\zeta}_{-p}(\bm{s})\right\} -\hat{\bm{\zeta}}_{-p}(\bm{s})\right]\notag\\
 & +\left\{ n^{-1}\bm{Z}_{p}^{T}(\bm{s})\bm{W}(\bm{s})\bm{Z}_{p}(\bm{s})\right\} h\sqrt{n}\left[\bm{\zeta}_{p}(\bm{s})+\frac{h^{2}\kappa_{2}}{2\kappa_{0}}\left\{ \nabla_{uu}^{2}\bm{\zeta}_{p}(\bm{s})+\nabla_{vv}^{2}\bm{\zeta}_{p}(\bm{s})\right\} -\hat{\bm{\zeta}}_{p}(\bm{s})\right]
\end{align}

\end_inset


\end_layout

\begin_layout Standard
From Lemma 2 of 
\begin_inset CommandInset citation
LatexCommand citet
key "Sun-Yan-Zhang-Lu-2014"

\end_inset

, 
\begin_inset Formula $\left\{ n^{-1}\bm{Z}_{p}^{T}(\bm{s})\bm{W}(\bm{s})\bm{Z}_{-p}(\bm{s})\right\} =O_{p}(1)$
\end_inset

 and 
\begin_inset Formula $\left\{ n^{-1}\bm{Z}_{p}^{T}(\bm{s})\bm{W}(\bm{s})\bm{Z}_{p}(\bm{s})\right\} =O_{p}(1)$
\end_inset

.
\end_layout

\begin_layout Standard
From Theorem 3 of 
\begin_inset CommandInset citation
LatexCommand citet
key "Sun-Yan-Zhang-Lu-2014"

\end_inset

, we have that 
\begin_inset Formula $h\sqrt{n}\left[\hat{\bm{\zeta}}_{-p}(\bm{s})-\bm{\zeta}_{-p}(\bm{s})-\frac{h^{2}\kappa_{2}}{2\kappa_{0}}\left\{ \nabla_{uu}^{2}\zeta_{-p}(\bm{s})+\nabla_{vv}^{2}\zeta_{-p}(\bm{s})\right\} \right]=O_{p}(1)$
\end_inset

 and 
\begin_inset Formula $h\sqrt{n}\left[\hat{\bm{\zeta}}_{p}(\bm{s})-\bm{\zeta}_{p}(\bm{s})-\frac{h^{2}\kappa_{2}}{2\kappa_{0}}\left\{ \nabla_{uu}^{2}\zeta_{p}(\bm{s})+\nabla_{vv}^{2}\zeta_{p}(\bm{s})\right\} \right]=O_{p}(1)$
\end_inset

.
\end_layout

\begin_layout Standard
So the second and third terms of the sum in (
\begin_inset CommandInset ref
LatexCommand ref
reference "eq:selection"

\end_inset

) are 
\begin_inset Formula $O_{p}(1)$
\end_inset

.
\end_layout

\begin_layout Standard
We showed in the proof of 
\begin_inset CommandInset ref
LatexCommand ref
reference "theorem:normality"

\end_inset

 that 
\begin_inset Formula $h\sqrt{n}\bm{Z}_{p}^{T}(\bm{s})\bm{W}(\bm{s})\left[\bm{Y}-\bm{Z}(\bm{s})\bm{\zeta}(\bm{s})-\frac{h^{2}\kappa_{2}}{2\kappa_{0}}\left\{ \nabla_{uu}^{2}\bm{\zeta}(\bm{s})+\nabla_{vv}^{2}\bm{\zeta}(\bm{s})\right\} \right]=O_{p}(1)$
\end_inset

.
\end_layout

\begin_layout Standard
The three terms of the sum to the right of the equals sign in (
\begin_inset CommandInset ref
LatexCommand ref
reference "eq:selection"

\end_inset

) are 
\begin_inset Formula $O_{p}(1)$
\end_inset

, so for 
\begin_inset Formula $\hat{\bm{\zeta}}_{p}(\bm{s})$
\end_inset

 to be a solution, we must have that 
\begin_inset Formula $hn^{-1/2}\phi_{p}(\bm{s})\hat{\bm{\zeta}}_{p}(\bm{s})/\|\hat{\bm{\zeta}}_{p}(\bm{s})\|=O_{p}(1)$
\end_inset

.
\end_layout

\begin_layout Standard
But since by assumption 
\begin_inset Formula $\hat{\bm{\zeta}}_{p}(\bm{s})\ne0$
\end_inset

, there must be some 
\begin_inset Formula $k\in\{1,\dots,3\}$
\end_inset

 such that 
\begin_inset Formula $|\hat{\zeta}_{p_{k}}(\bm{s})|=\max\{|\hat{\zeta}_{p_{k'}}(\bm{s})|:1\le k'\le3\}$
\end_inset

.
 And for this 
\begin_inset Formula $k$
\end_inset

, we have that 
\begin_inset Formula $|\hat{\zeta}_{p_{k}}(\bm{s})|/\|\hat{\bm{\zeta}}_{p}(\bm{s})\|\ge1/\sqrt{3}>0$
\end_inset

.
\end_layout

\begin_layout Standard
Now since 
\begin_inset Formula $hn^{-1/2}b_{n}\to\infty$
\end_inset

, we have that 
\begin_inset Formula $hn^{-1/2}\phi_{p}(\bm{s})\hat{\bm{\zeta}}_{p}(\bm{s})/\|\hat{\bm{\zeta}}_{p}(\bm{s})\|\ge hb_{n}/\sqrt{3n}\to\infty$
\end_inset

 and therefore the term to the left of the equals sign dominates the sum
 to the right of the equals sign in (
\begin_inset CommandInset ref
LatexCommand ref
reference "eq:selection"

\end_inset

).
 So for large enough 
\begin_inset Formula $n$
\end_inset

, 
\begin_inset Formula $\hat{\bm{\zeta}}_{p}(\bm{s})\ne0$
\end_inset

 cannot maximize 
\begin_inset Formula $Q$
\end_inset

.
\end_layout

\begin_layout Standard
So 
\begin_inset Formula $P\left\{ \hat{\bm{\zeta}}_{(b)}(\bm{s})=0\right\} \to1$
\end_inset

.
 
\end_layout

\begin_layout Standard
\begin_inset CommandInset bibtex
LatexCommand bibtex
bibfiles "/Users/wesley/git/gwr/references/gwr"
options "chicago"

\end_inset


\end_layout

\end_body
\end_document
