#LyX 2.1 created this file. For more info see http://www.lyx.org/
\lyxformat 474
\begin_document
\begin_header
\textclass article
\begin_preamble
\usepackage{multirow}
\end_preamble
\use_default_options true
\begin_modules
theorems-ams-bytype
natbibapa
knitr
\end_modules
\maintain_unincluded_children false
\language english
\language_package default
\inputencoding auto
\fontencoding global
\font_roman default
\font_sans default
\font_typewriter default
\font_math auto
\font_default_family default
\use_non_tex_fonts false
\font_sc false
\font_osf false
\font_sf_scale 100
\font_tt_scale 100
\graphics default
\default_output_format default
\output_sync 0
\bibtex_command bibtex
\index_command default
\paperfontsize 12
\spacing double
\use_hyperref false
\papersize default
\use_geometry false
\use_package amsmath 1
\use_package amssymb 1
\use_package cancel 1
\use_package esint 1
\use_package mathdots 1
\use_package mathtools 1
\use_package mhchem 1
\use_package stackrel 1
\use_package stmaryrd 1
\use_package undertilde 2
\cite_engine natbib
\cite_engine_type authoryear
\biblio_style plain
\use_bibtopic false
\use_indices false
\paperorientation portrait
\suppress_date false
\justification true
\use_refstyle 1
\index Index
\shortcut idx
\color #008000
\end_index
\secnumdepth 3
\tocdepth 3
\paragraph_separation skip
\defskip bigskip
\quotes_language english
\papercolumns 1
\papersides 1
\paperpagestyle default
\tracking_changes false
\output_changes false
\html_math_output 0
\html_css_as_file 0
\html_be_strict false
\end_header

\begin_body

\begin_layout Title
Local Adaptive Grouped Regularization and its Oracle Properties
\end_layout

\begin_layout Author
Wesley Brooks, Jun Zhu, Zudi Lu
\end_layout

\begin_layout Section
Introduction
\end_layout

\begin_layout Standard
Whereas the coefficients in traditional linear regression are scalar constants,
 the coefficients in a varying coefficients regression (VCR) model are functions
 - often 
\emph on
smooth
\emph default
 functions - of some effect-modifying variable 
\begin_inset CommandInset citation
LatexCommand citep
key "Hastie:1993a,Cleveland-Grosse-1991"

\end_inset

.
\end_layout

\begin_layout Standard
Current practice for VCR models relies on global model selection to decide
 which variables should be included in the model, meaning that predictors
 are identified as relevant or irrelevant over the entire domain 
\begin_inset Formula $\mathcal{D}$
\end_inset

.
 
\begin_inset CommandInset citation
LatexCommand citet
key "Antoniadis:2012a"

\end_inset

 describe a method for globally selecting the relevant predictors in a VCR
 model where the coefficient functions are estimated with P-splines.
 
\begin_inset CommandInset citation
LatexCommand citet
key "Wang-2008a"

\end_inset

 show a method for doing global variable selection in a VCR model where
 the coefficient functions are estimated by basis expansion.
\end_layout

\begin_layout Standard
Local adaptive grouped regularization (LAGR) is developed here as a method
 to select only the locally relevant predictors at any specific location
 
\begin_inset Formula $\bm{s}$
\end_inset

 in the domain 
\begin_inset Formula $\mathcal{D}$
\end_inset

 of a VCR model.
 The method of LAGR applies to VCR models where the coefficients are estimated
 using locally linear kernel smoothing.
\end_layout

\begin_layout Standard
Using kernel smoothing for nonparametric regression is described in detail
 in 
\begin_inset CommandInset citation
LatexCommand citet*
key "Fan-Gijbels-1996"

\end_inset

.
 The extension to estimating VCR models is made by 
\begin_inset CommandInset citation
LatexCommand citet
key "Fan-Zhang-1999"

\end_inset

 for a VCR a univariate effect-modifying variable, and by 
\begin_inset CommandInset citation
LatexCommand citet
key "Sun-Yan-Zhang-Lu-2014"

\end_inset

 for two-dimensional effect-modifying variable and autocorrelation among
 the obverved response.
 These methods minimize the boundary effect 
\begin_inset CommandInset citation
LatexCommand citep
key "Hastie:1993b"

\end_inset

 by estimating the coefficients as local polynomials of odd degree (usually
 locally linear).
\end_layout

\begin_layout Standard
For linear regression models, the adaptive lasso (AL) 
\begin_inset CommandInset citation
LatexCommand citep
key "Zou-2006"

\end_inset

 produces consistent estimates of the coefficients and has been shown to
 have appealing properties for automating variable selection, which under
 suitable conditions include the 
\begin_inset Quotes eld
\end_inset

oracle
\begin_inset Quotes erd
\end_inset

 property of asymptotically including exactly the correct set of covariates
 and estimating their coefficients as well as if the correct covariates
 were known in advance.
 For data where the obvserved variables fall into mutually exclusive groups
 that are known in advance, the adaptive group lasso 
\begin_inset CommandInset citation
LatexCommand citep
key "Yuan-Lin-2006,Wang-Leng-2008"

\end_inset

 has similar oracle properties to the adaptive lasso while doing selection
 at the level of groups rather than individual variables.
 The proposed LAGR method uses the adaptive group lasso for local variable
 selection and coefficient estimation in a locally linear regression model.
 We show that LAGR posesses the oracle properties of asymptotically selecting
 exactly the correct local covariates and estimating their local coefficients
 as accurately as would be possible if the identity of the nonzero coefficients
 for the local model were known in advance.
\end_layout

\begin_layout Standard
The remainder of this document is organized as follows.
 The kernel-based VCR model is described in Section 
\begin_inset CommandInset ref
LatexCommand ref
reference "sec:vcr"

\end_inset

; the proposed LAGR technique and its oracle properties are presented in
 Section 
\begin_inset CommandInset ref
LatexCommand ref
reference "sec:lagr-gaussian"

\end_inset

; in Section 
\begin_inset CommandInset ref
LatexCommand ref
reference "sec:simulations"

\end_inset

, the performance of the proposed LAGR technique is evaluated in a simulation
 study, and in Section 
\begin_inset CommandInset ref
LatexCommand ref
reference "sec:example"

\end_inset

 the proposed method is applied to the Boston house price dataset.
 Proofs of the theorems appear in Appendix 
\begin_inset CommandInset ref
LatexCommand ref
reference "sec:gaussian-normality-proof"

\end_inset

.
\end_layout

\begin_layout Section
Varying coefficients regression
\begin_inset CommandInset label
LatexCommand label
name "sec:vcr"

\end_inset


\end_layout

\begin_layout Subsection
Model
\end_layout

\begin_layout Standard
Consider 
\begin_inset Formula $n$
\end_inset

 data points, observed at sampling locations 
\begin_inset Formula $\bm{s}_{i}=(s_{i,1},\; s_{i,2})^{T}$
\end_inset

 for 
\begin_inset Formula $i=1,\dots,n$
\end_inset

, which are distributed in a spatial domain 
\begin_inset Formula $\mathcal{D}\subset\mathbb{R}^{2}$
\end_inset

 according to a density 
\begin_inset Formula $f(\bm{s})$
\end_inset

 with 
\begin_inset Formula $\bm{s}\in\mathcal{D}$
\end_inset

.
 For 
\begin_inset Formula $i=1,\dots,n$
\end_inset

, let 
\begin_inset Formula $y(\bm{s}_{i})$
\end_inset

 and 
\begin_inset Formula $\bm{x}(\bm{s}_{i})$
\end_inset

 denote, respectively, the univariate response and the 
\begin_inset Formula $(p+1)$
\end_inset

-variate vector of covariates measured at location 
\begin_inset Formula $\bm{s}_{i}$
\end_inset

.
 At each location 
\begin_inset Formula $\bm{s}_{i}$
\end_inset

, assume that the outcome is related to the covariates by a linear regression
 where the coefficients 
\begin_inset Formula $\bm{\beta}(\bm{s}_{i})$
\end_inset

 are functions in two dimensions and 
\begin_inset Formula $\varepsilon(\bm{s}_{i})$
\end_inset

 is random error at location 
\begin_inset Formula $\bm{s}_{i}$
\end_inset

.
 That is, 
\begin_inset Formula 
\begin{align}
y(\bm{s}_{i})=\bm{x}(\bm{s}_{i})'\bm{\beta}(\bm{s}_{i})+\varepsilon(\bm{s}_{i}).\label{eq:lm(s)}
\end{align}

\end_inset


\end_layout

\begin_layout Standard
Further assume that the error term 
\begin_inset Formula $\varepsilon(\bm{s}_{i})$
\end_inset

 is normally distributed with zero mean and variance 
\begin_inset Formula $\sigma^{2}$
\end_inset

, and that 
\begin_inset Formula $\varepsilon(\bm{s}_{i})$
\end_inset

, 
\begin_inset Formula $i=1,\dots,n$
\end_inset

 are independent.
 That is, 
\begin_inset Formula 
\begin{align}
\bm{\varepsilon}\overset{iid}{\sim}\mathcal{N}\left(0,\sigma^{2}\right).\label{eq:err}
\end{align}

\end_inset


\end_layout

\begin_layout Standard
In the context of nonparametric regression, the boundary-effect bias can
 be reduced by local polynomial modeling, usually in the form of a locally
 linear model 
\begin_inset CommandInset citation
LatexCommand citep
key "Fan-Gijbels-1996"

\end_inset

.
 Here, to prepare for the estimation of locally linear coefficients, we
 augment the local design matrix with covariate-by-location interactions
 in two dimensions 
\begin_inset CommandInset citation
LatexCommand citep
key "Wang-2008b"

\end_inset

.
 The augmented local design matrix at location 
\begin_inset Formula $\bm{s}_{i}$
\end_inset

 is 
\begin_inset Formula 
\begin{align}
\bm{Z}(\bm{s}_{i})=\left(\bm{X}\:\:\bm{L}_{i}\bm{X}\:\:\bm{M}_{i}\bm{X}\right)
\end{align}

\end_inset


\end_layout

\begin_layout Standard
where 
\begin_inset Formula $\bm{X}$
\end_inset

 is the unaugmented matrix of covariates, 
\begin_inset Formula $\bm{L}_{i}=\text{diag}\{s_{i',1}-s_{i,1}\}$
\end_inset

 and 
\begin_inset Formula $\bm{M}_{i}=\text{diag}\{s_{i',2}-s_{i,2}\}$
\end_inset

 for 
\begin_inset Formula $i'=1,\dots,n$
\end_inset

.
\end_layout

\begin_layout Standard
Now we have that 
\begin_inset Formula $Y(\bm{s}_{i})=\left\{ \bm{Z}(\bm{s}_{i})\right\} _{i}^{T}\bm{\zeta}(\bm{s}_{i})+\varepsilon(\bm{s}_{i})$
\end_inset

, where 
\begin_inset Formula $\left\{ \bm{Z}(\bm{s}_{i})\right\} _{i}^{T}$
\end_inset

 is the 
\begin_inset Formula $i$
\end_inset

th row of the matrix 
\begin_inset Formula $\bm{Z}(\bm{s}_{i})$
\end_inset

 as a row vector, and 
\begin_inset Formula $\bm{\zeta}(\bm{s}_{i})$
\end_inset

 is the vector of local coefficients at location 
\begin_inset Formula $\bm{s}_{i}$
\end_inset

, augmented with the local gradients of the coefficient surfaces in the
 two spatial dimensions, indicated by 
\begin_inset Formula $\nabla_{u}$
\end_inset

 and 
\begin_inset Formula $\nabla_{v}$
\end_inset

:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
\bm{\zeta}(\bm{s}_{i})=\left(\bm{\beta}(\bm{s}_{i})^{T},\;\nabla_{u}\bm{\beta}(\bm{s}_{i})^{T},\;\nabla_{v}\bm{\beta}(\bm{s}_{i})^{T}\right)^{T}
\]

\end_inset


\end_layout

\begin_layout Subsection
Local Likelihood and Coefficient Estimation
\end_layout

\begin_layout Standard
The total log-likelihood of the observed data is the sum of the log-likelihood
 of each individual observation: 
\begin_inset Formula 
\begin{align}
\ell\left(\bm{\zeta}\right)=-(1/2)\sum_{i=1}^{n}\left[\log{\sigma^{2}}+\sigma^{-2}\left\{ y(\bm{s}_{i})-\bm{z}'(\bm{s}_{i})\bm{\zeta}(\bm{s}_{i})\right\} ^{2}\right].\label{eq:coefficients}
\end{align}

\end_inset


\end_layout

\begin_layout Standard
Since there are a total of 
\begin_inset Formula $n\times3(p+1)+1$
\end_inset

 parameters for 
\begin_inset Formula $n$
\end_inset

 observations, the model is not identifiable and it is not possible to directly
 maximize the total likelihood.
 But when the coefficient functions are smooth, the coefficients at location
 
\begin_inset Formula $\bm{s}$
\end_inset

 can approximate the coefficients within some neighborhood of 
\begin_inset Formula $\bm{s}$
\end_inset

, with the quality of the approximation declining as the distance from 
\begin_inset Formula $\bm{s}$
\end_inset

 increases.
\end_layout

\begin_layout Standard
This intuition is formalized by the local (log-)likelihood, which is maximized
 at location 
\begin_inset Formula $\bm{s}$
\end_inset

 to estimate the local coefficients 
\begin_inset Formula $\bm{\zeta}(\bm{s})$
\end_inset

:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{align}
\ell\left(\bm{\zeta}(\bm{s})\right)= & -(1/2)\sum_{i=1}^{n}K_{h}(\|\bm{s}-\bm{s}_{i}\|)\left[\log\sigma^{2}+\sigma^{-2}\left\{ y\left(\bm{s}_{i}\right)-\bm{z}'\left(\bm{s}_{i}\right)\bm{\zeta}\left(\bm{s}\right)\right\} ^{2}\right]\label{eq:local-log-likelihood}
\end{align}

\end_inset


\end_layout

\begin_layout Standard
where 
\begin_inset Formula $h$
\end_inset

 is a bandwidth parameter and the 
\begin_inset Formula $K_{h}\left(\|\bm{s}-\bm{s}_{i}\|\right)$
\end_inset

 for 
\begin_inset Formula $i=1,\dots,n$
\end_inset

 are local weights from a kernel function and 
\begin_inset Formula $h$
\end_inset

 is a bandwidth parameter.
 For instance, the Epanechnikov kernel is defined as 
\begin_inset CommandInset citation
LatexCommand citep
key "Samiuddin-el-Sayyad-1990"

\end_inset

: 
\begin_inset Formula 
\begin{align}
K_{h}(\|\bm{s}_{i}-\bm{s}_{i'}\|) & =h^{-2}K\left(h^{-1}\|\bm{s}_{i}-\bm{s}_{i'}\|\right)\notag\label{eq:epanechnikov}\\
K(x) & =\begin{cases}
(3/4)(1-x^{2}) & \mbox{ if }x<1,\\
0 & \mbox{ if }x\geq1.
\end{cases}
\end{align}

\end_inset


\end_layout

\begin_layout Standard
Letting 
\begin_inset Formula $\bm{W}(\bm{s})=diag\left\{ K_{h}(\|\bm{s}-\bm{s}_{i}\|)\right\} $
\end_inset

 be a diagonal matrix of kernel weights, the local likelihood is maximized
 by weighted least squares: 
\begin_inset Formula 
\begin{align}
\mathcal{S}\left(\bm{\zeta}\left(\bm{s}\right)\right) & =(1/2)\left\{ \bm{Y}-\bm{Z}(\bm{s})\bm{\zeta}(\bm{s})\right\} ^{T}\bm{W}(\bm{s})\left\{ \bm{Y}-\bm{Z}(\bm{s})\bm{\zeta}(\bm{s})\right\} ^{T}\notag\label{eq:zeta-hat}
\end{align}

\end_inset


\end_layout

\begin_layout Standard
Thus, we have
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
\tilde{\bm{\zeta}}(\bm{s})=\left\{ \bm{Z}^{T}(\bm{s})\bm{W}(\bm{s})\bm{Z}(\bm{s})\right\} ^{-1}\bm{Z}^{T}(\bm{s})\bm{W}(\bm{s})\bm{Y}
\]

\end_inset


\end_layout

\begin_layout Standard
By Theorem 3 of 
\begin_inset CommandInset citation
LatexCommand cite
key "Sun-Yan-Zhang-Lu-2014"

\end_inset

, for any given 
\begin_inset Formula $\bm{s}$
\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
\sqrt{{nh^{2}f(\bm{{s}})}}\left[\hat{\bm{\beta}}(\bm{s})-\bm{\beta}(\bm{s})-(1/2)\kappa_{0}^{-1}\kappa_{2}h^{2}\left\{ \bm{\beta}_{uu}(\bm{s})+\bm{\beta}_{vv}(\bm{s})\right\} \right]\xrightarrow{{D}}N\left(\bm{0},\kappa_{0}^{-2}\nu_{0}\sigma^{2}\Psi^{-1}\right)
\]

\end_inset


\end_layout

\begin_layout Section
Local Variable Selection with LAGR
\begin_inset CommandInset label
LatexCommand label
name "sec:lagr-gaussian"

\end_inset


\end_layout

\begin_layout Subsection
The LAGR-Penalized Local Likelihood
\end_layout

\begin_layout Standard
Estimating the local coefficients by (
\begin_inset CommandInset ref
LatexCommand ref
reference "eq:zeta-hat"

\end_inset

) relies on 
\emph on
a priori
\emph default
 variable selection.
 Here we develop a new method of penalized regression to simultaneously
 select local covariates and estimate the local coefficients.
 For this purpose, each raw covariate is grouped with its covariate-by-location
 interactions.
 That is, 
\begin_inset Formula $\bm{\zeta}_{j}(\bm{s})=\left(\beta_{j}(\bm{s}),\;\;\nabla_{u}\beta_{j}(\bm{s}),\;\;\nabla_{v}\beta_{j}(\bm{s})\right)^{T}$
\end_inset

 for 
\begin_inset Formula $j=1,\dots,p$
\end_inset

.
 By the mechanism of the adaptive group lasso, variables within the same
 group are included in or dropped from the model together.
 The intercept group is left unpenalized.
 The proposed LAGR penalty is an adaptive 
\begin_inset Formula $\ell_{1}$
\end_inset

 penalty akin to the adaptive group lasso 
\begin_inset CommandInset citation
LatexCommand citep
key "Wang-Leng-2008,Zou-2006"

\end_inset

.
\end_layout

\begin_layout Standard
More specifically, we consider the penalized local sum of squares at location
 
\begin_inset Formula $\bm{s}$
\end_inset

: 
\begin_inset Formula 
\begin{align}
\mathcal{J}\left(\bm{\zeta}\left(\bm{s}\right)\right) & =\mathcal{S}\left(\bm{\zeta}\left(\bm{s}\right)\right)+\mathcal{P}\left(\bm{\zeta}\left(\bm{s}\right)\right)\notag\label{eq:adaptive-lasso-WLS}
\end{align}

\end_inset


\end_layout

\begin_layout Standard
where 
\begin_inset Formula $\mathcal{S}\left(\bm{\zeta}\left(\bm{s}\right)\right)=(1/2)\left\{ \bm{Y}-\bm{Z}(\bm{s})\bm{\zeta}(\bm{s})\right\} ^{T}\bm{W}(\bm{s})\left\{ \bm{Y}-\bm{Z}(\bm{s})\bm{\zeta}(\bm{s})\right\} ^{T}$
\end_inset

 is the locally weighted sum of squares, 
\begin_inset Formula $\mathcal{P}\left(\bm{\zeta}\left(\bm{s}\right)\right)=\sum_{j=1}^{p}\phi_{j}(\bm{s})\|\bm{\zeta}_{j}(\bm{s})\|$
\end_inset

 is a local adaptive grouped regularization (LAGR) penalty, and 
\begin_inset Formula $\|\cdot\|$
\end_inset

 is the 
\begin_inset Formula $L_{2}$
\end_inset

-norm.
\end_layout

\begin_layout Standard
The LAGR penalty for the 
\begin_inset Formula $j$
\end_inset

th group of coefficients 
\begin_inset Formula $\bm{\zeta}_{j}(\bm{s})$
\end_inset

 at location 
\begin_inset Formula $\bm{s}$
\end_inset

 is 
\begin_inset Formula $\phi_{j}(\bm{s})=\lambda_{n}(\bm{s})\|\tilde{\bm{\zeta}}_{j}(\bm{s})\|^{-\gamma}$
\end_inset

, where 
\begin_inset Formula $\lambda_{n}(\bm{s})>0$
\end_inset

 is a local tuning parameter applied to all coefficients at location 
\begin_inset Formula $\bm{s}$
\end_inset

 and 
\begin_inset Formula $\tilde{\bm{\zeta}}_{j}(\bm{s})$
\end_inset

 is the vector of unpenalized local coefficients from (
\begin_inset CommandInset ref
LatexCommand ref
reference "eq:zeta-hat"

\end_inset

).
\end_layout

\begin_layout Subsection
Oracle Properties
\end_layout

\begin_layout Standard
For a local model at location 
\begin_inset Formula $\bm{s}$
\end_inset

, define the following terms.
\end_layout

\begin_layout Itemize
\begin_inset Argument item:1
status open

\begin_layout Plain Layout
(D.1)
\end_layout

\end_inset

Let 
\begin_inset Formula $a_{n}=\max\left\{ \phi_{j}\left(\bm{s}\right),j\le p_{0}\right\} $
\end_inset

 be the largest penalty applied to a covariate group whose true coefficient
 norm is nonzero, and 
\begin_inset Formula $b_{n}=\min\left\{ \phi_{j}\left(\bm{s}\right),j>p_{0}\right\} $
\end_inset

 be the smallest penalty applied to a covariate group whose true coefficient
 norm is zero.
\end_layout

\begin_layout Itemize
\begin_inset Argument item:1
status open

\begin_layout Plain Layout
(D.2)
\end_layout

\end_inset

Let 
\begin_inset Formula $\bm{Z}_{k}\left(\bm{s}\right)$
\end_inset

 be the augmented design matrix for covariate group 
\begin_inset Formula $k$
\end_inset

, and let 
\begin_inset Formula $\bm{Z}_{-k}\left(\bm{s}\right)$
\end_inset

 be the augmented design matrix for all the data except covariate group
 
\begin_inset Formula $k$
\end_inset

.
 Similarly, let 
\begin_inset Formula $\bm{\zeta}_{k}\left(\bm{s}\right)$
\end_inset

 be the augmented coefficients for covariate group 
\begin_inset Formula $k$
\end_inset

 and 
\begin_inset Formula $\bm{\zeta}_{-k}\left(\bm{s}\right)$
\end_inset

 be the augmented coefficients for all covariate groups except 
\begin_inset Formula $k$
\end_inset

.
\end_layout

\begin_layout Itemize
\begin_inset Argument item:1
status open

\begin_layout Plain Layout
(D.3)
\end_layout

\end_inset

Let 
\begin_inset Formula $\kappa_{0}=\int_{R^{2}}K\left(\|\bm{s}\|\right)ds$
\end_inset

, 
\begin_inset Formula $\kappa_{2}=\int_{R^{2}}[(1,0)\bm{s}]^{2}K\left(\|\bm{s}\|\right)ds=\int_{R^{2}}[(0,1)\bm{s}]^{2}K\left(\|\bm{s}\|\right)ds$
\end_inset

, and 
\begin_inset Formula $\nu_{0}=\int_{R^{2}}K^{2}\left(\|\bm{s}\|\right)ds$
\end_inset

.
\end_layout

\begin_layout Standard
Assume the following conditions.
\end_layout

\begin_layout Itemize
\begin_inset Argument item:1
status open

\begin_layout Plain Layout
(A.1)
\end_layout

\end_inset

The kernel function 
\begin_inset Formula $K\left(\cdot\right)$
\end_inset

 is bounded, positive, symmetric, and Lipschitz continuous on 
\begin_inset Formula $\mathbb{R}$
\end_inset

.
\end_layout

\begin_layout Itemize
\begin_inset Argument item:1
status open

\begin_layout Plain Layout
(A.2)
\end_layout

\end_inset

There are 
\begin_inset Formula $p_{0}<p$
\end_inset

 covariates 
\begin_inset Formula $\bm{X}_{a}\left(\bm{s}\right)$
\end_inset

 with nonzero local regression coefficients, indicated by 
\begin_inset Formula $\bm{\beta}_{a}(\bm{s})$
\end_inset

.
 Without loss of generality, assume these are covariates 
\begin_inset Formula $1,\dots,p_{0}$
\end_inset

.
 The remaining covariates 
\begin_inset Formula $\bm{X}_{b}\left(\bm{s}\right)$
\end_inset

 have true coefficients equal to zero, indicated by 
\begin_inset Formula $\bm{\beta}_{b}\left(\bm{s}\right)$
\end_inset

.
\end_layout

\begin_layout Itemize
\begin_inset Argument item:1
status open

\begin_layout Plain Layout
(A.3)
\end_layout

\end_inset


\begin_inset Formula $\bm{X}\left(\bm{s}_{1}\right),\dots,\bm{X}\left(\bm{s}_{n}\right)$
\end_inset

 are 
\begin_inset Formula $iid$
\end_inset

 random variables that are independent of 
\begin_inset Formula $\varepsilon\left(\bm{s}_{1}\right),\dots,\varepsilon\left(\bm{s}_{n}\right)$
\end_inset

.
 Also 
\begin_inset Formula $\Psi=E\left\{ \bm{X}\left(\bm{s}_{1}\right)\bm{X}^{T}\left(\bm{s}_{1}\right)\right\} $
\end_inset

 is positive-definite, 
\begin_inset Formula $E\left|\bm{X}\left(\bm{s}_{1}\right)\right|^{2q}<\infty$
\end_inset

, and 
\begin_inset Formula $E\left|\varepsilon\left(\bm{s}_{1}\right)\right|^{2q}<\infty$
\end_inset

.
\end_layout

\begin_layout Itemize
\begin_inset Argument item:1
status open

\begin_layout Plain Layout
(A.4)
\end_layout

\end_inset

The coefficient functions 
\begin_inset Formula $ $
\end_inset


\begin_inset Formula $\beta_{j}\left(\cdot\right)$
\end_inset

, 
\begin_inset Formula $j=1,\dots,p$
\end_inset

 have continuous second partial derivatives.
\end_layout

\begin_layout Itemize
\begin_inset Argument item:1
status open

\begin_layout Plain Layout
(A.5)
\end_layout

\end_inset


\begin_inset Formula $h=h_{n}=O\left(n^{-1/6}\right)$
\end_inset


\end_layout

\begin_layout Theorem
\begin_inset CommandInset label
LatexCommand label
name "theorem:normality"

\end_inset

 
\end_layout

\begin_layout Theorem
\begin_inset Argument 1
status open

\begin_layout Plain Layout
Asymptotic normality
\end_layout

\end_inset


\end_layout

\begin_layout Theorem
If 
\begin_inset Formula $h^{-1}n^{-1/2}a_{n}\xrightarrow{p}0$
\end_inset

 and 
\begin_inset Formula $hn^{-1/2}b_{n}\xrightarrow{p}\infty$
\end_inset

 then 
\begin_inset Formula 
\[
h\sqrt{n}\left[\hat{\bm{\beta}}_{a}\left(\bm{s}\right)-\bm{\beta}_{a}\left(\bm{s}\right)-\frac{\kappa_{2}h^{2}}{2\kappa_{0}}\left\{ \nabla_{uu}^{2}\bm{\beta}_{a}\left(\bm{s}\right)+\nabla_{vv}^{2}\bm{\beta}_{a}\left(\bm{s}\right)\right\} \right]\xrightarrow{d}N\left(0,f\left(\bm{s}\right){}^{-1}\kappa_{0}^{-2}\nu_{0}\sigma^{2}\Psi^{-1}\right)
\]

\end_inset


\end_layout

\begin_layout --Separator--

\end_layout

\begin_layout Theorem
\begin_inset CommandInset label
LatexCommand label
name "theorem:selection"

\end_inset


\end_layout

\begin_layout Theorem
\begin_inset Argument 1
status open

\begin_layout Plain Layout
Selection consistency
\end_layout

\end_inset


\end_layout

\begin_layout Theorem
If 
\begin_inset Formula $h^{-1}n^{-1/2}a_{n}\xrightarrow{p}\infty$
\end_inset

 and 
\begin_inset Formula $hn^{-1/2}b_{n}\xrightarrow{p}\infty$
\end_inset

 then 
\begin_inset Formula $Pr\left\{ \|\hat{\bm{\zeta}}_{j}\left(\bm{s}\right)\|=\utilde{0}\right\} \to0$
\end_inset

 if 
\begin_inset Formula $j\le p_{0}$
\end_inset

 and 
\begin_inset Formula $Pr\left\{ \|\hat{\bm{\zeta}}_{j}\left(\bm{s}\right)\|=\utilde{0}\right\} \to1$
\end_inset

 if 
\begin_inset Formula $j>p_{0}$
\end_inset

.
 
\end_layout

\begin_layout Paragraph
Remarks
\end_layout

\begin_layout Standard
Together, TheoremÂ 
\begin_inset CommandInset ref
LatexCommand ref
reference "theorem:normality"

\end_inset

 and Theorem 
\begin_inset CommandInset ref
LatexCommand ref
reference "theorem:selection"

\end_inset

 indicate that the LAGR estimates have the same asymptotic distribution
 as a local regression model where the nonzero coefficients are known in
 advance 
\begin_inset CommandInset citation
LatexCommand citep
key "Sun-Yan-Zhang-Lu-2014"

\end_inset

, and that the LAGR estimates of true zero coefficients go to zero with
 probability one.
 Thus, selection and estimation by LAGR has the oracle property.
\end_layout

\begin_layout Paragraph
A note on rates
\end_layout

\begin_layout Standard
To establish the oracle properties of LAGR, we assumed that 
\begin_inset Formula $h^{-1}n^{-1/2}a_{n}\xrightarrow{p}0$
\end_inset

 and 
\begin_inset Formula $hn^{-1/2}b_{n}\xrightarrow{p}\infty$
\end_inset

.
 Therefore, 
\begin_inset Formula $h^{-1}n^{-1/2}\lambda_{n}\left(\bm{s}\right)\to0$
\end_inset

 for 
\begin_inset Formula $j\le p_{0}$
\end_inset

 and 
\begin_inset Formula $hn^{-1/2}\lambda_{n}\left(\bm{s}\right)\|\bm{\zeta}_{j}\left(\bm{s}\right)\|^{-\gamma}\to\infty$
\end_inset

 for 
\begin_inset Formula $j>p_{0}$
\end_inset

.
 We require that 
\begin_inset Formula $\lambda_{n}\left(\bm{s}\right)$
\end_inset

 satisfy both assumptions.
 Suppose 
\begin_inset Formula $\lambda_{n}\left(\bm{s}\right)=n^{\alpha}$
\end_inset

, and recall that 
\begin_inset Formula $h=O\left(n^{-1/6}\right)$
\end_inset

 and 
\begin_inset Formula $\|\tilde{\bm{\zeta}}_{p}(\bm{s})\|=O\left(h^{-1}n^{-1/2}\right)$
\end_inset

.
 Then 
\begin_inset Formula $h^{-1}n^{-1/2}\lambda_{n}\left(\bm{s}\right)=O\left(n^{-1/3+\alpha}\right)$
\end_inset

 and 
\begin_inset Formula $hn^{-1/2}\lambda_{n}\left(\bm{s}\right)\|\tilde{\bm{\zeta}}_{p}\left(\bm{s}\right)\|^{-\gamma}=O\left(n^{-2/3+\alpha+\gamma/3}\right)$
\end_inset

.
 Thus, 
\begin_inset Formula $\left(2-\gamma\right)/3<\alpha<1/3$
\end_inset

, which can only be satisfied for 
\begin_inset Formula $\gamma>1$
\end_inset

.
\end_layout

\begin_layout Subsection
Tuning Parameter Selection
\end_layout

\begin_layout Standard
In practical application, it is necessary to select the LAGR tuning parameter
 
\begin_inset Formula $\lambda_{n}(\bm{s})$
\end_inset

 for each local model.
 A popular approach in other lasso-type problems is to select the tuning
 parameter that maximizes a criterion that approximates the expected log-likelih
ood of a new, independent data set drawn from the same distribution.
 This is the framework of Mallows' Cp, Stein's unbiased risk estimate (SURE)
 and Akaike's information criterion (AIC) 
\begin_inset CommandInset citation
LatexCommand citep
key "Mallows-1973,Stein-1981,Akaike-1973"

\end_inset

.
\end_layout

\begin_layout Standard
These criteria use a so-called covariance penalty to estimate the bias due
 to using the same data set to select a model and to estimate its parameters
 
\begin_inset CommandInset citation
LatexCommand citep
key "Efron:2004a"

\end_inset

.
 We adopt the approximate degrees of freedom for the adaptive group lasso
 from 
\begin_inset CommandInset citation
LatexCommand citet
key "Yuan-Lin-2006"

\end_inset

 and minimize the AICc to select the tuning parameter 
\begin_inset Formula $\lambda_{n}(\bm{s})$
\end_inset

 
\begin_inset CommandInset citation
LatexCommand citep
key "Hurvich-1998"

\end_inset

.
 That is, let
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{align*}
\hat{df}(\lambda;\bm{s})= & \sum_{j=1}^{p}I\left(\|\hat{\bm{\zeta}}(\lambda;\bm{s})\|>0\right)+\sum_{j=1}^{p}\frac{\|\hat{\bm{\zeta}}(\lambda;\bm{s})\|}{\|\tilde{\bm{\zeta}}(\bm{s})\|}(p_{j}-1)\\
\text{AIC}_{c}(\lambda;\bm{s})= & \sum_{i=1}^{n}K_{h}(\|\bm{s}-\bm{s}_{i}\|)\sigma^{-2}\left\{ y(\bm{s}_{i})-z'(\bm{s}_{i})\hat{\bm{\zeta}}(\lambda;\bm{s})\right\} ^{2}+2\hat{df}(\lambda;\bm{s})\\
 & +\frac{2\hat{df}(\lambda;\bm{s})\left\{ \hat{df}(\lambda;\bm{s})+1\right\} }{\sum_{i=1}^{n}K_{h}(\|\bm{s}-\bm{s}_{i}\|)-\hat{df}(\lambda;\bm{s})-1}
\end{align*}

\end_inset


\end_layout

\begin_layout Standard
where the local coefficient estimate is written 
\begin_inset Formula $\hat{\bm{\zeta}}(\lambda;\bm{s})$
\end_inset

 to emphasize that it depends on the tuning parameter.
\end_layout

\begin_layout Section
Simulation Study
\begin_inset CommandInset label
LatexCommand label
name "sec:simulations"

\end_inset


\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout

<<simulation-imports, message=FALSE, warning=FALSE, echo=FALSE>>=
\end_layout

\begin_layout Plain Layout

	#Imports:
\end_layout

\begin_layout Plain Layout

	require(xtable)
\end_layout

\begin_layout Plain Layout

	require(dplyr)
\end_layout

\begin_layout Plain Layout

	require(brooks)
\end_layout

\begin_layout Plain Layout

	load("~/scratch/gwr-sim-output.RData")
\end_layout

\begin_layout Plain Layout

@
\end_layout

\end_inset


\end_layout

\begin_layout Subsection
Simulation Setup
\end_layout

\begin_layout Standard
A simulation study was conducted to assess the performance of the method
 described in Sections 
\begin_inset CommandInset ref
LatexCommand ref
reference "sec:vcr"

\end_inset

--
\begin_inset CommandInset ref
LatexCommand ref
reference "sec:lagr-gaussian"

\end_inset

.
 Data were simulated on the domain 
\begin_inset Formula $[0,1]^{2}$
\end_inset

, which was divided into a 
\begin_inset Formula $30\times30$
\end_inset

 grid.
 Each of 
\begin_inset Formula $p=5$
\end_inset

 covariates 
\begin_inset Formula $X_{1},\dots,X_{5}$
\end_inset

 was simulated by a Gaussian random field with mean zero and exponential
 covariance function 
\begin_inset Formula $\text{Cov}\left(X_{ji},X_{ji'}\right)=\sigma_{x}^{2}\exp{\left(-\tau_{x}^{-1}\delta_{ii'}\right)}$
\end_inset

 where 
\begin_inset Formula $\sigma_{x}^{2}=1$
\end_inset

 is the variance, 
\begin_inset Formula $\tau_{x}=0.1$
\end_inset

 is the range parameter, and 
\begin_inset Formula $\delta_{ii'}=\|\bm{s}_{i}-\bm{s}_{i'}\|_{2}$
\end_inset

 is the Euclidean distance between locations 
\begin_inset Formula $\bm{s}$
\end_inset

 and 
\begin_inset Formula $\bm{s}_{i}$
\end_inset

.
 
\end_layout

\begin_layout Standard
Correlation was induced between the covariates by multiplying the design
 matrix 
\begin_inset Formula $\bm{X}$
\end_inset

 by 
\begin_inset Formula $\bm{R}$
\end_inset

, where 
\begin_inset Formula $\bm{R}$
\end_inset

 is the Cholesky decomposition of the covariance matrix 
\begin_inset Formula $\bm{\Sigma}=\bm{R}'\bm{R}$
\end_inset

.
 The covariance matrix 
\begin_inset Formula $\bm{\Sigma}$
\end_inset

 is a 
\begin_inset Formula $5\times5$
\end_inset

 matrix that has ones on the diagonal and 
\begin_inset Formula $\rho$
\end_inset

 for all off-diagonal entries, where 
\begin_inset Formula $\rho$
\end_inset

 is the between-covariate correlation.
 
\end_layout

\begin_layout Standard
The simulated response was 
\begin_inset Formula $y_{i}=\bm{x}'_{i}\bm{\beta}_{i}+\varepsilon_{i}$
\end_inset

 for 
\begin_inset Formula $i=1,\dots,n$
\end_inset

 where 
\begin_inset Formula $n=900$
\end_inset

 and the 
\begin_inset Formula $\varepsilon_{i}$
\end_inset

's were iid Gaussian with mean zero and variance 
\begin_inset Formula $\sigma_{\varepsilon}^{2}$
\end_inset

.
 The simulated data included the response 
\begin_inset Formula $y$
\end_inset

 and five covariates 
\begin_inset Formula $x_{1},\dots,x_{5}$
\end_inset

.
 The true data-generating model uses only 
\begin_inset Formula $x_{1}$
\end_inset

.
 The variables 
\begin_inset Formula $x_{2},\dots,x_{5}$
\end_inset

 are included to assess performance in model selection.
 
\end_layout

\begin_layout Standard
Three different functions were used for the coefficient surface 
\begin_inset Formula $\beta_{1}(\bm{s})$
\end_inset

 (Figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:simulation-coefficient-functions"

\end_inset

).
 The first is the 
\begin_inset Quotes eld
\end_inset

step
\begin_inset Quotes erd
\end_inset

 function:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
\beta_{step}(\bm{s})=\ \ \begin{cases}
1 & if\ s_{x}>0.6\\
5s_{x}-2 & if\ 0.4<s_{x}\le0.6\\
0 & o.w.
\end{cases}.
\]

\end_inset


\end_layout

\begin_layout Standard
The second is the gradient function, 
\begin_inset Formula $\beta_{gradient}(\bm{s})=s_{x}$
\end_inset

, and the third is the parabola 
\begin_inset Formula $\beta_{parabola}(\bm{s})=1-2\left\{ (s_{x}-0.5)^{2}+(s_{y}-0.5)^{2}\right\} $
\end_inset

.
\end_layout

\begin_layout Standard
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\begin_inset Graphics
	filename ../../figures/simulation/step.pdf
	width 33text%

\end_inset


\begin_inset Graphics
	filename ../../figures/simulation/gradient.pdf
	width 33text%

\end_inset


\begin_inset Graphics
	filename ../../figures/simulation/parabola.pdf
	width 33text%

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
These are, respectively, the step, gradient, and parabola functions that
 were used for the coefficient function 
\begin_inset Formula $\beta_{1}(\bm{s})$
\end_inset

 in the VCR model 
\begin_inset Formula $y(\bm{s}_{i})=x_{1}(\bm{s}_{i})\beta_{1}(\bm{s}_{i})+\varepsilon(\bm{s}_{i})$
\end_inset

 when generating the data for the simulation study.
\begin_inset CommandInset label
LatexCommand label
name "fig:simulation-coefficient-functions"

\end_inset


\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
In total, three parameters were varied to produce 18 settings, each of which
 was simulated 100 times.
 There were the three functional forms for the coefficient surface 
\begin_inset Formula $\beta_{1}(\bm{s})$
\end_inset

; data was simulated both with low (
\begin_inset Formula $\rho=0$
\end_inset

), medium (
\begin_inset Formula $\rho=0.5$
\end_inset

), and high (
\begin_inset Formula $\rho=0.9$
\end_inset

) correlation between the covariates; and simulations were made with low
 (
\begin_inset Formula $\sigma_{\varepsilon}=0.5$
\end_inset

) and high (
\begin_inset Formula $\sigma_{\varepsilon}=1$
\end_inset

) variance for the random error term.
\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout

<<prefix, echo=FALSE, results='asis', message=FALSE>>=
\end_layout

\begin_layout Plain Layout

	sim.prefix <- list()
\end_layout

\begin_layout Plain Layout

	sim.prefix$pos <- sapply(0:17, function(x) return(x), simplify=FALSE)
\end_layout

\begin_layout Plain Layout

	sim.prefix$command <- c("
\backslash

\backslash
multirow{6}{*}{step} & 
\backslash

\backslash
multirow{2}{*}{0} & 0.5 & ",
\end_layout

\begin_layout Plain Layout

		" &  & 1.0 & ",
\end_layout

\begin_layout Plain Layout

		" & 
\backslash

\backslash
multirow{2}{*}{0.5} & 0.5 & ",
\end_layout

\begin_layout Plain Layout

		" &  & 1.0 & ",
\end_layout

\begin_layout Plain Layout

		" & 
\backslash

\backslash
multirow{2}{*}{0.9} & 0.5 & ",
\end_layout

\begin_layout Plain Layout

		" &  & 1.0 & ",
\end_layout

\begin_layout Plain Layout

		"
\backslash

\backslash
hline 
\backslash

\backslash
multirow{6}{*}{gradient} & 
\backslash

\backslash
multirow{2}{*}{0} & 0.5 & ",
\end_layout

\begin_layout Plain Layout

		" &  & 1.0 & ",
\end_layout

\begin_layout Plain Layout

		" & 
\backslash

\backslash
multirow{2}{*}{0.5} & 0.5 & ",
\end_layout

\begin_layout Plain Layout

		" &  & 1.0 & ",
\end_layout

\begin_layout Plain Layout

		" & 
\backslash

\backslash
multirow{2}{*}{0.9} & 0.5 & ",
\end_layout

\begin_layout Plain Layout

		" &  & 1.0 & ",
\end_layout

\begin_layout Plain Layout

		"
\backslash

\backslash
hline 
\backslash

\backslash
multirow{6}{*}{parabola} & 
\backslash

\backslash
multirow{2}{*}{0} & 0.5 & ",
\end_layout

\begin_layout Plain Layout

		" &  & 1.0 & ",
\end_layout

\begin_layout Plain Layout

		" & 
\backslash

\backslash
multirow{2}{*}{0.5} & 0.5 & ",
\end_layout

\begin_layout Plain Layout

		" &  & 1.0 & ",
\end_layout

\begin_layout Plain Layout

		" & 
\backslash

\backslash
multirow{2}{*}{0.9} & 0.5 & ",
\end_layout

\begin_layout Plain Layout

		" &  & 1.0 & ")
\end_layout

\begin_layout Plain Layout

@
\end_layout

\end_inset


\end_layout

\begin_layout Standard
The results are presented in terms of the mean integrated squared error
 (MISE) of the coefficient surface estimates 
\begin_inset Formula $\hat{\beta}_{1}(\bm{s}),\dots,\hat{\beta}_{5}(\bm{s})$
\end_inset

, the MISE of the fitted response 
\begin_inset Formula $\hat{y}(\bm{s})$
\end_inset

, and the frequency with which the coefficient surface estimates 
\begin_inset Formula $\hat{\beta}_{2}(\bm{s}),\dots,\hat{\beta}_{5}(\bm{s})$
\end_inset

 estimated by LAGR were zero.
 The performance of LAGR was compared to that of a VCR model without variable
 selection, and to a VCR model with oracular selection.
 Oracular selection means that exactly the correct set of covariates was
 used to fit each local model.
\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
begin{table}
\end_layout

\begin_layout Plain Layout

	
\backslash
begin{tabular}{ccc|ccc|cc}
\end_layout

\begin_layout Plain Layout

		
\backslash
multicolumn{3}{c}{
\backslash
begin{tabular}[c]{@{}c@{}}Simulation
\backslash

\backslash
settings
\backslash
end{tabular}} & 
\backslash
multicolumn{3}{c}{
\backslash
begin{tabular}[c]{@{}c@{}}MISE
\backslash

\backslash
$
\backslash
hat{
\backslash
beta}_1$
\backslash
end{tabular}} & 
\backslash
multicolumn{2}{c}{
\backslash
begin{tabular}[c]{@{}c@{}}MISE
\backslash

\backslash
$
\backslash
hat{
\backslash
beta}_2, 
\backslash
dots, 
\backslash
hat{
\backslash
beta}_5$
\backslash
end{tabular}} 
\backslash

\backslash

\end_layout

\begin_layout Plain Layout

		$
\backslash
beta_{1}(
\backslash
bm{s})$ & $
\backslash
rho$ & $
\backslash
sigma_{
\backslash
varepsilon}$ & LAGR & VCR & Oracle & LAGR & VCR 
\backslash

\backslash

\end_layout

\begin_layout Plain Layout

		
\backslash
hline 
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

<<MISE-X1, echo=FALSE, results='asis', message=FALSE, warning=FALSE>>=
\end_layout

\begin_layout Plain Layout

#Calculate the MISE for the first coefficient:
\end_layout

\begin_layout Plain Layout

mise = matrix(0, nrow=0, ncol=3)
\end_layout

\begin_layout Plain Layout

for (setting in 1:18) {
\end_layout

\begin_layout Plain Layout

    #Get the proper coefficient surface
\end_layout

\begin_layout Plain Layout

    if (setting < 7) {B1 = step}
\end_layout

\begin_layout Plain Layout

    else if (setting < 13) {B1 = gradient}
\end_layout

\begin_layout Plain Layout

    else {B1 = parabola}
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

    #compute the MISE
\end_layout

\begin_layout Plain Layout

    row = sapply(c('lagr', 'gwr', 'oracle'),
\end_layout

\begin_layout Plain Layout

                  function(selection.method) {
\end_layout

\begin_layout Plain Layout

                     mean(sweep(output[[setting]][[selection.method]][['X1']],
 1, as.vector(B1))**2)                  			}
\end_layout

\begin_layout Plain Layout

	)
\end_layout

\begin_layout Plain Layout

    mise = rbind(mise, row)
\end_layout

\begin_layout Plain Layout

}
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

#Which entries should be bolded (for having the lowest MISE)?
\end_layout

\begin_layout Plain Layout

bold = matrix(FALSE, nrow=nrow(mise), ncol=ncol(mise))
\end_layout

\begin_layout Plain Layout

for (i in 1:nrow(mise)){
\end_layout

\begin_layout Plain Layout

    bold[i,which.min(mise[i,])] = TRUE
\end_layout

\begin_layout Plain Layout

}
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

#Which entries should be italicised (for having the second-lowest MISE)?
\end_layout

\begin_layout Plain Layout

ital = matrix(FALSE, nrow=nrow(mise), ncol=ncol(mise))
\end_layout

\begin_layout Plain Layout

for (i in 1:nrow(mise)){
\end_layout

\begin_layout Plain Layout

    ital[i,order(mise[i,])[2]] = TRUE
\end_layout

\begin_layout Plain Layout

}
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

#Calculate the MISE for the second through fifth coefficients:
\end_layout

\begin_layout Plain Layout

mise.x2.x5 = matrix(0, nrow=0, ncol=2)
\end_layout

\begin_layout Plain Layout

for (setting in 1:18) {
\end_layout

\begin_layout Plain Layout

    #Get the proper coefficient surface
\end_layout

\begin_layout Plain Layout

    if (setting < 7) {B1 = step}
\end_layout

\begin_layout Plain Layout

    else if (setting < 13) {B1 = gradient}
\end_layout

\begin_layout Plain Layout

    else {B1 = parabola}
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

    #compute the MISE
\end_layout

\begin_layout Plain Layout

    row = sapply(c('lagr', 'gwr'),
\end_layout

\begin_layout Plain Layout

		function(selection.method) {
\end_layout

\begin_layout Plain Layout

			mean(sapply(c('X2','X3','X4','X5'), function(vv) {
\end_layout

\begin_layout Plain Layout

				output[[setting]][[selection.method]][[vv]]**2
\end_layout

\begin_layout Plain Layout

			}))
\end_layout

\begin_layout Plain Layout

		}
\end_layout

\begin_layout Plain Layout

	)
\end_layout

\begin_layout Plain Layout

    mise.x2.x5 = rbind(mise.x2.x5, row)
\end_layout

\begin_layout Plain Layout

}
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

#Which entries should be bolded (for having the lowest MISE)?
\end_layout

\begin_layout Plain Layout

bold.x2.x5 = matrix(FALSE, nrow=nrow(mise.x2.x5), ncol=ncol(mise.x2.x5))
\end_layout

\begin_layout Plain Layout

for (i in 1:nrow(mise.x2.x5)){
\end_layout

\begin_layout Plain Layout

    bold.x2.x5[i,which.min(mise.x2.x5[i,])] = TRUE
\end_layout

\begin_layout Plain Layout

}
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

#Put names on the table
\end_layout

\begin_layout Plain Layout

rownames(mise) = NULL
\end_layout

\begin_layout Plain Layout

colnames(mise) = c("LAGR", "VCR", "Oracle")
\end_layout

\begin_layout Plain Layout

colnames(mise.x2.x5) = c("LAGR", "VCR")
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

#Generate the table, caption it, and print it with emphasis.
\end_layout

\begin_layout Plain Layout

mise.table = xtable(cbind(mise, mise.x2.x5))
\end_layout

\begin_layout Plain Layout

caption(mise.table) = "The MISE for the estimates of $
\backslash

\backslash
beta_1(
\backslash

\backslash
bm{s})$ in each simulation setting, under variable selection via LAGR, no
 variable selection, and oracular variable selection.
 Highlighting indicates the 
\backslash

\backslash
textbf{lowest} and 
\backslash

\backslash
emph{next-lowest} MISE."
\end_layout

\begin_layout Plain Layout

label(mise.table) = "tab:x1-mise"
\end_layout

\begin_layout Plain Layout

xtable.printbold(mise.table,
\end_layout

\begin_layout Plain Layout

	table.placement=NULL,
\end_layout

\begin_layout Plain Layout

	which.bold=cbind(bold, bold.x2.x5),
\end_layout

\begin_layout Plain Layout

	which.ital=cbind(ital, matrix(FALSE, nrow=18, ncol=2)),
\end_layout

\begin_layout Plain Layout

	hline.after=NULL,
\end_layout

\begin_layout Plain Layout

	only.contents=TRUE,
\end_layout

\begin_layout Plain Layout

	include.rownames=FALSE,
\end_layout

\begin_layout Plain Layout

	include.colnames=FALSE,
\end_layout

\begin_layout Plain Layout

	add.to.row=sim.prefix)
\end_layout

\begin_layout Plain Layout

@
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

	
\backslash
end{tabular}
\end_layout

\begin_layout Plain Layout

	
\backslash
caption{Listing of the simulation settings used to assess the performance
 of LAGR models versus oracle selection and no selection.}
\end_layout

\begin_layout Plain Layout

	
\backslash
label{tab:mise}
\end_layout

\begin_layout Plain Layout


\backslash
end{table}
\end_layout

\end_inset


\end_layout

\begin_layout Subsection
Simulation Results
\end_layout

\begin_layout Standard
The MISE of the estimates of 
\begin_inset Formula $\beta_{1}(\bm{s})$
\end_inset

 are in Table 
\begin_inset CommandInset ref
LatexCommand ref
reference "tab:misex"

\end_inset

.
 Recall that 
\begin_inset Formula $\beta_{2}(\bm{s}),\dots,\beta_{5}(\bm{s})$
\end_inset

 are exactly zero across the entire domain.
 Oracle selection will estimate these coefficients perfectly, so we focus
 on the comparison between estimation by LAGR and by the VCR model with
 no selection.
 These results show that for every simulation setting, LAGR estimation is
 more accurate than the standard VCR model.
\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout

<<PZERO, echo=FALSE, results='asis', message=FALSE>>=
\end_layout

\begin_layout Plain Layout

load("~/scratch/gwr-sim-output.RData")
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

zz = vector()
\end_layout

\begin_layout Plain Layout

for (i in 1:18) {
\end_layout

\begin_layout Plain Layout

    zz = c(zz, mean(sapply(pzero, function(x) x[i])))
\end_layout

\begin_layout Plain Layout

}
\end_layout

\begin_layout Plain Layout

zz = matrix(zz)
\end_layout

\begin_layout Plain Layout

colnames(zz) = c("Frequency of exact zero")
\end_layout

\begin_layout Plain Layout

@
\end_layout

\end_inset


\end_layout

\begin_layout Standard
From Table 
\begin_inset CommandInset ref
LatexCommand ref
reference "tab:misey"

\end_inset

 we see that LAGR has good ability to identify zero-coefficient covariates.
 The frequency with which 
\begin_inset Formula $\beta_{2}(\bm{s}),\dots,\beta_{5}(\bm{s})$
\end_inset

 were dropped from the LAGR models ranged from 
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
Sexpr{round(min(zz),2)}
\end_layout

\end_inset

 to 
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
Sexpr{round(max(zz),2)}
\end_layout

\end_inset

.
 The MISE of the fitted 
\begin_inset Formula $\hat{y}(\bm{s})$
\end_inset

 is listed in Table 
\begin_inset CommandInset ref
LatexCommand ref
reference "tab:misey"

\end_inset

, where the highlighting is based on which methods estimate an error variance
 that is closest to the known truth for the simulation.
 The results are all very similar to each other, indicating that no method
 was consistently better than the others in this simulation at fitting the
 model output.
\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
begin{table}
\end_layout

\begin_layout Plain Layout

	
\backslash
begin{tabular}{ccc|c|ccc}
\end_layout

\begin_layout Plain Layout

		
\backslash
multicolumn{3}{c}{
\backslash
begin{tabular}[c]{@{}c@{}}Simulation
\backslash

\backslash
settings
\backslash
end{tabular}} &  
\backslash
multicolumn{1}{c}{
\backslash
begin{tabular}[c]{@{}c@{}}Zero
\backslash

\backslash
frequency
\backslash
end{tabular}} &  
\backslash
multicolumn{3}{c}{
\backslash
begin{tabular}[c]{@{}c@{}}MISE
\backslash

\backslash
$
\backslash
hat{y}$
\backslash
end{tabular}} 
\backslash

\backslash

\end_layout

\begin_layout Plain Layout

		$
\backslash
beta_{1}(
\backslash
bm{s})$ & $
\backslash
rho$ & $
\backslash
sigma_{
\backslash
varepsilon}$ & $
\backslash
hat{
\backslash
beta}_2,
\backslash
dots,
\backslash
hat{
\backslash
beta}_5 & LAGR & VCR & Oracle 
\backslash

\backslash

\end_layout

\begin_layout Plain Layout

		
\backslash
hline 
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

<<MISEY, echo=FALSE, results='asis', message=FALSE>>=
\end_layout

\begin_layout Plain Layout

	std = matrix(rbind(c(0.25, 0.25, 0.25), c(1, 1, 1)), nrow=18, ncol=3)
\end_layout

\begin_layout Plain Layout

	bold.misey = matrix(FALSE, nrow=nrow(mise), ncol=ncol(mise))
\end_layout

\begin_layout Plain Layout

	for (i in 1:nrow(mise)){
\end_layout

\begin_layout Plain Layout

		bold.misey[i,which.min(abs(misey[i,] - std[i,]))] = TRUE
\end_layout

\begin_layout Plain Layout

	}
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

	#Which entries should be italicised (for having the second-lowest MISE)?
\end_layout

\begin_layout Plain Layout

	ital.misey = matrix(FALSE, nrow=nrow(mise), ncol=ncol(mise))
\end_layout

\begin_layout Plain Layout

	for (i in 1:nrow(mise)){
\end_layout

\begin_layout Plain Layout

		ital.misey[i,order(abs(misey[i,] - std[i,]))[2]] = TRUE
\end_layout

\begin_layout Plain Layout

	}
\end_layout

\begin_layout Plain Layout

	
\end_layout

\begin_layout Plain Layout

	#Put names on the table
\end_layout

\begin_layout Plain Layout

	rownames(misey) = NULL
\end_layout

\begin_layout Plain Layout

	colnames(misey) = c("LAGR", "VCR", "Oracle")
\end_layout

\begin_layout Plain Layout

	
\end_layout

\begin_layout Plain Layout

	#Generate the table, caption it, and print it with emphasis.
\end_layout

\begin_layout Plain Layout

	misey.table = xtable(cbind(zz, misey))
\end_layout

\begin_layout Plain Layout

	
\end_layout

\begin_layout Plain Layout

	xtable.printbold(misey.table,
\end_layout

\begin_layout Plain Layout

		table.placement=NULL,
\end_layout

\begin_layout Plain Layout

		which.bold=cbind(rep(FALSE, 18), bold.misey),
\end_layout

\begin_layout Plain Layout

		which.ital=cbind(rep(FALSE, 18), ital.misey),
\end_layout

\begin_layout Plain Layout

		hline.after=NULL,
\end_layout

\begin_layout Plain Layout

		only.contents=TRUE,
\end_layout

\begin_layout Plain Layout

		include.rownames=FALSE,
\end_layout

\begin_layout Plain Layout

		include.colnames=FALSE,
\end_layout

\begin_layout Plain Layout

		add.to.row=sim.prefix
\end_layout

\begin_layout Plain Layout

	)
\end_layout

\begin_layout Plain Layout

@
\end_layout

\begin_layout Plain Layout

	
\backslash
end{tabular}
\end_layout

\begin_layout Plain Layout

	
\backslash
caption{The MISE for the fitted output in each simulation setting, under
 variable selection via LAGR, no variable selection, and oracular variable
 selection.
 Highlighting indicates the 
\backslash
textbf{closest} and 
\backslash
emph{next-closest} to the actual error variance $
\backslash
sigma_
\backslash
varepsilon^2$ for that setting.}
\end_layout

\begin_layout Plain Layout

	
\backslash
label{tab:misey}
\end_layout

\begin_layout Plain Layout


\backslash
end{table}
\end_layout

\end_inset


\end_layout

\begin_layout Standard
The proposed LAGR method was accurate in selection and estimation, with
 estimation accuracy for 
\begin_inset Formula $\beta_{1}(\bm{s})$
\end_inset

 about equal to that of the VCR model with no selection, and with consistently
 better accuracy for estimating 
\begin_inset Formula $\beta_{2}(\bm{s}),\dots,\beta_{5}(\bm{s})$
\end_inset

.
\end_layout

\begin_layout Standard
There was minimal difference in the performance of the proposed LAGR method
 between low (
\begin_inset Formula $\sigma_{\varepsilon}=0.5$
\end_inset

) and high (
\begin_inset Formula $\sigma_{\varepsilon}=1$
\end_inset

) error variance, and between no (
\begin_inset Formula $\rho=0$
\end_inset

) and moderate (
\begin_inset Formula $\rho=0.5$
\end_inset

) correlation among the covariates.
 But the selection and estimation accuracy did decline when there was high
 (
\begin_inset Formula $\rho=0.9$
\end_inset

) correlation among the predictor variables.
\end_layout

\begin_layout Section
Data Example
\begin_inset CommandInset label
LatexCommand label
name "sec:example"

\end_inset


\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout

<<boston-coef-import, echo=FALSE, results='asis', message=FALSE>>=
\end_layout

\begin_layout Plain Layout

require(xtable)
\end_layout

\begin_layout Plain Layout

require(brooks)
\end_layout

\begin_layout Plain Layout

load("~/git/gwr/scratch/boston-preset-bw.RData")
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

vars = c('CRIM', 'RM', 'RAD', 'TAX', 'LSTAT')
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

boston.coef.summary = matrix(NA, nrow=0, ncol=3)
\end_layout

\begin_layout Plain Layout

for (v in vars) {
\end_layout

\begin_layout Plain Layout

	row = vector()
\end_layout

\begin_layout Plain Layout

	colname.coef = paste("coef", v, sep="")
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

	#Add the table's elements to this row:
\end_layout

\begin_layout Plain Layout

	row = c(row, mean(boston.tracts@data[,colname.coef]))
\end_layout

\begin_layout Plain Layout

	row = c(row, sd(boston.tracts@data[,colname.coef]))
\end_layout

\begin_layout Plain Layout

	row = c(row, mean(boston.tracts@data[,colname.coef]==0))
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

	#Add this row to the table:
\end_layout

\begin_layout Plain Layout

	boston.coef.summary = rbind(boston.coef.summary, row)
\end_layout

\begin_layout Plain Layout

}
\end_layout

\begin_layout Plain Layout

rownames(boston.coef.summary) = vars
\end_layout

\begin_layout Plain Layout

colnames(boston.coef.summary) = c('Mean', 'SD', 'Prop.
 zero')
\end_layout

\begin_layout Plain Layout

@
\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Standard
The proposed LAGR estimation method was used to estimate the coefficients
 in a VCR model of the effect of some covariates on the price of homes in
 Boston 
\begin_inset CommandInset citation
LatexCommand citep
key "Harrison-Rubinfeld-1978,Gilley-Pace-1996,Pace-Gilley-1997"

\end_inset

.
 The data source is based on the 1970 U.S.
 census.
 In the data, we have the median price of homes sold in 506 census tracts
 (MEDV), along with some potential covariates.
 The covariates are CRIM (the per-capita crime rate in the tract), RM (the
 mean number of rooms for houses sold in the tract), RAD (an index of how
 accessible the tract is from Boston's radial roads), TAX (the property
 tax per $10,000 of property value), and LSTAT (the percentage of the tract's
 residents who are considered 
\begin_inset Quotes eld
\end_inset

lower status
\begin_inset Quotes erd
\end_inset

).
 The bandwidth parameter was set to 0.2 for a nearest neighbors-type bandwidth,
 meaning that the sum of kernel weights for each local model was 20% of
 the total number of observations.
 The kernel used was the Epanechnikov kernel.
\end_layout

\begin_layout Standard
A summary of the local coefficients is in Table 
\begin_inset CommandInset ref
LatexCommand ref
reference "tab:boston-coefs-lagr"

\end_inset

.
 It indicates that RM is the only predictor variable with a positive mean
 of the local coefficients.
 The coefficient of the CRIM variable was estimated to be exactly zero at
 
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
Sexpr{100*round(boston.coef.summary['CRIM','Prop.
 zero'],2)}
\end_layout

\end_inset

% of the locations.
 The percentage for the RAD variable was 
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
Sexpr{100*round(boston.coef.summary['RAD','Prop.
 zero'],2)}
\end_layout

\end_inset

%.
\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
begin{figure}
\end_layout

\begin_layout Plain Layout

<<boston-plots, echo=FALSE, results='asis', message=FALSE>>=
\end_layout

\begin_layout Plain Layout

require(brooks)
\end_layout

\begin_layout Plain Layout

load("~/git/gwr/scratch/boston-preset-bw.RData")
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

bmap = list()
\end_layout

\begin_layout Plain Layout

for (v in c('CRIM', 'RM', 'RAD', 'TAX', 'LSTAT')) {
\end_layout

\begin_layout Plain Layout

    bmap[[v]] = ggplot(boston.map) +
\end_layout

\begin_layout Plain Layout

        aes(x=PolyCoordsY, y=PolyCoordsX, group=Poly_Name) +
\end_layout

\begin_layout Plain Layout

        aes_string(fill=paste('coef', v, sep='')) +
\end_layout

\begin_layout Plain Layout

        geom_polygon() +
\end_layout

\begin_layout Plain Layout

        scale_fill_gradient2(low='orange', mid='white', high="purple", midpoint=
0) +
\end_layout

\begin_layout Plain Layout

        xlab("longitude") +
\end_layout

\begin_layout Plain Layout

        ylab("latitude")
\end_layout

\begin_layout Plain Layout

}
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

multiplot(plotlist=bmap, cols=2)
\end_layout

\begin_layout Plain Layout

@
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout


\backslash
caption{The LAGR estimates of coefficients for the Boston house price data.
\backslash
label{fig:boston-lagr-coefs}}
\end_layout

\begin_layout Plain Layout


\backslash
end{figure}
\end_layout

\end_inset


\end_layout

\begin_layout Standard
Estimates of the regression coefficients are plotted in Figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:boston-lagr-coefs"

\end_inset

.
 One interesting result is that LAGR indicates that the TAX variable was
 nowhere an important predictor of the median house price.
 Another is that the coefficients of CRIM and LSTAT are everywhere negative
 or zero (meaning that a greater crime rate or proportion of lower-status
 individuals is associated with a lower median house price where the effect
 is discernable) and that of RM is positive (meaning that a greater average
 number of rooms per house is associated with a greater median house price).
 The coefficient of RAD is positive in some areas and negative in others.
 This indicates that there are parts of Boston where improved access to
 radial roads is associates with a greater median house price and parts
 where it is associated with a lesser median house price.
\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout

<<boston-coef-table, echo=FALSE, results='asis', message=FALSE>>=
\end_layout

\begin_layout Plain Layout

require(xtable)
\end_layout

\begin_layout Plain Layout

require(brooks)
\end_layout

\begin_layout Plain Layout

load("~/git/gwr/scratch/boston-preset-bw.RData")
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

vars = c('CRIM', 'RM', 'RAD', 'TAX', 'LSTAT')
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

boston.coef.summary = matrix(NA, nrow=0, ncol=3)
\end_layout

\begin_layout Plain Layout

for (v in vars) {
\end_layout

\begin_layout Plain Layout

	row = vector()
\end_layout

\begin_layout Plain Layout

	colname.coef = paste("coef", v, sep="")
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

	#Add the table's elements to this row:
\end_layout

\begin_layout Plain Layout

	row = c(row, mean(boston.tracts@data[,colname.coef]))
\end_layout

\begin_layout Plain Layout

	row = c(row, sd(boston.tracts@data[,colname.coef]))
\end_layout

\begin_layout Plain Layout

	row = c(row, mean(boston.tracts@data[,colname.coef]==0))
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

	#Add this row to the table:
\end_layout

\begin_layout Plain Layout

	boston.coef.summary = rbind(boston.coef.summary, row)
\end_layout

\begin_layout Plain Layout

}
\end_layout

\begin_layout Plain Layout

rownames(boston.coef.summary) = vars
\end_layout

\begin_layout Plain Layout

colnames(boston.coef.summary) = c('Mean', 'SD', 'Prop.
 zero')
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

#Generate the table, caption it, and print it with emphasis.
\end_layout

\begin_layout Plain Layout

boston.coef.table = xtable(boston.coef.summary)
\end_layout

\begin_layout Plain Layout

caption(boston.coef.table) = "The mean, standard deviation, and proportion
 of zeros among the local coefficients in a model for the median house price
 in census tracts in Boston, with coefficients selected and fitted by LAGR."
\end_layout

\begin_layout Plain Layout

label(boston.coef.table) = "tab:boston-coefs-lagr"
\end_layout

\begin_layout Plain Layout

print(boston.coef.table, table.placement=NULL, hline.after=c(0))
\end_layout

\begin_layout Plain Layout

@
\end_layout

\end_inset


\end_layout

\begin_layout Standard
In their example using the same data, 
\begin_inset CommandInset citation
LatexCommand cite
key "Sun-Yan-Zhang-Lu-2014"

\end_inset

 estimated that the coefficients of RAD annd LSTAT should be constant, at
 
\begin_inset Formula $0.36$
\end_inset

 and 
\begin_inset Formula $-0.45$
\end_inset

, respectively.
 That conclusion differs from our result, which says that the mean local
 coefficient of RAD is actually negative (
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
Sexpr{round(boston.coef.summary['RAD','Mean'],2)}
\end_layout

\end_inset

), while our mean fitted local coefficient for LSTAT was more negative than
 the estimate of 
\begin_inset CommandInset citation
LatexCommand cite
key "Sun-Yan-Zhang-Lu-2014"

\end_inset

.
\end_layout

\begin_layout Section
Extension to GLMs
\begin_inset CommandInset label
LatexCommand label
name "sec:lagr-gllm"

\end_inset


\end_layout

\begin_layout Subsection
Model
\end_layout

\begin_layout Standard
Generalized linear models (GLM) extend the linear model to distributions
 other than gaussian.
 The generalized local linear model (GLLM) is an extension of the GLM to
 varying coefficient models via local regression.
\end_layout

\begin_layout Standard
As was the case for local linear regression models, the GLLM coefficients
 are smooth functions of location, called 
\begin_inset Formula $\bm{\beta}(\bm{s})$
\end_inset

.
 If the response variable 
\begin_inset Formula $y$
\end_inset

 is from an exponential-family distribution then its density is 
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
f\left(y\left(\bm{s}\right)|\bm{x}\left(\bm{s}\right),\theta\left(\bm{s}\right)\right)=c\left(y\left(\bm{s}\right)\right)\times\exp\left[\theta\left(\bm{s}\right)y\left(\bm{s}\right)-b\left(\theta\left(\bm{s}\right)\right)\right]
\]

\end_inset


\end_layout

\begin_layout Standard
where 
\begin_inset Formula $\phi$
\end_inset

 and 
\begin_inset Formula $\theta$
\end_inset

 are parameters and
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{align*}
E\left\{ y(\bm{s})|\bm{x}(\bm{s})\right\} = & \mu(\bm{s})=b'\left(\theta\left(\bm{s}\right)\right)\\
\theta\left(\bm{s}\right)= & (g\circ b')^{-1}\left(\eta\left(\bm{s}\right)\right)\\
\eta\left(\bm{s}\right)= & \bm{x}^{T}\left(\bm{s}\right)\bm{\beta}\left(\bm{s}\right)=g\left(\mu\left(\bm{s}\right)\right)\\
\text{\text{Var}}\left\{ y\left(\bm{s}\right)|\bm{x}\left(\bm{s}\right)\right\} = & b''\left(\theta\left(\bm{s}\right)\right)
\end{align*}

\end_inset


\end_layout

\begin_layout Standard
The function 
\begin_inset Formula $g(\cdot)$
\end_inset

 is called the link function.
 If its inverse 
\begin_inset Formula $g^{-1}(\cdot)=b'(\cdot)$
\end_inset

 then the composition 
\begin_inset Formula $\left(g\circ b'\right)\left(\cdot\right)$
\end_inset

 is the identity function.
 This particular choice of 
\begin_inset Formula $g$
\end_inset

 is called the canonical link.
 We follow the practice of 
\begin_inset CommandInset citation
LatexCommand cite
key "Fan-Heckman-Wand-1995"

\end_inset

 in assuming the use of the canonical link.
\end_layout

\begin_layout Standard
Under the canonical link function, the expressions for the mean and variance
 of the response variable can be simplified to
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{align*}
E\left\{ y(\bm{s})|\bm{x}(\bm{s})\right\} = & g^{-1}\left(\eta(\bm{s})\right)\\
\text{\text{Var}}\left\{ y(\bm{s})|\bm{x}(\bm{s})\right\} = & \left[g'\left(\mu(\bm{s})\right)\right]^{-1}=V\left(\mu(\bm{s})\right)\\
\frac{d}{d\mu} & g^{-1}\left(\mu\left(\bm{s}\right)\right)=V\left(\mu\left(\bm{s}\right)\right)
\end{align*}

\end_inset

 
\end_layout

\begin_layout Subsection
Local quasi-likelihood
\end_layout

\begin_layout Standard
Assuming the canonical link, all that is required is to specify the mean-varianc
e relationship via the variance function, 
\begin_inset Formula $V\left\{ \mu(\bm{s})\right\} $
\end_inset

.
 Then the GLLM coefficients can be estimated by maximizing the local quasi-likel
ihood 
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{align}
\mathcal{\ell}^{*}\left(\bm{\zeta}(\bm{s})\right) & =\sum_{i=1}^{n}K_{h}\left(\|\bm{s}-\bm{s}_{i}\|\right)Q\left(g^{-1}\left(\bm{z}'(\bm{s}_{i})\bm{\zeta}(\bm{s})\right),Y(\bm{s}_{i})\right).
\end{align}

\end_inset


\end_layout

\begin_layout Standard
The local quasi-likelihood generalizes the local log-likelihood that was
 used to estimate coefficients in the local linear model case.
 The quasi-likelihood is convex, and is defined in terms of its derivative,
 the quasi-score function
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
\frac{\partial}{\partial\mu}Q\left(\mu,y\right)=\frac{y-\mu}{V\left(\mu\right)}.
\]

\end_inset


\end_layout

\begin_layout Subsection
Estimation
\end_layout

\begin_layout Standard
Under these conditions, the local quasi-likelihood is maximized where
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{align}
\frac{\partial}{\partial\bm{\zeta}}\mathcal{\ell}^{*}\left(\hat{\bm{\zeta}}\left(\bm{s}\right)\right) & =\sum_{i=1}^{n}K_{h}\left(\|\bm{s}-\bm{s}_{i}\|\right)\frac{y\left(\bm{s}_{i}\right)-\hat{\mu}\left(\bm{s}_{i};\bm{s}\right)}{V\left(\hat{\mu}\left(\bm{s}_{i};\bm{s}\right)\right)}\bm{z}\left(\bm{s}_{i}\right)=\bm{0}_{3p}
\end{align}

\end_inset


\end_layout

\begin_layout Standard
and 
\begin_inset Formula $\hat{\mu}\left(\bm{s}_{i};\bm{s}\right)=g^{-1}\left(\bm{z}'\left(\bm{s}_{i}\right)\hat{\bm{\zeta}}\left(\bm{s}\right)\right)$
\end_inset

 is the mean at location 
\begin_inset Formula $\bm{s}_{i}$
\end_inset

 estimated using the coefficients 
\begin_inset Formula $\hat{\bm{\zeta}}\left(\bm{s}\right)$
\end_inset

 fitted at location 
\begin_inset Formula $\bm{s}$
\end_inset

.
 Except for the 
\begin_inset Formula $K_{h}\left(\|\bm{s}-\bm{s}_{i}\|\right)$
\end_inset

 term, this is the same as the normal equations for estimating coefficients
 in a GLM.
 The method of iteratively reweighted least squares (IRLS) is used to solve
 for 
\begin_inset Formula $\hat{\bm{\zeta}}\left(\bm{s}\right)$
\end_inset

.
\end_layout

\begin_layout Subsection
Distribution of the local coefficients
\end_layout

\begin_layout Standard
The asymptotic distribution of the local coefficients in a varying-coefficients
 GLM with a one-dimensional effect-modifying parameter are given in 
\begin_inset CommandInset citation
LatexCommand cite
key "Cai-Fan-Li-2000"

\end_inset

.
 For coefficients that vary in two dimensions (e.g.
 spatial location), the asymptotic distribution under the canonical link
 is
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
\sqrt{{nh^{2}f(\bm{{s}})}}\left[\hat{\bm{\beta}}(\bm{s})-\bm{\beta}(\bm{s})-(1/2)\kappa_{0}^{-1}\kappa_{2}h^{2}\left\{ \bm{\beta}_{uu}(\bm{s})+\bm{\beta}_{vv}(\bm{s})\right\} \right]\xrightarrow{{D}}N\left(\bm{0},\kappa_{0}^{-2}\nu_{0}\Gamma^{-1}(\bm{s})\right)
\]

\end_inset


\end_layout

\begin_layout Standard
where 
\begin_inset Formula $\Gamma(\bm{s})=E\left[V\left(\mu(\bm{s})\right)X(\bm{s})X(\bm{s})^{T}\right]$
\end_inset

.
\end_layout

\begin_layout Subsection
LAGR penalty
\end_layout

\begin_layout Standard
As in the case of linear models, the LAGR for GLMs is a grouped 
\begin_inset Formula $\ell_{1}$
\end_inset

 regularization method.
 Now, though, we use a penalized local quasi-likelihood:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{align}
\mathcal{J}\left(\bm{\zeta}(\bm{s})\right) & =\mathcal{\ell}^{*}\left(\bm{\zeta}(\bm{s})\right)+\mathcal{P}\left(\bm{\zeta}(\bm{s})\right)\label{eq:adaptive-lasso-GLLM}\\
 & =\sum_{i=1}^{n}K_{h}\left(\|\bm{s}-\bm{s}_{i}\|\right)Q\left(g^{-1}\left(z'(\bm{s}_{i})\bm{\zeta}(\bm{s})\right),Y(\bm{s}_{i})\right)+\sum_{j=1}^{p}\phi_{j}\left(\bm{s}\right)\|\bm{\zeta}_{j}\left(\bm{s}\right)\|
\end{align}

\end_inset


\end_layout

\begin_layout Standard
and similarly to the case for gaussian data, 
\begin_inset Formula $\phi_{j}\left(\bm{s}\right)=\lambda_{n}\left(\bm{s}\right)\|\tilde{\bm{\zeta}}_{j}\left(\bm{s}\right)\|^{-\gamma}$
\end_inset

, where 
\begin_inset Formula $\lambda_{n}\left(\bm{s}\right)>0$
\end_inset

 is a the local tuning parameter applied to all coefficients at location
 
\begin_inset Formula $\bm{s}$
\end_inset

 and 
\begin_inset Formula $\tilde{\bm{\zeta}}_{j}\left(\bm{s}\right)$
\end_inset

 is the vector of unpenalized local coefficients.
\end_layout

\begin_layout Subsection
Oracle properties of LAGR in the GLM setting
\end_layout

\begin_layout Standard
The oracle properties for LAGR in the GLM setting are similar to those in
 the gaussian setting:
\end_layout

\begin_layout Theorem
\begin_inset CommandInset label
LatexCommand label
name "theorem:normality-glm"

\end_inset

 
\end_layout

\begin_layout Theorem
\begin_inset Argument 1
status open

\begin_layout Plain Layout
Asymptotic normality
\end_layout

\end_inset


\end_layout

\begin_layout Theorem
If 
\begin_inset Formula $h^{-1}n^{-1/2}a_{n}\xrightarrow{p}0$
\end_inset

 and 
\begin_inset Formula $hn^{-1/2}b_{n}\xrightarrow{p}\infty$
\end_inset

 then 
\begin_inset Formula 
\[
h\sqrt{n}\left[\hat{\bm{\beta}}_{a}(\bm{s})-\bm{\beta}_{a}(\bm{s})-\frac{\kappa_{2}h^{2}}{2\kappa_{0}}\left\{ \nabla_{uu}^{2}\bm{\beta}_{a}(\bm{s})+\nabla_{vv}^{2}\bm{\beta}_{a}(\bm{s})\right\} \right]\xrightarrow{d}N\left(0,f\left(\bm{s}\right)^{-1}\kappa_{0}^{-2}\nu_{0}\Gamma^{-1}(\bm{s})\right)
\]

\end_inset


\end_layout

\begin_layout --Separator--

\end_layout

\begin_layout Theorem
\begin_inset CommandInset label
LatexCommand label
name "theorem:selection-glm"

\end_inset


\end_layout

\begin_layout Theorem
\begin_inset Argument 1
status open

\begin_layout Plain Layout
Selection consistency
\end_layout

\end_inset


\end_layout

\begin_layout Theorem
If 
\begin_inset Formula $h^{-1}n^{-1/2}a_{n}\xrightarrow{p}\infty$
\end_inset

 and 
\begin_inset Formula $hn^{-1/2}b_{n}\xrightarrow{p}\infty$
\end_inset

 then 
\begin_inset Formula $Pr\left\{ \|\hat{\bm{\zeta}}_{j}(\bm{s})\|=\utilde{0}\right\} \to0$
\end_inset

 if 
\begin_inset Formula $j\le p_{0}$
\end_inset

 and 
\begin_inset Formula $Pr\left\{ \|\hat{\bm{\zeta}}_{j}(\bm{s})\|=\utilde{0}\right\} \to1$
\end_inset

 if 
\begin_inset Formula $j>p_{0}$
\end_inset

.
 
\end_layout

\begin_layout Section*
\start_of_appendix
Appendix: Proofs of Theorem 
\begin_inset CommandInset ref
LatexCommand ref
reference "theorem:normality"

\end_inset


\begin_inset CommandInset label
LatexCommand label
name "sec:gaussian-normality-proof"

\end_inset

 
\end_layout

\begin_layout Proof
Let 
\begin_inset Formula $H_{n}(\bm{u})=\mathcal{J}\left(\bm{\zeta}\left(\bm{s}\right)+h^{-1}n^{-1/2}\bm{u}\right)-\mathcal{J}\left(\bm{\zeta}\left(\bm{s}\right)\right)$
\end_inset

.
 Then, we have 
\begin_inset Formula 
\begin{align}
H_{n}\left(\bm{u}\right)= & (1/2)\left[\bm{Y}-\bm{Z}(\bm{s})\left\{ \bm{\zeta}\left(\bm{s}\right)+h^{-1}n^{-1/2}\bm{u}\right\} \right]^{T}\bm{W}(\bm{s})\left[\bm{Y}-\bm{Z}(\bm{s})\left\{ \bm{\zeta}\left(\bm{s}\right)+h^{-1}n^{-1/2}\bm{u}\right\} \right]\\
 & +\sum_{j=1}^{p}\phi_{j}(\bm{s})\|\bm{\zeta}_{j}(\bm{s})+h^{-1}n^{-1/2}\bm{u}_{j}\|\\
 & -(1/2)\left\{ \bm{Y}-\bm{Z}(\bm{s})\bm{\zeta}(\bm{s})\right\} ^{T}\bm{W}(\bm{s})\left\{ \bm{Y}-\bm{Z}(\bm{s})\bm{\zeta}(\bm{s})\right\} -\sum_{j=1}^{p}\phi_{j}(\bm{s})\|\bm{\zeta}_{j}(\bm{s})\|\\
= & (1/2)\bm{u}^{T}\left\{ h^{-2}n^{-1}\bm{Z}^{T}(\bm{s})\bm{W}(\bm{s})\bm{Z}(\bm{s})\right\} \bm{u}\\
 & -\bm{u}^{T}\left[h^{-1}n^{-1/2}\bm{Z}^{T}(\bm{s})\bm{W}(\bm{s})\left\{ \bm{Y}-\bm{Z}(\bm{s})\bm{\zeta}(\bm{s})\right\} \right]\\
 & +\sum_{j=1}^{p}n^{-1/2}\phi_{j}(\bm{s})n^{1/2}\left\{ \|\bm{\zeta}_{j}(\bm{s})+h^{-1}n^{-1/2}\bm{u}_{j}\|-\|\bm{\zeta}_{j}(\bm{s})\|\right\} 
\end{align}

\end_inset


\end_layout

\begin_layout Proof
Note that the limiting behavior of the last term differs between the cases
 
\begin_inset Formula $j\le p_{0}$
\end_inset

 and 
\begin_inset Formula $j>p_{0}$
\end_inset

.
\end_layout

\begin_layout Proof
Case 
\begin_inset Formula $j\le p_{0}$
\end_inset

:
\end_layout

\begin_layout Proof
If 
\begin_inset Formula $j\le p_{0}$
\end_inset

, then 
\begin_inset Formula $n^{-1/2}\phi_{j}(\bm{s})\to n^{-1/2}\lambda_{n}(\bm{s})\|\bm{\zeta}_{j}(\bm{s})\|^{-\gamma}$
\end_inset

 and 
\begin_inset Formula $|\sqrt{n}\left\{ \|\bm{\zeta}_{j}(\bm{s})+h^{-1}n^{-1/2}\bm{u}_{j}\|-\|\bm{\zeta}_{j}(\bm{s})\|\right\} |\le h^{-1}\|\bm{u}_{j}\|$
\end_inset

 .
 Thus, 
\begin_inset Formula 
\[
\lim\limits _{n\to\infty}\phi_{j}(\bm{s})\left(\|\bm{\zeta}_{j}(\bm{s})+h^{-1}n^{-1/2}\bm{u}_{j}\|-\|\bm{\zeta}_{j}(\bm{s})\|\right)\le h^{-1}n^{-1/2}\phi_{j}(\bm{s})\|\bm{u}_{j}\|\le h^{-1}n^{-1/2}a_{n}\|\bm{u}_{j}\|\to0
\]

\end_inset


\end_layout

\begin_layout Proof
Case 
\begin_inset Formula $j>p_{0}$
\end_inset

:
\end_layout

\begin_layout Proof
If 
\begin_inset Formula $j>p_{0}$
\end_inset

, then 
\begin_inset Formula $\phi_{j}(\bm{s})\left(\|\bm{\zeta}_{j}(\bm{s})+h^{-1}n^{-1/2}\bm{u}_{j}\|-\|\bm{\zeta}_{j}(\bm{s})\|\right)=\phi_{j}(\bm{s})h^{-1}n^{-1/2}\|\bm{u}_{j}\|$
\end_inset

.
\end_layout

\begin_layout Proof
Since 
\begin_inset Formula $h=O(n^{-1/6})$
\end_inset

, if 
\begin_inset Formula $hn^{-1/2}b_{n}\xrightarrow{p}\infty$
\end_inset

, then 
\begin_inset Formula $h^{-1}n^{-1/2}b_{n}\xrightarrow{p}\infty$
\end_inset

.
\end_layout

\begin_layout Proof
Now, if 
\begin_inset Formula $\|\bm{u}_{j}\|\ne0$
\end_inset

, then 
\begin_inset Formula 
\[
h^{-1}n^{-1/2}\phi_{j}(\bm{s})\|\bm{u}_{j}\|\ge h^{-1}n^{-1/2}b_{n}\|\bm{u}_{j}\|\to\infty.
\]

\end_inset

On the other hand, if 
\begin_inset Formula $\|\bm{u}_{j}\|=0$
\end_inset

, then 
\begin_inset Formula $h^{-1}n^{-1/2}\phi_{j}(\bm{s})\|\bm{u}_{j}\|=0$
\end_inset

.
\end_layout

\begin_layout Proof
Thus, the limit of 
\begin_inset Formula $H_{n}\left(\bm{u}\right)$
\end_inset

 is the same as the limit of 
\begin_inset Formula $H_{n}^{*}\left(\bm{u}\right)$
\end_inset

 where
\end_layout

\begin_layout Proof
\begin_inset Formula 
\[
H_{n}^{*}\left(\bm{u}\right)=(1/2)\bm{u}^{T}\left\{ h^{-2}n^{-1}\bm{Z}^{T}(\bm{s})\bm{W}(\bm{s})\bm{Z}(\bm{s})\right\} \bm{u}-\bm{u}^{T}\left[h^{-1}n^{-1/2}\bm{Z}^{T}(\bm{s})\bm{W}(\bm{s})\left\{ \bm{Y}-\bm{Z}(\bm{s})\bm{\zeta}(\bm{s})\right\} \right]
\]

\end_inset


\end_layout

\begin_layout Proof
if 
\begin_inset Formula $\|\bm{u}_{j}\|=0\;\forall j>p_{0}$
\end_inset

, and 
\begin_inset Formula $H_{n}^{*}\left(\bm{u}\right)=\infty$
\end_inset

 otherwise.
 It follows that 
\begin_inset Formula $H_{n}^{*}\left(\bm{u}\right)$
\end_inset

 is convex and its unique minimizer 
\begin_inset Formula $\hat{\bm{u}}_{n}$
\end_inset

 is found by solving the equation:
\end_layout

\begin_layout Proof
\begin_inset Formula 
\begin{align}
\utilde{0} & =\left\{ h^{-2}n^{-1}\bm{Z}\left(\bm{s}\right)^{T}\bm{W}\left(\bm{s}\right)\bm{Z}\left(\bm{s}\right)\right\} \hat{\bm{u}}_{n}-\left[h^{-1}n^{-1/2}\bm{Z}\left(\bm{s}\right)^{T}\bm{W}\left(\bm{s}\right)\left\{ \bm{Y}-\bm{Z}\left(\bm{s}\right)\bm{\zeta}\left(\bm{s}\right)\right\} \right].\label{eq:limit}
\end{align}

\end_inset


\end_layout

\begin_layout Proof
That is, 
\begin_inset Formula $\hat{\bm{u}}_{n}=\left\{ n^{-1}\bm{Z}^{T}\left(\bm{s}\right)\bm{W}\left(\bm{s}\right)\bm{Z}\left(\bm{s}\right)\right\} ^{-1}\left[hn^{-1/2}\bm{Z}\left(\bm{s}\right)^{T}\bm{W}\left(\bm{s}\right)\left\{ \bm{Y}-\bm{Z}\left(\bm{s}\right)\bm{\zeta}\left(\bm{s}\right)\right\} \right]$
\end_inset

.
\end_layout

\begin_layout Proof
By epiconvergence results, the minimizer of the limiting function is the
 limit of the minimizers 
\begin_inset Formula $\hat{\bm{u}}^{(n)}$
\end_inset

 
\begin_inset CommandInset citation
LatexCommand citep
key "Geyer-1994,Knight-Fu-2000"

\end_inset

.
 Since, by Lemma 2 of 
\begin_inset CommandInset citation
LatexCommand citet
key "Sun-Yan-Zhang-Lu-2014"

\end_inset

,
\end_layout

\begin_layout Proof
\begin_inset Formula 
\begin{equation}
\hat{\bm{u}}_{n}\xrightarrow{d}N\left(\frac{\kappa_{2}h^{2}}{2\kappa_{0}}\{\nabla_{uu}^{2}\bm{\zeta}_{j}(\bm{s})+\nabla_{vv}^{2}\bm{\zeta}_{j}(\bm{s})\},f(\bm{s})\kappa_{0}^{-2}\nu_{0}\sigma^{2}\Psi^{-1}\right)
\end{equation}

\end_inset

the result of Theorem 
\begin_inset CommandInset ref
LatexCommand ref
reference "theorem:normality"

\end_inset

 follows.
\end_layout

\begin_layout Section*
Appendix: Proof of Theorem 
\begin_inset CommandInset ref
LatexCommand ref
reference "theorem:selection"

\end_inset


\begin_inset CommandInset label
LatexCommand label
name "sec:gaussian-selection-proof"

\end_inset


\end_layout

\begin_layout Proof
We showed in Theorem 
\begin_inset CommandInset ref
LatexCommand ref
reference "theorem:normality"

\end_inset

 that 
\begin_inset Formula $\hat{\bm{\zeta}}_{j}\left(\bm{s}\right)\xrightarrow{p}\bm{\zeta}_{j}\left(\bm{s}\right)+\frac{\kappa_{2}h^{2}}{2\kappa_{0}}\{\nabla_{uu}^{2}\bm{\zeta}_{j}\left(\bm{s}\right)+\nabla_{vv}^{2}\bm{\zeta}_{j}\left(\bm{s}\right)\}$
\end_inset

, so to complete the proof of selection consistency, it only remains to
 show that 
\begin_inset Formula $Pr\left\{ \hat{\bm{\zeta}}_{j}\left(\bm{s}\right)=\utilde{0}\right\} \to1$
\end_inset

 if 
\begin_inset Formula $j>p_{0}$
\end_inset

.
\end_layout

\begin_layout Proof
The proof is by contradiction.
 Without loss of generality we consider only the case 
\begin_inset Formula $j=p$
\end_inset

.
\end_layout

\begin_layout Proof
Assume 
\begin_inset Formula $\|\hat{\bm{\zeta}}_{p}(\bm{s})\|\ne0$
\end_inset

.
 Then 
\begin_inset Formula $\mathcal{J}\left(\bm{\zeta}\left(\bm{s}\right)\right)$
\end_inset

 is differentiable w.r.t.
 
\begin_inset Formula $\bm{\zeta}_{p}\left(\bm{s}\right)$
\end_inset

 and is minimized where 
\begin_inset Formula 
\begin{align}
\utilde{0}= & \bm{Z}_{p}^{T}\left(\bm{s}\right)\bm{W}\left(\bm{s}\right)\left\{ \bm{Y}-\bm{Z}_{-p}\left(\bm{s}\right)\hat{\bm{\zeta}}_{-p}\left(\bm{s}\right)-\bm{Z}_{p}\left(\bm{s}\right)\hat{\bm{\zeta}}_{p}\left(\bm{s}\right)\right\} -\phi_{p}(\bm{s})\frac{\hat{\bm{\zeta}}_{p}\left(\bm{s}\right)}{\|\hat{\bm{\zeta}}_{p}\left(\bm{s}\right)\|}\\
= & \bm{Z}_{p}\left(\bm{s}\right)^{T}\bm{W}\left(\bm{s}\right)\left[\bm{Y}-\bm{Z}\left(\bm{s}\right)\bm{\zeta}\left(\bm{s}\right)-\frac{h^{2}\kappa_{2}}{2\kappa_{0}}\left\{ \nabla_{uu}^{2}\bm{\zeta}\left(\bm{s}\right)+\nabla_{vv}^{2}\bm{\zeta}\left(\bm{s}\right)\right\} \right]\\
 & +\bm{Z}_{p}\left(\bm{s}\right)^{T}\bm{W}\left(\bm{s}\right)\bm{Z}_{-p}\left(\bm{s}\right)\left[\bm{\zeta}_{-p}\left(\bm{s}\right)+\frac{h^{2}\kappa_{2}}{2\kappa_{0}}\left\{ \nabla_{uu}^{2}\bm{\zeta}_{-p}\left(\bm{s}\right)+\nabla_{vv}^{2}\bm{\zeta}_{-p}\left(\bm{s}\right)\right\} -\hat{\bm{\zeta}}_{-p}\left(\bm{s}\right)\right]\\
 & +\bm{Z}_{p}\left(\bm{s}\right)^{T}\bm{W}\left(\bm{s}\right)\bm{Z}_{p}\left(\bm{s}\right)\left[\bm{\zeta}_{p}\left(\bm{s}\right)+\frac{h^{2}\kappa_{2}}{2\kappa_{0}}\left\{ \nabla_{uu}^{2}\bm{\zeta}_{p}\left(\bm{s}\right)+\nabla_{vv}^{2}\bm{\zeta}_{p}\left(\bm{s}\right)\right\} -\hat{\bm{\zeta}}_{p}\left(\bm{s}\right)\right]\\
 & -\phi_{p}\left(\bm{s}\right)\frac{\hat{\bm{\zeta}}_{p}\left(\bm{s}\right)}{\|\hat{\bm{\zeta}}_{p}\left(\bm{s}\right)\|}
\end{align}

\end_inset


\end_layout

\begin_layout Proof
Thus, 
\begin_inset Formula 
\begin{align}
\frac{h}{\sqrt{n}}\phi_{p}\left(\bm{s}\right)\frac{\hat{\bm{\zeta}}_{p}\left(\bm{s}\right)}{\|\hat{\bm{\zeta}}_{p}\left(\bm{s}\right)\|}=\label{eq:selection}\\
 & \bm{Z}_{p}\left(\bm{s}\right)^{T}\bm{W}\left(\bm{s}\right)\frac{h}{\sqrt{n}}\left[\bm{Y}-\bm{Z}\left(\bm{s}\right)\bm{\zeta}\left(\bm{s}\right)-\frac{h^{2}\kappa_{2}}{2\kappa_{0}}\left\{ \nabla_{uu}^{2}\bm{\zeta}\left(\bm{s}\right)+\nabla_{vv}^{2}\bm{\zeta}\left(\bm{s}\right)\right\} \right]\\
 & +\left\{ n^{-1}\bm{Z}_{p}\left(\bm{s}\right)^{T}\bm{W}(\bm{s})\bm{Z}_{-p}\left(\bm{s}\right)\right\} h\sqrt{n}\left[\bm{\zeta}_{-p}\left(\bm{s}\right)+\frac{h^{2}\kappa_{2}}{2\kappa_{0}}\left\{ \nabla_{uu}^{2}\bm{\zeta}_{-p}\left(\bm{s}\right)+\nabla_{vv}^{2}\bm{\zeta}_{-p}\left(\bm{s}\right)\right\} -\hat{\bm{\zeta}}_{-p}\left(\bm{s}\right)\right]\notag\\
 & +\left\{ n^{-1}\bm{Z}_{p}\left(\bm{s}\right)^{T}\bm{W}\left(\bm{s}\right)\bm{Z}_{p}\left(\bm{s}\right)\right\} h\sqrt{n}\left[\bm{\zeta}_{p}\left(\bm{s}\right)+\frac{h^{2}\kappa_{2}}{2\kappa_{0}}\left\{ \nabla_{uu}^{2}\bm{\zeta}_{p}\left(\bm{s}\right)+\nabla_{vv}^{2}\bm{\zeta}_{p}\left(\bm{s}\right)\right\} -\hat{\bm{\zeta}}_{p}\left(\bm{s}\right)\right]
\end{align}

\end_inset


\end_layout

\begin_layout Proof
From Lemma 2 of 
\begin_inset CommandInset citation
LatexCommand citet
key "Sun-Yan-Zhang-Lu-2014"

\end_inset

, 
\begin_inset Formula $\left\{ n^{-1}\bm{Z}_{p}\left(\bm{s}\right)^{T}\bm{W}\left(\bm{s}\right)\bm{Z}_{-p}\left(\bm{s}\right)\right\} =O_{p}\left(1\right)$
\end_inset

 and 
\begin_inset Formula $\left\{ n^{-1}\bm{Z}_{p}\left(\bm{s}\right)^{T}\bm{W}\left(\bm{s}\right)\bm{Z}_{p}\left(\bm{s}\right)\right\} =O_{p}\left(1\right)$
\end_inset

.
\end_layout

\begin_layout Proof
From Theorem 3 of 
\begin_inset CommandInset citation
LatexCommand citet
key "Sun-Yan-Zhang-Lu-2014"

\end_inset

, we have that 
\begin_inset Formula $h\sqrt{n}\left[\hat{\bm{\zeta}}_{-p}\left(\bm{s}\right)-\bm{\zeta}_{-p}\left(\bm{s}\right)-\frac{h^{2}\kappa_{2}}{2\kappa_{0}}\left\{ \nabla_{uu}^{2}\zeta_{-p}\left(\bm{s}\right)+\nabla_{vv}^{2}\zeta_{-p}\left(\bm{s}\right)\right\} \right]=O_{p}\left(1\right)$
\end_inset

 and 
\begin_inset Formula $h\sqrt{n}\left[\hat{\bm{\zeta}}_{p}\left(\bm{s}\right)-\bm{\zeta}_{p}\left(\bm{s}\right)-\frac{h^{2}\kappa_{2}}{2\kappa_{0}}\left\{ \nabla_{uu}^{2}\zeta_{p}\left(\bm{s}\right)+\nabla_{vv}^{2}\zeta_{p}\left(\bm{s}\right)\right\} \right]=O_{p}\left(1\right)$
\end_inset

.
\end_layout

\begin_layout Proof
We showed in the proof of Theorem 
\begin_inset CommandInset ref
LatexCommand ref
reference "theorem:normality"

\end_inset

 that
\end_layout

\begin_layout Proof
\begin_inset Formula 
\[
h\sqrt{n}\bm{Z}_{p}\left(\bm{s}\right)^{T}\bm{W}\left(\bm{s}\right)\left[\bm{Y}-\bm{Z}\left(\bm{s}\right)\bm{\zeta}\left(\bm{s}\right)-\frac{h^{2}\kappa_{2}}{2\kappa_{0}}\left\{ \nabla_{uu}^{2}\bm{\zeta}\left(\bm{s}\right)+\nabla_{vv}^{2}\bm{\zeta}\left(\bm{s}\right)\right\} \right]=O_{p}\left(1\right).
\]

\end_inset


\end_layout

\begin_layout Proof
The right hand side of (
\begin_inset CommandInset ref
LatexCommand ref
reference "eq:selection"

\end_inset

) is 
\begin_inset Formula $O_{p}(1)$
\end_inset

, so for 
\begin_inset Formula $\hat{\bm{\zeta}}_{p}\left(\bm{s}\right)$
\end_inset

 to be a solution, we must have that 
\begin_inset Formula $hn^{-1/2}\phi_{p}\left(\bm{s}\right)\hat{\bm{\zeta}}_{p}\left(\bm{s}\right)/\|\hat{\bm{\zeta}}_{p}\left(\bm{s}\right)\|=O_{p}\left(1\right)$
\end_inset

.
\end_layout

\begin_layout Proof
But since by assumption 
\begin_inset Formula $\hat{\bm{\zeta}}_{p}\left(\bm{s}\right)\ne\utilde{0}$
\end_inset

, there must be some 
\begin_inset Formula $k\in\{1,2,3\}$
\end_inset

 such that 
\begin_inset Formula $|\hat{\zeta}_{p_{k}}\left(\bm{s}\right)|=\max\{|\hat{\zeta}_{p_{k'}}\left(\bm{s}\right)|:1\le k'\le3\}$
\end_inset

.
 And for this 
\begin_inset Formula $k$
\end_inset

, we have that 
\begin_inset Formula $|\hat{\zeta}_{p_{k}}\left(\bm{s}\right)|/\|\hat{\bm{\zeta}}_{p}\left(\bm{s}\right)\|\ge1/\sqrt{3}>0$
\end_inset

.
\end_layout

\begin_layout Proof
Since 
\begin_inset Formula $hn^{-1/2}b_{n}\to\infty$
\end_inset

, we have that 
\begin_inset Formula $hn^{-1/2}\phi_{p}\left(\bm{s}\right)\hat{\bm{\zeta}}_{p}\left(\bm{s}\right)/\|\hat{\bm{\zeta}}_{p}\left(\bm{s}\right)\|\ge hb_{n}/\sqrt{3n}\to\infty$
\end_inset

 and therefore the left hand side of 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq:selection"

\end_inset

 dominates the sum to the right side.
 Thus, for large enough 
\begin_inset Formula $n$
\end_inset

, 
\begin_inset Formula $\hat{\bm{\zeta}}_{p}\left(\bm{s}\right)\ne\utilde{0}$
\end_inset

 cannot maximize 
\begin_inset Formula $\mathcal{J}\left(\cdot\right)$
\end_inset

, and therefore 
\begin_inset Formula $Pr\left\{ \hat{\bm{\zeta}}_{(b)}\left(\bm{s}\right)=\utilde{0}\right\} \to1$
\end_inset

.
 
\end_layout

\begin_layout Section*
Appendix: Lemmas
\end_layout

\begin_layout Standard
The next proofs require the following lemmas.
 Define the 
\begin_inset Formula $q$
\end_inset

-functions to be the derivatives of the quasi-likelihood: 
\begin_inset Formula $q_{j}(t,y)=\left(\partial/\partial t\right)^{j}Q\left(g^{-1}\left(t\right),y\right)$
\end_inset

.
 Then 
\begin_inset Formula $q_{1}\left(\eta\left(\bm{s}\right),\mu\left(\bm{s}\right)\right)=0$
\end_inset

 and 
\begin_inset Formula $q_{2}\left(\eta\left(\bm{s}\right),\mu\left(\bm{s}\right)\right)=-b''\left(\eta\left(\bm{s}\right)\right)$
\end_inset

.
 Also define 
\begin_inset Formula $\bar{\eta}_{i}\left(\right)$
\end_inset


\end_layout

\begin_layout Lemma
\begin_inset Argument 1
status open

\begin_layout Plain Layout
\begin_inset CommandInset label
LatexCommand label
name "lemma:omega"

\end_inset


\end_layout

\end_inset


\begin_inset Formula 
\[
E\left[\sum_{i=1}^{n}K_{h}\left(\|\bm{s}-\bm{s}_{i}\|\right)q_{1}\left(\left\{ \bm{Z}\left(\bm{s}_{i}\right)\right\} _{i}^{T}\bm{\zeta}\left(\bm{s}\right),Y\left(\bm{s}_{i}\right)\right)\left\{ \bm{Z}\left(\bm{s}_{i}\right)\right\} _{i}\right]=(1/2)\alpha_{n}^{-1}h^{2}f\left(\bm{s}\right)\left(\begin{array}{ccc}
1 & \nu_{1} & \nu_{2}\\
\nu_{1} & \nu_{2} & \nu_{3}\\
\nu_{2} & \nu_{2} & \nu_{4}
\end{array}\right)\left\{ 1+o\left(1\right)\right\} 
\]

\end_inset


\end_layout

\begin_layout Lemma
and 
\end_layout

\begin_layout Lemma
\begin_inset Formula 
\[
Var\left[\sum_{i=1}^{n}K_{h}\left(\|\bm{s}-\bm{s}_{i}\|\right)q_{1}\left(\left\{ \bm{Z}\left(\bm{s}_{i}\right)\right\} _{i}^{T}\bm{\zeta}\left(\bm{s}\right),Y\left(\bm{s}_{i}\right)\right)\left\{ \bm{Z}\left(\bm{s}_{i}\right)\right\} _{i}\right]=f\left(\bm{s}\right)\left(\begin{array}{ccc}
\nu_{0} & \nu_{1} & \nu_{2}\\
\nu_{1} & \nu_{2} & \nu_{3}\\
\nu_{2} & \nu_{2} & \nu_{4}
\end{array}\right)\otimes\Gamma\left(\bm{s}\right)=-\Lambda+o\left(1\right)
\]

\end_inset


\end_layout

\begin_layout --Separator--

\end_layout

\begin_layout Lemma
\begin_inset Argument 1
status open

\begin_layout Plain Layout
\begin_inset CommandInset label
LatexCommand label
name "lemma:delta"

\end_inset


\end_layout

\end_inset


\begin_inset Formula 
\[
E\left[\sum_{i=1}^{n}K_{h}\left(\|\bm{s}-\bm{s}_{i}\|\right)q_{2}\left(\left\{ \bm{Z}\left(\bm{s}_{i}\right)\right\} _{i}^{T}\bm{\zeta}\left(\bm{s}\right),Y\left(\bm{s}_{i}\right)\right)\left\{ \bm{Z}\left(\bm{s}_{i}\right)\right\} _{i}\left\{ \bm{Z}\left(\bm{s}_{i}\right)\right\} _{i}^{T}\right]\to-f\left(\bm{s}\right)\left(\begin{array}{ccc}
1 & \nu_{1} & \nu_{2}\\
\nu_{1} & \nu_{2} & \nu_{3}\\
\nu_{2} & \nu_{2} & \nu_{4}
\end{array}\right)\otimes\Gamma\left(\bm{s}\right)=-\Delta\left(\bm{s}\right)
\]

\end_inset


\end_layout

\begin_layout Lemma
and
\end_layout

\begin_layout Lemma
\begin_inset Formula 
\[
Var\left\{ \left(\sum_{i=1}^{n}K_{h}\left(\|\bm{s}-\bm{s}_{i}\|\right)q_{2}\left(\left\{ \bm{Z}\left(\bm{s}_{i}\right)\right\} _{i}^{T}\bm{\zeta}\left(\bm{s}\right),Y\left(\bm{s}_{i}\right)\right)\left\{ \bm{Z}\left(\bm{s}_{i}\right)\right\} _{i}\left\{ \bm{Z}\left(\bm{s}_{i}\right)\right\} _{i}^{T}\right)_{ij}\right\} =O\left(n^{-1}h^{-2}\right)
\]

\end_inset


\end_layout

\begin_layout Section*
Appendix: Proof of Theorem 
\begin_inset CommandInset ref
LatexCommand ref
reference "theorem:normality-glm"

\end_inset


\end_layout

\begin_layout Proof
\begin_inset Argument 1
status open

\begin_layout Plain Layout
Proof of theorem 
\begin_inset CommandInset ref
LatexCommand ref
reference "theorem:normality-glm"

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
Define 
\begin_inset Formula $H_{n}(\bm{u})=\mathcal{J}^{*}\left(\bm{\zeta}\left(\bm{s}\right)+h^{-1}n^{-1/2}\bm{u}\right)-\mathcal{J}^{*}\left(\bm{\zeta}\left(\bm{s}\right)\right)$
\end_inset

.
 Then, 
\begin_inset Formula 
\begin{align}
H_{n}(\bm{u})= & \sum_{i=1}^{n}K_{h}\left(\|\bm{s}-\bm{s}_{i}\|\right)Q\left(g^{-1}\left(\left\{ \bm{Z}\left(\bm{s}_{i}\right)\right\} _{i}^{T}\bm{\zeta}\left(\bm{s}\right)+h^{-1}n^{-1/2}\bm{u}\right),Y(\bm{s}_{i})\right)\\
 & -\sum_{i=1}^{n}K_{h}\left(\|\bm{s}-\bm{s}_{i}\|\right)Q\left(g^{-1}\left(\left\{ \bm{Z}\left(\bm{s}_{i}\right)\right\} _{i}^{T}\bm{\zeta}\left(\bm{s}\right)\right),Y\left(\bm{s}_{i}\right)\right)\\
 & +\sum_{j=1}^{p}\phi_{j}\left(\bm{s}\right)\|\bm{\zeta}_{j}\left(\bm{s}\right)+h^{-1}n^{-1/2}\bm{u}\|-+\sum_{j=1}^{p}\phi_{j}\left(\bm{s}\right)\|\bm{\zeta}_{j}\left(\bm{s}\right)\|
\end{align}

\end_inset


\end_layout

\begin_layout Standard
Define
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{align*}
\Omega_{n}\left(\bm{s}\right)= & \sum_{i=1}^{n}K_{h}\left(\|\bm{s}-\bm{s}_{i}\|\right)q_{1}\left(\left\{ \bm{Z}\left(\bm{s}_{i}\right)\right\} _{i}^{T}\bm{\zeta}\left(\bm{s}\right),Y\left(\bm{s}_{i}\right)\right)\left\{ \bm{Z}\left(\bm{s}_{i}\right)\right\} _{i}\\
\Delta_{n}\left(\bm{s}\right)= & \sum_{i=1}^{n}K_{h}\left(\|\bm{s}-\bm{s}_{i}\|\right)q_{2}\left(\left\{ \bm{Z}\left(\bm{s}_{i}\right)\right\} _{i}^{T}\bm{\zeta}\left(\bm{s}\right),Y\left(\bm{s}_{i}\right)\right)\left\{ \bm{Z}\left(\bm{s}_{i}\right)\right\} _{i}\left\{ \bm{Z}\left(\bm{s}_{i}\right)\right\} _{i}^{T}.
\end{align*}

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula $ $
\end_inset

Then taking the Taylor expansion of 
\begin_inset Formula $\mathcal{J}^{*}\left(\bm{\zeta}\left(\bm{s}\right)+h^{-1}n^{-1/2}\bm{u}\right)$
\end_inset

 around 
\begin_inset Formula $\bm{\zeta}\left(\bm{s}\right)$
\end_inset

 give us:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{align}
\mathcal{J}^{*}\left(\bm{\zeta}(\bm{s})+h^{-1}n^{-1/2}\bm{u}\right)= & \mathcal{J}^{*}\left(\bm{\zeta}\left(\bm{s}\right)\right)\label{eq:glm-Taylor-expansion}\\
 & +\Omega_{n}\left(\bm{s}\right)^{T}\bm{u}\\
 & +(1/2)\bm{u}^{T}\Delta_{n}\left(\bm{s}\right)\bm{u}\\
 & +\left(h^{-3}n^{-3/2}/6\right)\sum_{i=1}^{n}K_{h}\left(\|\bm{s}-\bm{s}_{i}\|\right)q_{3}\left(\left\{ \bm{Z}(\bm{s}_{i})\right\} _{i}^{T}\tilde{\bm{\zeta}}_{i},Y\left(\bm{s}_{i}\right)\right)\left[\left\{ \bm{Z}\left(\bm{s}_{i}\right)\right\} _{i}^{T}\bm{u}\right]^{3}\\
 & +\sum_{j=1}^{p}\phi_{j}\left(\bm{s}\right)\|\bm{\zeta}_{j}\left(\bm{s}\right)+h^{-1}n^{-1/2}\bm{u}\|\nonumber 
\end{align}

\end_inset


\end_layout

\begin_layout Standard
where 
\begin_inset Formula $\tilde{\bm{\zeta}_{i}}$
\end_inset

 lies between 
\begin_inset Formula $\bm{\zeta}(\bm{s})$
\end_inset

 and 
\begin_inset Formula $\bm{\zeta}(\bm{s})+h^{-1}n^{-1/2}\bm{u}$
\end_inset

.
 Thus,
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{align}
H_{n}\left(\bm{u}\right)= & \Omega_{n}\left(\bm{s}\right)^{T}\bm{u}\label{eq:taylor-expanded-glm-criterion}\\
 & +(1/2)\bm{u}^{T}\Delta_{n}\left(\bm{s}\right)\bm{u}\\
 & +\left(h^{-3}n^{-3/2}/6\right)\sum_{i=1}^{n}K_{h}\left(\|\bm{s}-\bm{s}_{i}\|\right)q_{3}\left(\left\{ \bm{Z}(\bm{s}_{i})\right\} _{i}^{T}\tilde{\bm{\zeta}}_{i},Y\left(\bm{s}_{i}\right)\right)\left[\left\{ \bm{Z}\left(\bm{s}_{i}\right)\right\} _{i}^{T}\bm{u}\right]^{3}\\
 & +\sum_{j=1}^{p}\phi_{j}\left(\bm{s}\right)\left\{ \|\bm{\zeta}_{j}\left(\bm{s}\right)+h^{-1}n^{-1/2}\bm{u}\|-\|\bm{\zeta}_{j}\left(\bm{s}\right)\|\right\} .\nonumber 
\end{align}

\end_inset


\end_layout

\begin_layout Standard
Since 
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
O\left(E\left|\left(h^{-3}n^{-3/2}/6\right)\sum_{i=1}^{n}K_{h}\left(\|\bm{s}-\bm{s}_{i}\|\right)q_{3}\left(\left\{ \bm{Z}(\bm{s}_{i})\right\} _{i}^{T}\tilde{\bm{\zeta}}_{i},Y\left(\bm{s}_{i}\right)\right)\left[\left\{ \bm{Z}\left(\bm{s}_{i}\right)\right\} _{i}^{T}\bm{u}\right]^{3}\right|\right)=O\left(n^{-1/2}h^{-1}\right),
\]

\end_inset


\end_layout

\begin_layout Standard
the third term in 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq:taylor-expanded-glm-criterion"

\end_inset

 is 
\begin_inset Formula $O_{p}\left(n^{-1/2}h^{-1}\right)$
\end_inset

.
\end_layout

\begin_layout Standard
Note that the limiting behavior of the last term of 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq:taylor-expanded-glm-criterion"

\end_inset

 differs between the cases 
\begin_inset Formula $j\le p_{0}$
\end_inset

 and 
\begin_inset Formula $j>p_{0}$
\end_inset

.
\end_layout

\begin_layout Paragraph
Case 
\begin_inset Formula $j\le p_{0}$
\end_inset

:
\end_layout

\begin_layout Standard
If 
\begin_inset Formula $j\le p_{0}$
\end_inset

, then 
\begin_inset Formula $n^{-1/2}\phi_{j}(\bm{s})\to n^{-1/2}\lambda_{n}(\bm{s})\|\bm{\zeta}_{j}(\bm{s})\|^{-\gamma}$
\end_inset

 and 
\begin_inset Formula $|\sqrt{n}\left\{ \|\bm{\zeta}_{j}(\bm{s})+h^{-1}n^{-1/2}\bm{u}_{j}\|-\|\bm{\zeta}_{j}(\bm{s})\|\right\} |\le h^{-1}\|\bm{u}_{j}\|$
\end_inset

 .
 Thus, 
\begin_inset Formula 
\[
\lim\limits _{n\to\infty}\phi_{j}(\bm{s})\left(\|\bm{\zeta}_{j}(\bm{s})+h^{-1}n^{-1/2}\bm{u}_{j}\|-\|\bm{\zeta}_{j}(\bm{s})\|\right)\le h^{-1}n^{-1/2}\phi_{j}(\bm{s})\|\bm{u}_{j}\|\le h^{-1}n^{-1/2}a_{n}\|\bm{u}_{j}\|\to0
\]

\end_inset


\end_layout

\begin_layout Paragraph
Case 
\begin_inset Formula $j>p_{0}$
\end_inset

:
\end_layout

\begin_layout Standard
If 
\begin_inset Formula $j>p_{0}$
\end_inset

, then 
\begin_inset Formula $\phi_{j}(\bm{s})\left(\|\bm{\zeta}_{j}(\bm{s})+h^{-1}n^{-1/2}\bm{u}_{j}\|-\|\bm{\zeta}_{j}(\bm{s})\|\right)=\phi_{j}(\bm{s})h^{-1}n^{-1/2}\|\bm{u}_{j}\|$
\end_inset

.
\end_layout

\begin_layout Standard
Since 
\begin_inset Formula $h=O(n^{-1/6})$
\end_inset

, if 
\begin_inset Formula $hn^{-1/2}b_{n}\xrightarrow{p}\infty$
\end_inset

, then 
\begin_inset Formula $h^{-1}n^{-1/2}b_{n}\xrightarrow{p}\infty$
\end_inset

.
\end_layout

\begin_layout Standard
Now, if 
\begin_inset Formula $\|\bm{u}_{j}\|\ne0$
\end_inset

, then 
\begin_inset Formula 
\[
h^{-1}n^{-1/2}\phi_{j}(\bm{s})\|\bm{u}_{j}\|\ge h^{-1}n^{-1/2}b_{n}\|\bm{u}_{j}\|\to\infty.
\]

\end_inset

On the other hand, if 
\begin_inset Formula $\|\bm{u}_{j}\|=0$
\end_inset

, then 
\begin_inset Formula $h^{-1}n^{-1/2}\phi_{j}(\bm{s})\|\bm{u}_{j}\|=0$
\end_inset

.
\end_layout

\begin_layout Standard
Now, 
\end_layout

\begin_layout Standard
Thus, the limit of 
\begin_inset Formula $H_{n}\left(\bm{u}\right)$
\end_inset

 is the same as the limit of 
\begin_inset Formula $H_{n}^{*}\left(\bm{u}\right)$
\end_inset

 where
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
H_{n}^{*}\left(\bm{u}\right)=\Omega_{n}\left(\bm{s}\right)^{T}\bm{u}+(1/2)\bm{u}^{T}\Delta\left(\bm{s}\right)\bm{u}+o_{p}\left(1\right)
\]

\end_inset

 
\end_layout

\begin_layout Standard
if 
\begin_inset Formula $\|\bm{u}_{j}\|=0\;\forall j>p_{0}$
\end_inset

, and 
\begin_inset Formula $H_{n}^{*}\left(\bm{u}\right)=\infty$
\end_inset

 otherwise.
 It follows that 
\begin_inset Formula $H_{n}^{*}\left(\bm{u}\right)$
\end_inset

 is convex and its unique minimizer 
\begin_inset Formula $\hat{\bm{u}}_{n}$
\end_inset

 is
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{align}
\hat{\bm{u}}_{n}= & \left\{ \Delta\left(\bm{s}\right)\right\} ^{-1}\Omega_{n}\left(\bm{s}\right)+o_{p}\left(1\right)\label{eq:limit-1}
\end{align}

\end_inset


\end_layout

\begin_layout Standard
by the quadratic approximation lemma 
\begin_inset CommandInset citation
LatexCommand citep
key "Fan-Gijbels-1996"

\end_inset

.
 Then by epiconvergence, the minimizer of the limiting function is the limit
 of the minimizers 
\begin_inset Formula $\hat{\bm{u}}_{n}$
\end_inset

 
\begin_inset CommandInset citation
LatexCommand citep
key "Geyer-1994,Knight-Fu-2000"

\end_inset

.
\end_layout

\begin_layout Standard
Since 
\begin_inset Formula $\Delta\left(\bm{s}\right)$
\end_inset

 is a constant, the normality of 
\begin_inset Formula $\hat{\bm{u}}_{n}$
\end_inset

 follows from the normality of 
\begin_inset Formula $\Omega_{n}\left(\bm{s}\right)$
\end_inset

, which is establised via the CramÃ©r-Wold device.
 Let 
\begin_inset Formula $\bm{d}\in\mathbb{R}^{3p}$
\end_inset

 be a unit vector, and let
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
\xi_{i}=K_{h}\left(\|\bm{s}_{i}-\bm{s}\|\right)q_{1}\left(g^{-1}\left(\left\{ \bm{Z}\left(\bm{s}_{i}\right)\right\} _{i}^{T}\bm{\zeta}\left(\bm{s}\right)\right),Y\left(\bm{s}_{i}\right)\right)\bm{d}^{T}\left\{ \bm{Z}\left(\bm{s}_{i}\right)\right\} _{i}.
\]

\end_inset


\end_layout

\begin_layout Standard
Then 
\begin_inset Formula $\bm{d}^{T}\Omega_{n}\left(\bm{s}\right)=\alpha_{n}\sum_{i=1}^{n}\xi_{i}$
\end_inset

.
\end_layout

\begin_layout Proof
\begin_inset Argument 1
status open

\begin_layout Plain Layout
Proof of Theorem 
\begin_inset CommandInset ref
LatexCommand ref
reference "theorem:selection"

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Proof
We showed in Theorem 
\begin_inset CommandInset ref
LatexCommand ref
reference "theorem:normality"

\end_inset

 that 
\begin_inset Formula $\hat{\bm{\zeta}}_{j}\left(\bm{s}\right)\xrightarrow{p}\bm{\zeta}_{j}\left(\bm{s}\right)+\frac{\kappa_{2}h^{2}}{2\kappa_{0}}\{\nabla_{uu}^{2}\bm{\zeta}_{j}\left(\bm{s}\right)+\nabla_{vv}^{2}\bm{\zeta}_{j}\left(\bm{s}\right)\}$
\end_inset

, so to complete the proof of selection consistency, it only remains to
 show that 
\begin_inset Formula $Pr\left\{ \hat{\bm{\zeta}}_{j}\left(\bm{s}\right)=\utilde{0}\right\} \to1$
\end_inset

 if 
\begin_inset Formula $j>p_{0}$
\end_inset

.
\end_layout

\begin_layout Standard
The proof is by contradiction.
 Without loss of generality we consider only the case 
\begin_inset Formula $j=p$
\end_inset

.
\end_layout

\begin_layout Standard
Assume 
\begin_inset Formula $\|\hat{\bm{\zeta}}_{p}(\bm{s})\|\ne0$
\end_inset

.
 Then 
\begin_inset Formula $\mathcal{J}\left(\bm{\zeta}\left(\bm{s}\right)\right)$
\end_inset

 is differentiable w.r.t.
 
\begin_inset Formula $\bm{\zeta}_{p}\left(\bm{s}\right)$
\end_inset

 and is minimized where 
\begin_inset Formula 
\begin{align}
\phi_{p}(\bm{s})\frac{\hat{\bm{\zeta}}_{p}\left(\bm{s}\right)}{\|\hat{\bm{\zeta}}_{p}\left(\bm{s}\right)\|}= & \sum_{i=1}^{n}K_{h}\left(\|\bm{s}_{i}-\bm{s}\|\right)q_{1}\left(g^{-1}\left(\left\{ \bm{Z}\left(\bm{s}_{i}\right)\right\} _{i}^{T}\hat{\bm{\zeta}}\left(\bm{s}\right)\right),Y_{i}\right)\left\{ \bm{Z}_{p}\left(\bm{s}_{i}\right)\right\} _{i}\label{eq:glm-selection}
\end{align}

\end_inset


\end_layout

\begin_layout Standard
From Lemma 
\begin_inset CommandInset ref
LatexCommand ref
reference "lemma:omega"

\end_inset

, the right hand side of 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq:glm-selection"

\end_inset

 is 
\begin_inset Formula $O_{p}\left(1\right)$
\end_inset

, so for 
\begin_inset Formula $\hat{\bm{\zeta}}_{p}\left(\bm{s}\right)$
\end_inset

 to be a solution, we must have that 
\begin_inset Formula $hn^{-1/2}\phi_{p}\left(\bm{s}\right)\hat{\bm{\zeta}}_{p}\left(\bm{s}\right)/\|\hat{\bm{\zeta}}_{p}\left(\bm{s}\right)\|=O_{p}\left(1\right)$
\end_inset

.
\end_layout

\begin_layout Standard
But since by assumption 
\begin_inset Formula $\hat{\bm{\zeta}}_{p}\left(\bm{s}\right)\ne\utilde{0}$
\end_inset

, there must be some 
\begin_inset Formula $k\in\{1,2,3\}$
\end_inset

 such that 
\begin_inset Formula $|\hat{\zeta}_{p_{k}}\left(\bm{s}\right)|=\max\{|\hat{\zeta}_{p_{k'}}\left(\bm{s}\right)|:1\le k'\le3\}$
\end_inset

.
 And for this 
\begin_inset Formula $k$
\end_inset

, we have that 
\begin_inset Formula $|\hat{\zeta}_{p_{k}}\left(\bm{s}\right)|/\|\hat{\bm{\zeta}}_{p}\left(\bm{s}\right)\|\ge1/\sqrt{3}>0$
\end_inset

.
\end_layout

\begin_layout Standard
Since 
\begin_inset Formula $hn^{-1/2}b_{n}\to\infty$
\end_inset

, we have that 
\begin_inset Formula $hn^{-1/2}\phi_{p}\left(\bm{s}\right)\hat{\bm{\zeta}}_{p}\left(\bm{s}\right)/\|\hat{\bm{\zeta}}_{p}\left(\bm{s}\right)\|\ge hb_{n}/\sqrt{3n}\to\infty$
\end_inset

 and therefore the left hand side of 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq:glm-selection"

\end_inset

 dominates the sum to the right side.
 Thus, for large enough 
\begin_inset Formula $n$
\end_inset

, 
\begin_inset Formula $\hat{\bm{\zeta}}_{p}\left(\bm{s}\right)\ne\utilde{0}$
\end_inset

 cannot maximize 
\begin_inset Formula $\mathcal{J}\left(\cdot\right)$
\end_inset

, and therefore 
\begin_inset Formula $Pr\left\{ \hat{\bm{\zeta}}_{(b)}\left(\bm{s}\right)=\utilde{0}\right\} \to1$
\end_inset

.
 
\end_layout

\begin_layout Standard
\begin_inset CommandInset bibtex
LatexCommand bibtex
bibfiles "/Users/wesley/git/gwr/references/gwr"
options "chicago"

\end_inset


\end_layout

\end_body
\end_document
